[2023-09-30T18:36:14.835+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:14.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:36:14.837+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:14.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:14.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:14.995+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:14.995+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:36:15.022+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:15.022+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:36:15.075+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.244 seconds
[2023-09-30T18:36:45.130+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:45.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:36:45.133+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:45.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:45.150+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:45.186+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:45.186+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:36:45.223+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:45.223+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:36:45.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-09-30T18:36:58.287+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:58.288+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:36:58.290+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:58.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:58.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:36:58.346+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:58.345+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:36:58.378+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:36:58.377+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:36:58.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-09-30T18:37:28.763+0000] {processor.py:157} INFO - Started process (PID=374) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:28.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:37:28.768+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:28.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:28.788+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:28.821+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:28.821+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:37:28.849+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:28.849+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:37:28.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-09-30T18:37:59.104+0000] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:59.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:37:59.108+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:59.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:59.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:37:59.165+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:59.165+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:37:59.198+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:37:59.198+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:37:59.225+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T18:38:29.497+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:29.499+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:38:29.500+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:29.500+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:29.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:29.549+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:29.549+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:38:29.581+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:29.580+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:38:29.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T18:38:59.835+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:59.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:38:59.839+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:59.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:59.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:38:59.907+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:59.907+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:38:59.935+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:38:59.935+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:38:59.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-09-30T18:39:30.174+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:39:30.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:39:30.177+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:39:30.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:39:30.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:39:30.231+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:39:30.230+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:39:30.260+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:39:30.260+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:39:30.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T18:40:00.562+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:00.564+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:40:00.565+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:00.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:00.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:00.616+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:00.616+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:40:00.646+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:00.645+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:40:00.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-09-30T18:40:30.903+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:30.905+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:40:30.907+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:30.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:30.926+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:40:30.960+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:30.959+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:40:30.990+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:40:30.989+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:40:31.012+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T18:41:01.311+0000] {processor.py:157} INFO - Started process (PID=430) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:01.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:41:01.315+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:01.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:01.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:01.363+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:01.362+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:41:01.393+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:01.392+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:41:01.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T18:41:31.704+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:31.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:41:31.708+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:31.707+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:31.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:41:31.760+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:31.760+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:41:31.788+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:41:31.788+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:41:31.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T18:42:02.048+0000] {processor.py:157} INFO - Started process (PID=446) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:02.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:42:02.051+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:02.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:02.065+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:02.100+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:02.100+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:42:02.129+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:02.129+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:42:02.162+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-09-30T18:42:32.398+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:32.400+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:42:32.402+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:32.401+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:32.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:42:32.464+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:32.463+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:42:32.492+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:42:32.492+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:42:32.519+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-09-30T18:43:02.751+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:02.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:43:02.754+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:02.754+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:02.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:02.814+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:02.814+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:43:02.842+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:02.842+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:43:02.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-09-30T18:43:33.096+0000] {processor.py:157} INFO - Started process (PID=470) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:33.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:43:33.100+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:33.099+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:33.116+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:43:33.156+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:33.156+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:43:33.186+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:43:33.186+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:43:33.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-09-30T18:44:03.482+0000] {processor.py:157} INFO - Started process (PID=478) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:03.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:44:03.485+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:03.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:03.499+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:03.533+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:03.533+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:44:03.563+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:03.562+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:44:03.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T18:44:33.857+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:33.858+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:44:33.860+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:33.859+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:33.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:44:33.911+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:33.911+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:44:33.940+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:44:33.940+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:44:33.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-09-30T18:45:04.242+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:04.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:45:04.245+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:04.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:04.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:04.293+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:04.293+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:45:04.326+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:04.325+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:45:04.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T18:45:34.520+0000] {processor.py:157} INFO - Started process (PID=502) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:34.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:45:34.522+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:34.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:34.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:45:34.567+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:34.566+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:45:34.596+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:45:34.595+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:45:34.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.106 seconds
[2023-09-30T18:46:04.828+0000] {processor.py:157} INFO - Started process (PID=510) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:04.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:46:04.831+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:04.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:04.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:04.876+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:04.876+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:46:04.906+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:04.905+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:46:04.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T18:46:35.262+0000] {processor.py:157} INFO - Started process (PID=518) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:35.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:46:35.264+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:35.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:35.277+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:46:35.310+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:35.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:46:35.344+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:46:35.343+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:46:35.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T18:47:05.572+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:05.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:47:05.575+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:05.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:05.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:05.621+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:05.621+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:47:05.651+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:05.651+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:47:05.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-09-30T18:47:35.988+0000] {processor.py:157} INFO - Started process (PID=534) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:35.989+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:47:35.992+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:35.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:36.009+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:47:36.043+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:36.042+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:47:36.072+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:47:36.071+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:47:36.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T18:48:06.321+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:06.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:48:06.324+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:06.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:06.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:06.373+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:06.372+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:48:06.401+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:06.401+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:48:06.424+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-09-30T18:48:36.708+0000] {processor.py:157} INFO - Started process (PID=550) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:36.709+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:48:36.711+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:36.710+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:36.726+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:48:36.757+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:36.757+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:48:36.786+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:48:36.786+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:48:36.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-09-30T18:49:07.006+0000] {processor.py:157} INFO - Started process (PID=558) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:07.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:49:07.009+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:07.009+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:07.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:07.057+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:07.057+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:49:07.087+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:07.087+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:49:07.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-09-30T18:49:37.398+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:37.399+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:49:37.401+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:37.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:37.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:49:37.448+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:37.448+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:49:37.482+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:49:37.482+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:49:37.505+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.112 seconds
[2023-09-30T18:50:07.736+0000] {processor.py:157} INFO - Started process (PID=574) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:07.738+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:50:07.740+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:07.740+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:07.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:07.795+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:07.795+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:50:07.824+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:07.824+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:50:07.861+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T18:50:38.112+0000] {processor.py:157} INFO - Started process (PID=582) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:38.113+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:50:38.115+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:38.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:38.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:50:38.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:38.164+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:50:38.194+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:50:38.194+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:50:38.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T18:51:08.459+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:08.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:51:08.463+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:08.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:08.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:08.512+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:08.511+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:51:08.540+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:08.540+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:51:08.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-09-30T18:51:38.875+0000] {processor.py:157} INFO - Started process (PID=597) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:38.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:51:38.879+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:38.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:38.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:51:38.934+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:38.933+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:51:38.967+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:51:38.967+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:51:38.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T18:52:09.159+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:09.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:52:09.162+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:09.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:09.176+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:09.209+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:09.209+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:52:09.239+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:09.239+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:52:09.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-09-30T18:52:39.624+0000] {processor.py:157} INFO - Started process (PID=613) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:39.626+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:52:39.629+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:39.628+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:39.648+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:52:39.680+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:39.679+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:52:39.708+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:52:39.708+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:52:39.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-09-30T18:53:09.975+0000] {processor.py:157} INFO - Started process (PID=622) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:09.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:53:09.978+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:09.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:09.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:10.047+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:10.047+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:53:10.090+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:10.090+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:53:10.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.169 seconds
[2023-09-30T18:53:40.355+0000] {processor.py:157} INFO - Started process (PID=630) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:40.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:53:40.358+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:40.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:40.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:53:40.403+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:40.403+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:53:40.437+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:53:40.437+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:53:40.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T18:54:10.753+0000] {processor.py:157} INFO - Started process (PID=638) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:10.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:54:10.756+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:10.756+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:10.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:10.801+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:10.800+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:54:10.829+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:10.829+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:54:10.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-09-30T18:54:41.031+0000] {processor.py:157} INFO - Started process (PID=646) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:41.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:54:41.033+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:41.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:41.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:54:41.078+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:41.078+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:54:41.107+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:54:41.107+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:54:41.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.105 seconds
[2023-09-30T18:55:11.452+0000] {processor.py:157} INFO - Started process (PID=654) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:11.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:55:11.456+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:11.455+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:11.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:11.507+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:11.507+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:55:11.536+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:11.535+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:55:11.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T18:55:41.783+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:41.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:55:41.787+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:41.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:41.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:55:41.841+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:41.841+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:55:41.870+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:55:41.869+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:55:41.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T18:56:12.161+0000] {processor.py:157} INFO - Started process (PID=670) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:12.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:56:12.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:12.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:12.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:12.213+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:12.212+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:56:12.241+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:12.241+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:56:12.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-09-30T18:56:42.552+0000] {processor.py:157} INFO - Started process (PID=678) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:42.554+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:56:42.555+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:42.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:42.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:56:42.602+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:42.602+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:56:42.630+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:56:42.630+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:56:42.652+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.106 seconds
[2023-09-30T18:57:12.828+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:12.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:57:12.831+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:12.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:12.847+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:12.892+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:12.892+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:57:12.921+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:12.921+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:57:12.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T18:57:43.261+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:43.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:57:43.265+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:43.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:43.282+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:57:43.318+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:43.318+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:57:43.346+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:57:43.346+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:57:43.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T18:58:13.567+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:13.569+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:58:13.570+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:13.570+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:13.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:13.619+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:13.619+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:58:13.650+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:13.649+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:58:13.686+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-09-30T18:58:43.942+0000] {processor.py:157} INFO - Started process (PID=710) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:43.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:58:43.945+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:43.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:43.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:58:43.995+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:43.995+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:58:44.024+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:58:44.024+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:58:44.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T18:59:14.266+0000] {processor.py:157} INFO - Started process (PID=718) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:14.267+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:59:14.269+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:14.269+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:14.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:14.318+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:14.318+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:59:14.347+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:14.347+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:59:14.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-09-30T18:59:44.620+0000] {processor.py:157} INFO - Started process (PID=727) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:44.622+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T18:59:44.623+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:44.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:44.639+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T18:59:44.669+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:44.669+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T18:59:44.698+0000] {logging_mixin.py:150} INFO - [2023-09-30T18:59:44.698+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T18:59:44.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-09-30T19:00:14.949+0000] {processor.py:157} INFO - Started process (PID=735) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:14.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:00:14.952+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:14.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:14.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:15.014+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:15.014+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:00:15.044+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:15.043+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:00:15.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-09-30T19:00:45.297+0000] {processor.py:157} INFO - Started process (PID=743) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:45.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:00:45.300+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:45.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:45.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:00:45.347+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:45.347+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:00:45.378+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:00:45.377+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:00:45.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-09-30T19:01:15.626+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:15.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:01:15.631+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:15.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:15.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:15.701+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:15.701+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:01:15.742+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:15.742+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:01:15.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.156 seconds
[2023-09-30T19:01:46.014+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:46.015+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:01:46.016+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:46.016+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:46.029+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:01:46.062+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:46.061+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:01:46.092+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:01:46.092+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:01:46.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-09-30T19:02:16.377+0000] {processor.py:157} INFO - Started process (PID=767) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:16.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:02:16.380+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:16.380+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:16.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:16.427+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:16.426+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:02:16.457+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:16.456+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:02:16.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.112 seconds
[2023-09-30T19:02:46.740+0000] {processor.py:157} INFO - Started process (PID=776) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:46.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:02:46.743+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:46.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:46.758+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:02:46.791+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:46.791+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:02:46.821+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:02:46.820+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:02:46.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-09-30T19:03:17.119+0000] {processor.py:157} INFO - Started process (PID=784) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:17.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:03:17.122+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:17.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:17.137+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:17.169+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:17.169+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:03:17.201+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:17.200+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:03:17.258+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-09-30T19:03:22.239+0000] {processor.py:157} INFO - Started process (PID=785) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:22.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:03:22.253+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:22.345+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag_1']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:22.555+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.555+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:web_scraping_dag_1
[2023-09-30T19:03:22.571+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.570+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:web_scraping_dag_1
[2023-09-30T19:03:22.611+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.610+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:web_scraping_dag_1
[2023-09-30T19:03:22.648+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.647+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:03:22.670+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.670+0000] {dag.py:2763} INFO - Creating ORM DAG for web_scraping_dag_1
[2023-09-30T19:03:22.685+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:22.685+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag_1 to None, run_after=None
[2023-09-30T19:03:22.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.504 seconds
[2023-09-30T19:03:34.896+0000] {processor.py:157} INFO - Started process (PID=793) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:34.900+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:03:34.902+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:34.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:34.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:03:34.975+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:34.974+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:03:35.015+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:03:35.015+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:03:35.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.184 seconds
[2023-09-30T19:04:05.229+0000] {processor.py:157} INFO - Started process (PID=801) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:05.231+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:04:05.233+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:05.233+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:05.253+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:05.290+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:05.289+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:04:05.320+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:05.320+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:04:05.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-09-30T19:04:35.636+0000] {processor.py:157} INFO - Started process (PID=809) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:35.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:04:35.638+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:35.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:35.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:04:35.691+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:35.691+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:04:35.725+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:04:35.725+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:04:35.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-09-30T19:05:06.043+0000] {processor.py:157} INFO - Started process (PID=818) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:06.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:05:06.049+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:06.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:06.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:06.099+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:06.099+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:05:06.129+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:06.129+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:05:06.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-09-30T19:05:36.382+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:36.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:05:36.385+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:36.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:36.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:05:36.440+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:36.440+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:05:36.474+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:05:36.474+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:05:36.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:06:06.700+0000] {processor.py:157} INFO - Started process (PID=834) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:06.702+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:06:06.703+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:06.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:06.717+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:06.750+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:06.749+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:06:06.780+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:06.780+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:06:06.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-09-30T19:06:37.193+0000] {processor.py:157} INFO - Started process (PID=842) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:37.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:06:37.199+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:37.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:37.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:06:37.250+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:37.250+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:06:37.288+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:06:37.288+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:06:37.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-09-30T19:07:07.519+0000] {processor.py:157} INFO - Started process (PID=850) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:07.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:07:07.524+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:07.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:07.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:07.618+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:07.618+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:07:07.648+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:07.648+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:07:07.700+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.188 seconds
[2023-09-30T19:07:37.986+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:37.988+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:07:37.990+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:37.990+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:38.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:07:38.046+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:38.046+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:07:38.080+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:07:38.079+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:07:38.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-09-30T19:08:08.330+0000] {processor.py:157} INFO - Started process (PID=867) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:08.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:08:08.337+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:08.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:08.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:08.402+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:08.402+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:08:08.431+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:08.431+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:08:08.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-09-30T19:08:38.778+0000] {processor.py:157} INFO - Started process (PID=875) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:38.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:08:38.781+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:38.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:38.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['web_scraping_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:38.827+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:38.827+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:08:38.858+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:38.858+0000] {dag.py:3508} INFO - Setting next_dagrun for web_scraping_dag to None, run_after=None
[2023-09-30T19:08:38.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-09-30T19:08:56.016+0000] {processor.py:157} INFO - Started process (PID=876) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:56.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:08:56.020+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:56.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:56.037+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:08:56.033+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:08:56.038+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:08:56.065+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.059 seconds
[2023-09-30T19:09:26.377+0000] {processor.py:157} INFO - Started process (PID=884) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:26.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:09:26.381+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:09:26.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:26.391+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:09:26.389+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:09:26.392+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:26.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.048 seconds
[2023-09-30T19:09:56.759+0000] {processor.py:157} INFO - Started process (PID=892) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:56.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:09:56.762+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:09:56.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:56.774+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:09:56.771+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:09:56.774+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:09:56.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-09-30T19:10:27.059+0000] {processor.py:157} INFO - Started process (PID=900) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:27.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:10:27.062+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:10:27.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:27.075+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:10:27.072+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:10:27.075+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:27.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-09-30T19:10:57.407+0000] {processor.py:157} INFO - Started process (PID=908) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:57.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:10:57.411+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:10:57.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:57.423+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:10:57.420+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:10:57.423+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:10:57.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-09-30T19:11:27.776+0000] {processor.py:157} INFO - Started process (PID=916) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:27.777+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:11:27.778+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:11:27.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:27.788+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:11:27.786+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:11:27.788+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:27.813+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.041 seconds
[2023-09-30T19:11:58.187+0000] {processor.py:157} INFO - Started process (PID=925) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:58.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:11:58.191+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:11:58.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:58.203+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:11:58.201+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:11:58.203+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:11:58.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.053 seconds
[2023-09-30T19:12:28.513+0000] {processor.py:157} INFO - Started process (PID=933) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:28.515+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:12:28.516+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:12:28.516+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:28.526+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:12:28.524+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:12:28.527+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:28.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-09-30T19:12:58.827+0000] {processor.py:157} INFO - Started process (PID=941) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:58.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:12:58.831+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:12:58.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:58.841+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:12:58.838+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:12:58.841+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:12:58.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-09-30T19:13:29.183+0000] {processor.py:157} INFO - Started process (PID=950) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:29.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:13:29.186+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:13:29.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:29.198+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:13:29.195+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:13:29.198+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:29.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-09-30T19:13:59.566+0000] {processor.py:157} INFO - Started process (PID=958) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:59.568+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:13:59.570+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:13:59.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:59.582+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:13:59.579+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:13:59.582+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:13:59.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.048 seconds
[2023-09-30T19:14:29.949+0000] {processor.py:157} INFO - Started process (PID=966) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:29.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:14:29.954+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:29.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:29.966+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:29.963+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_another_container). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:14:29.967+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:29.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-09-30T19:14:48.179+0000] {processor.py:157} INFO - Started process (PID=974) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:48.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:14:48.182+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:48.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:48.328+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.328+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:webscrape_dag
[2023-09-30T19:14:48.342+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.342+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:webscrape_dag
[2023-09-30T19:14:48.353+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.352+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:webscrape_dag
[2023-09-30T19:14:48.370+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.370+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:14:48.384+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.384+0000] {dag.py:2763} INFO - Creating ORM DAG for webscrape_dag
[2023-09-30T19:14:48.399+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:48.399+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:14:48.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.252 seconds
[2023-09-30T19:14:53.292+0000] {processor.py:157} INFO - Started process (PID=975) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:53.294+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:14:53.296+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:53.295+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:53.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:14:53.330+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:53.330+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:14:53.360+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:14:53.359+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:14:53.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-09-30T19:15:23.688+0000] {processor.py:157} INFO - Started process (PID=983) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:23.691+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:15:23.694+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:23.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:23.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:23.755+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:23.755+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:15:23.784+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:23.784+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:15:23.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-09-30T19:15:54.026+0000] {processor.py:157} INFO - Started process (PID=991) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:54.027+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:15:54.029+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:54.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:54.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:15:54.074+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:54.074+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:15:54.105+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:15:54.105+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:15:54.130+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-09-30T19:16:24.520+0000] {processor.py:157} INFO - Started process (PID=999) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:24.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:16:24.524+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:24.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:24.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:24.578+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:24.578+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:16:24.616+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:24.615+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:16:24.640+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-09-30T19:16:54.840+0000] {processor.py:157} INFO - Started process (PID=1007) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:54.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:16:54.843+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:54.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:54.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:16:54.901+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:54.901+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:16:54.933+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:16:54.932+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:16:54.957+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-09-30T19:17:25.255+0000] {processor.py:157} INFO - Started process (PID=1015) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:25.256+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:17:25.259+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:25.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:25.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:25.309+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:25.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:17:25.340+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:25.340+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:17:25.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T19:17:55.590+0000] {processor.py:157} INFO - Started process (PID=1023) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:55.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:17:55.595+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:55.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:55.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:17:55.652+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:55.651+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:17:55.684+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:17:55.683+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:17:55.714+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-09-30T19:18:25.918+0000] {processor.py:157} INFO - Started process (PID=1031) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:25.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:18:25.922+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:25.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:25.939+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:25.976+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:25.975+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:18:26.014+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:26.014+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:18:26.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-09-30T19:18:56.314+0000] {processor.py:157} INFO - Started process (PID=1040) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:56.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:18:56.320+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:56.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:56.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:18:56.372+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:56.372+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:18:56.402+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:18:56.402+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:18:56.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-09-30T19:19:26.666+0000] {processor.py:157} INFO - Started process (PID=1048) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:26.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:19:26.671+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:26.670+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:26.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:26.724+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:26.723+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:19:26.754+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:26.754+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:19:26.789+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-09-30T19:19:29.793+0000] {processor.py:157} INFO - Started process (PID=1049) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:29.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:19:29.797+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:29.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:29.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:29.971+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:29.970+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:19:30.003+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:30.003+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:19:30.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.254 seconds
[2023-09-30T19:19:34.920+0000] {processor.py:157} INFO - Started process (PID=1057) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:34.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:19:34.929+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:34.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:34.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:19:35.007+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:35.007+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:19:35.059+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:19:35.058+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:19:35.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.206 seconds
[2023-09-30T19:20:05.415+0000] {processor.py:157} INFO - Started process (PID=1066) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:05.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:20:05.419+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:05.419+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:05.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:05.472+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:05.471+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:20:05.502+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:05.502+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:20:05.555+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-09-30T19:20:35.766+0000] {processor.py:157} INFO - Started process (PID=1074) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:35.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:20:35.769+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:35.769+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:35.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:20:35.819+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:35.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:20:35.849+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:20:35.849+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:20:35.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-09-30T19:21:06.215+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:06.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:21:06.220+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:06.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:06.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:06.296+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:06.296+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:21:06.342+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:06.342+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:21:06.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-09-30T19:21:36.518+0000] {processor.py:157} INFO - Started process (PID=1090) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:36.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:21:36.527+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:36.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:36.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:21:36.611+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:36.611+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:21:36.679+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:21:36.679+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:21:36.729+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.221 seconds
[2023-09-30T19:22:07.038+0000] {processor.py:157} INFO - Started process (PID=1098) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:07.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:22:07.042+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:07.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:07.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:07.090+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:07.090+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:22:07.119+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:07.119+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:22:07.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-09-30T19:22:37.362+0000] {processor.py:157} INFO - Started process (PID=1106) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:37.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:22:37.366+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:37.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:37.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:22:37.425+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:37.425+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:22:37.456+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:22:37.456+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:22:37.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-09-30T19:23:07.745+0000] {processor.py:157} INFO - Started process (PID=1114) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:07.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:23:07.747+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:07.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:07.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:07.801+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:07.801+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:23:07.834+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:07.834+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:23:07.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T19:23:38.092+0000] {processor.py:157} INFO - Started process (PID=1123) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:38.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:23:38.095+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:38.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:38.110+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:23:38.148+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:38.147+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:23:38.182+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:23:38.182+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:23:38.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-09-30T19:24:08.449+0000] {processor.py:157} INFO - Started process (PID=1131) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:08.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:24:08.454+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:08.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:08.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:08.517+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:08.516+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:24:08.550+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:08.549+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:24:08.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-09-30T19:24:38.806+0000] {processor.py:157} INFO - Started process (PID=1139) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:38.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:24:38.810+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:38.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:38.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:24:38.898+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:38.897+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:24:38.951+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:24:38.951+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:24:38.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.177 seconds
[2023-09-30T19:25:09.155+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:09.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:25:09.160+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:09.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:09.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:09.228+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:09.228+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:25:09.269+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:09.269+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:25:09.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-09-30T19:25:39.602+0000] {processor.py:157} INFO - Started process (PID=1156) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:39.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:25:39.605+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:39.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:39.617+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:25:39.649+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:39.649+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:25:39.692+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:25:39.691+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:25:39.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-09-30T19:26:09.966+0000] {processor.py:157} INFO - Started process (PID=1164) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:09.968+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:26:09.971+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:09.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:09.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:10.023+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:10.023+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:26:10.054+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:10.054+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:26:10.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-09-30T19:26:40.381+0000] {processor.py:157} INFO - Started process (PID=1172) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:40.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:26:40.385+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:40.384+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:40.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:26:40.432+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:40.432+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:26:40.466+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:26:40.465+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:26:40.489+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T19:27:10.732+0000] {processor.py:157} INFO - Started process (PID=1180) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:10.734+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:27:10.736+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:10.736+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:10.751+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:10.785+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:10.785+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:27:10.815+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:10.814+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:27:10.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T19:27:41.090+0000] {processor.py:157} INFO - Started process (PID=1188) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:41.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:27:41.096+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:41.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:41.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:27:41.193+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:41.192+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:27:41.221+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:27:41.221+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:27:41.245+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.172 seconds
[2023-09-30T19:28:11.482+0000] {processor.py:157} INFO - Started process (PID=1196) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:11.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:28:11.491+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:11.490+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:11.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:11.549+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:11.549+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:28:11.579+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:11.579+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:28:11.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-09-30T19:28:41.852+0000] {processor.py:157} INFO - Started process (PID=1204) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:41.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:28:41.857+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:41.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:41.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:28:41.917+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:41.917+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:28:41.947+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:28:41.947+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:28:41.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-09-30T19:29:12.247+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:12.250+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:29:12.252+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:12.252+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:12.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:12.309+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:12.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:29:12.341+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:12.341+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:29:12.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-09-30T19:29:42.574+0000] {processor.py:157} INFO - Started process (PID=1220) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:42.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:29:42.579+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:42.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:42.596+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:29:42.636+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:42.636+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:29:42.673+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:29:42.672+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:29:42.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.186 seconds
[2023-09-30T19:30:13.053+0000] {processor.py:157} INFO - Started process (PID=1228) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:13.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:30:13.060+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:13.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:13.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:13.127+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:13.127+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:30:13.161+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:13.160+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:30:13.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-09-30T19:30:43.440+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:43.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:30:43.445+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:43.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:43.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:30:43.501+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:43.501+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:30:43.539+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:30:43.538+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:30:43.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-09-30T19:31:13.792+0000] {processor.py:157} INFO - Started process (PID=1244) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:13.794+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:31:13.796+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:13.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:13.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:13.847+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:13.846+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:31:13.879+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:13.879+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:31:13.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T19:31:44.282+0000] {processor.py:157} INFO - Started process (PID=1253) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:44.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:31:44.286+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:44.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:44.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:31:44.332+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:44.331+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:31:44.361+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:31:44.360+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:31:44.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-09-30T19:32:14.613+0000] {processor.py:157} INFO - Started process (PID=1261) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:14.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:32:14.617+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:14.616+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:14.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:14.685+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:14.684+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:32:14.728+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:14.728+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:32:14.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-09-30T19:32:45.007+0000] {processor.py:157} INFO - Started process (PID=1269) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:45.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:32:45.010+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:45.009+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:45.024+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:32:45.056+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:45.056+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:32:45.086+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:32:45.085+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:32:45.119+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T19:33:15.372+0000] {processor.py:157} INFO - Started process (PID=1277) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:15.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:33:15.374+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:15.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:15.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:15.417+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:15.417+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:33:15.458+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:15.458+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:33:15.508+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-09-30T19:33:45.667+0000] {processor.py:157} INFO - Started process (PID=1285) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:45.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:33:45.670+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:45.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:45.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:33:45.724+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:45.724+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:33:45.758+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:33:45.758+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:33:45.784+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:34:15.977+0000] {processor.py:157} INFO - Started process (PID=1293) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:34:15.979+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:34:15.981+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:34:15.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:34:16.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:34:16.146+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:34:16.145+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:37:47.515+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:37:47.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:37:47.535+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:37:47.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:37:47.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:37:48.375+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:37:48.375+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:37:48.423+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:37:48.423+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:37:48.462+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.973 seconds
[2023-09-30T19:38:18.716+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:18.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:38:18.724+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:18.723+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:18.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:18.814+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:18.814+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:38:18.844+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:18.844+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:38:18.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-09-30T19:38:49.060+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:49.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:38:49.064+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:49.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:49.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:38:49.118+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:49.118+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:38:49.146+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:38:49.146+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:38:49.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-09-30T19:39:19.433+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:19.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:39:19.436+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:19.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:19.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:19.482+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:19.482+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:39:19.512+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:19.511+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:39:19.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.107 seconds
[2023-09-30T19:39:49.738+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:49.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:39:49.743+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:49.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:49.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:39:49.799+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:49.799+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:39:49.832+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:39:49.832+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:39:49.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-09-30T19:40:20.138+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:20.141+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:40:20.144+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:20.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:20.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:20.194+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:20.193+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:40:20.223+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:20.223+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:40:20.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:40:50.496+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:50.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:40:50.500+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:50.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:50.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:40:50.548+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:50.548+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:40:50.576+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:40:50.575+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:40:50.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-09-30T19:41:20.814+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:20.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:41:20.817+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:20.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:20.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:20.870+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:20.870+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:41:20.900+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:20.900+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:41:20.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T19:41:51.186+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:51.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:41:51.195+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:51.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:51.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:41:51.284+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:51.284+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:41:51.322+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:41:51.322+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:41:51.381+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.208 seconds
[2023-09-30T19:42:21.494+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:21.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:42:21.498+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:21.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:21.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:21.545+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:21.545+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:42:21.577+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:21.577+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:42:21.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-09-30T19:42:51.836+0000] {processor.py:157} INFO - Started process (PID=128) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:51.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:42:51.841+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:51.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:51.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:42:51.896+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:51.895+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:42:51.926+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:42:51.926+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:42:51.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:43:22.249+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:22.253+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:43:22.257+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:22.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:22.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:22.314+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:22.314+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:43:22.344+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:22.344+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:43:22.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-09-30T19:43:52.549+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:52.551+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:43:52.553+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:52.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:52.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:43:52.613+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:52.613+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:43:52.645+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:43:52.645+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:43:52.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T19:44:22.982+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:22.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:44:22.985+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:22.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:23.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['webscrape_dag']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:23.033+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:23.032+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:44:23.061+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:23.061+0000] {dag.py:3508} INFO - Setting next_dagrun for webscrape_dag to None, run_after=None
[2023-09-30T19:44:23.083+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.107 seconds
[2023-09-30T19:44:44.236+0000] {processor.py:157} INFO - Started process (PID=153) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:44.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:44:44.241+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:44.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:44.259+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:44.255+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 28, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock', '/path/to/host/folder:/path/in/container']}
[2023-09-30T19:44:44.260+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:44.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.078 seconds
[2023-09-30T19:44:51.364+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:51.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:44:51.367+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:51.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:51.381+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:51.379+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:44:51.382+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:51.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.062 seconds
[2023-09-30T19:44:56.470+0000] {processor.py:157} INFO - Started process (PID=161) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:56.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:44:56.473+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:56.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:56.489+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:44:56.486+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:44:56.489+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:44:56.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-09-30T19:45:01.590+0000] {processor.py:157} INFO - Started process (PID=162) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:01.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:45:01.603+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:45:01.601+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:01.660+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:45:01.648+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:45:01.662+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:01.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-09-30T19:45:31.916+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:31.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:45:31.920+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:45:31.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:31.937+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:45:31.933+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:45:31.938+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:45:31.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.064 seconds
[2023-09-30T19:46:02.335+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:02.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:46:02.338+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:02.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:02.350+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:02.347+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:46:02.350+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:02.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-09-30T19:46:32.652+0000] {processor.py:157} INFO - Started process (PID=186) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:32.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:46:32.659+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:32.658+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:32.687+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:32.682+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:46:32.688+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:32.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.085 seconds
[2023-09-30T19:46:44.793+0000] {processor.py:157} INFO - Started process (PID=194) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:44.795+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:46:44.797+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:44.796+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:44.816+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:46:44.812+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:46:44.817+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:46:44.846+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.064 seconds
[2023-09-30T19:47:15.167+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:15.169+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:47:15.171+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:47:15.170+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:15.182+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:47:15.180+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:47:15.183+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:15.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.045 seconds
[2023-09-30T19:47:45.524+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:45.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:47:45.533+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:47:45.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:45.546+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:47:45.543+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:47:45.547+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:47:45.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.061 seconds
[2023-09-30T19:48:15.885+0000] {processor.py:157} INFO - Started process (PID=219) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:15.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:48:15.889+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:15.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:15.901+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:15.898+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 27, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/var/run/docker.sock:/var/run/docker.sock']}
[2023-09-30T19:48:15.901+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:15.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-09-30T19:48:30.060+0000] {processor.py:157} INFO - Started process (PID=220) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:30.062+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:48:30.065+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.064+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:30.095+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:48:30.440+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.440+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:trigger_script_in_docker
[2023-09-30T19:48:30.469+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.469+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:trigger_script_in_docker
[2023-09-30T19:48:30.486+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.485+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:trigger_script_in_docker
[2023-09-30T19:48:30.514+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.514+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:48:30.535+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.535+0000] {dag.py:2763} INFO - Creating ORM DAG for trigger_script_in_docker
[2023-09-30T19:48:30.558+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:48:30.557+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:48:30.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.539 seconds
[2023-09-30T19:49:00.911+0000] {processor.py:157} INFO - Started process (PID=228) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:00.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:49:00.916+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:00.915+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:00.936+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:00.971+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:00.971+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:49:01.000+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:01.000+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:49:01.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-09-30T19:49:31.250+0000] {processor.py:157} INFO - Started process (PID=235) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:31.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:49:31.257+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:31.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:31.278+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:49:31.309+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:31.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:49:31.342+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:49:31.342+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:49:31.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-09-30T19:50:01.611+0000] {processor.py:157} INFO - Started process (PID=243) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:01.613+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:50:01.616+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:01.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:01.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:01.666+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:01.666+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:50:01.696+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:01.696+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:50:01.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T19:50:31.932+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:31.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:50:31.936+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:31.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:31.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:50:31.997+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:31.996+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:50:32.025+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:50:32.025+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:50:32.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-09-30T19:51:02.325+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:02.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:51:02.332+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:02.331+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:02.353+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:02.385+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:02.385+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:51:02.415+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:02.415+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:51:02.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-09-30T19:51:32.587+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:32.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:51:32.590+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:32.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:32.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:51:32.639+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:32.638+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:51:32.671+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:51:32.671+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:51:32.693+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.112 seconds
[2023-09-30T19:52:02.989+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:02.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:52:02.993+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:02.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:03.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:03.045+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:03.044+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:52:03.074+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:03.074+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:52:03.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T19:52:33.321+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:33.322+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:52:33.324+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:33.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:33.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:52:33.374+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:33.374+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:52:33.404+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:52:33.404+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:52:33.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-09-30T19:53:03.697+0000] {processor.py:157} INFO - Started process (PID=292) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:03.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:53:03.700+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:03.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:03.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:03.750+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:03.750+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:53:03.782+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:03.782+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:53:03.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-09-30T19:53:34.060+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:34.061+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:53:34.064+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:34.063+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:34.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:53:34.111+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:34.111+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:53:34.143+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:53:34.143+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:53:34.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-09-30T19:54:04.413+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:04.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:54:04.418+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:04.417+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:04.435+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:04.476+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:04.475+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:54:04.507+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:04.507+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:54:04.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-09-30T19:54:34.785+0000] {processor.py:157} INFO - Started process (PID=317) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:34.787+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:54:34.789+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:34.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:34.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:54:34.847+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:34.847+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:54:34.876+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:54:34.875+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:54:34.899+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:55:05.107+0000] {processor.py:157} INFO - Started process (PID=325) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:05.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:55:05.111+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:05.110+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:05.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:05.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:05.164+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:55:05.197+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:05.196+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:55:05.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T19:55:35.501+0000] {processor.py:157} INFO - Started process (PID=332) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:35.502+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:55:35.504+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:35.504+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:35.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:55:35.555+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:35.555+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:55:35.585+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:55:35.585+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:55:35.608+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T19:58:04.439+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:04.442+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:58:04.445+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:04.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:04.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:04.869+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:04.869+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:58:04.912+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:04.912+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:58:04.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.516 seconds
[2023-09-30T19:58:35.340+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:35.345+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:58:35.350+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:35.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:35.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:58:35.591+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:35.591+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:58:35.692+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:58:35.692+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:58:35.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.451 seconds
[2023-09-30T19:59:05.992+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:05.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:59:05.996+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:05.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:06.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:06.094+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:06.094+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:59:06.154+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:06.154+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:59:06.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.232 seconds
[2023-09-30T19:59:36.317+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:36.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T19:59:36.323+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:36.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:36.342+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T19:59:36.376+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:36.376+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T19:59:36.409+0000] {logging_mixin.py:150} INFO - [2023-09-30T19:59:36.409+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T19:59:36.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-09-30T20:00:06.605+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:06.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:00:06.609+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:06.608+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:06.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:06.668+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:06.668+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:00:06.729+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:06.728+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:00:06.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-09-30T20:00:36.995+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:36.997+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:00:36.999+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:36.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:37.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:00:37.058+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:37.058+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:00:37.113+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:00:37.113+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:00:37.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.198 seconds
[2023-09-30T20:01:07.411+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:07.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:01:07.416+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:07.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:07.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:07.483+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:07.482+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:01:07.511+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:07.511+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:01:07.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T20:01:37.840+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:37.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:01:37.846+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:37.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:37.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:01:37.904+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:37.904+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:01:37.935+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:01:37.935+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:01:38.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.187 seconds
[2023-09-30T20:02:08.207+0000] {processor.py:157} INFO - Started process (PID=118) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:08.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:02:08.226+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:08.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:08.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:08.301+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:08.301+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:02:08.330+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:08.330+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:02:08.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-09-30T20:02:38.599+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:38.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:02:38.603+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:38.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:38.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:02:38.655+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:38.655+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:02:38.685+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:02:38.685+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:02:38.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T20:03:09.020+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:09.025+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:03:09.034+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:09.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:09.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:09.166+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:09.166+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:03:09.243+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:09.242+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:03:09.276+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.276 seconds
[2023-09-30T20:03:39.361+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:39.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:03:39.366+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:39.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:39.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:03:39.418+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:39.418+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:03:39.448+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:03:39.448+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:03:39.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T20:04:09.627+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:09.628+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:04:09.629+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:09.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:09.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:09.676+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:09.675+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:04:09.707+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:09.707+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:04:09.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:04:39.916+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:39.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:04:39.919+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:39.919+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:39.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:04:39.973+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:39.973+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:04:40.004+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:04:40.004+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:04:40.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T20:05:10.355+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:10.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:05:10.360+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:10.359+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:10.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:10.421+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:10.421+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:05:10.451+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:10.451+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:05:10.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T20:05:40.685+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:40.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:05:40.690+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:40.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:40.706+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:05:40.740+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:40.740+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:05:40.771+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:05:40.771+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:05:40.799+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-09-30T20:06:11.088+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:11.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:06:11.092+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:11.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:11.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:11.171+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:11.171+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:06:11.215+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:11.215+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:06:11.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-09-30T20:06:41.358+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:41.361+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:06:41.363+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:41.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:41.389+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:06:41.429+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:41.429+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:06:41.459+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:06:41.459+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:06:41.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T20:07:11.738+0000] {processor.py:157} INFO - Started process (PID=199) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:11.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:07:11.741+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:11.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:11.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:11.787+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:11.787+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:07:11.817+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:11.817+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:07:11.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.105 seconds
[2023-09-30T20:07:42.090+0000] {processor.py:157} INFO - Started process (PID=207) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:42.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:07:42.097+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:42.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:42.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:07:42.152+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:42.152+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:07:42.181+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:07:42.181+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:07:42.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-09-30T20:08:12.484+0000] {processor.py:157} INFO - Started process (PID=215) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:12.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:08:12.488+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:12.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:12.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:12.538+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:12.537+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:08:12.568+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:12.567+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:08:12.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.112 seconds
[2023-09-30T20:08:42.813+0000] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:42.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:08:42.818+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:42.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:42.837+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:08:42.885+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:42.885+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:08:42.921+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:08:42.921+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:08:42.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-09-30T20:09:13.214+0000] {processor.py:157} INFO - Started process (PID=231) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:13.216+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:09:13.218+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:13.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:13.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:13.274+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:13.274+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:09:13.304+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:13.304+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:09:13.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-09-30T20:09:43.588+0000] {processor.py:157} INFO - Started process (PID=239) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:43.591+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:09:43.594+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:43.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:43.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:09:43.646+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:43.646+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:09:43.675+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:09:43.675+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:09:43.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T20:12:42.280+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:12:42.283+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:12:42.285+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:12:42.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:12:42.321+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:12:42.402+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:12:42.401+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:12:42.446+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:12:42.445+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:12:42.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.204 seconds
[2023-09-30T20:13:12.591+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:12.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:13:12.594+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:12.593+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:12.611+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:12.645+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:12.645+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:13:12.674+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:12.674+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:13:12.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-09-30T20:13:42.865+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:42.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:13:42.867+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:42.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:42.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:13:42.919+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:42.919+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:13:42.956+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:13:42.956+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:13:43.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-09-30T20:14:13.071+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:13.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:14:13.075+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:13.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:13.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:13.418+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:13.417+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:14:13.458+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:13.458+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:14:13.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.430 seconds
[2023-09-30T20:14:43.673+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:43.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:14:43.678+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:43.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:43.705+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:14:43.778+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:43.777+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:14:43.857+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:14:43.857+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:14:43.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.244 seconds
[2023-09-30T20:15:14.100+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:14.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:15:14.104+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:14.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:14.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:14.151+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:14.151+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:15:14.179+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:14.178+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:15:14.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-09-30T20:15:44.258+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:44.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:15:44.261+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:44.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:44.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:15:44.344+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:44.344+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:15:44.395+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:15:44.395+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:15:44.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.178 seconds
[2023-09-30T20:16:14.517+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:14.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:16:14.520+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:14.520+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:14.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:14.608+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:14.607+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:16:14.681+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:14.681+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:16:14.713+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.201 seconds
[2023-09-30T20:16:44.787+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:44.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:16:44.812+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:44.812+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:44.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:16:45.022+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:45.021+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:16:45.123+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:16:45.122+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:16:45.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.418 seconds
[2023-09-30T20:17:15.411+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:15.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:17:15.414+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:15.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:15.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:15.582+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:15.581+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:17:15.611+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:15.611+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:17:15.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.231 seconds
[2023-09-30T20:17:45.853+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:45.854+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:17:45.855+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:45.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:45.869+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:17:45.901+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:45.900+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:17:45.930+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:17:45.930+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:17:45.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.106 seconds
[2023-09-30T20:18:16.072+0000] {processor.py:157} INFO - Started process (PID=127) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:16.073+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:18:16.075+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:16.074+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:16.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:16.126+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:16.126+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:18:16.157+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:16.157+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:18:16.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-09-30T20:18:46.379+0000] {processor.py:157} INFO - Started process (PID=135) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:46.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:18:46.383+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:46.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:46.398+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:18:46.429+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:46.429+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:18:46.458+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:18:46.457+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:18:46.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-09-30T20:19:16.621+0000] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:16.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:19:16.625+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:16.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:16.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:16.673+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:16.672+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:19:16.704+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:16.704+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:19:16.732+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T20:19:46.938+0000] {processor.py:157} INFO - Started process (PID=151) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:46.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:19:46.941+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:46.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:46.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:19:46.989+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:46.988+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:19:47.018+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:19:47.018+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:19:47.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:20:17.179+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:17.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:20:17.181+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:17.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:17.198+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:17.232+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:17.232+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:20:17.262+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:17.262+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:20:17.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:20:47.483+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:47.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:20:47.486+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:47.485+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:47.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:20:47.535+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:47.535+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:20:47.565+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:20:47.564+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:20:47.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:21:17.683+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:17.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:21:17.686+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:17.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:17.704+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:17.953+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:17.952+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:21:17.997+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:17.997+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:21:18.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.362 seconds
[2023-09-30T20:21:48.227+0000] {processor.py:157} INFO - Started process (PID=182) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:48.228+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:21:48.230+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:48.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:48.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:21:48.291+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:48.290+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:21:48.325+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:21:48.325+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:21:48.353+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-09-30T20:22:18.429+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:18.431+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:22:18.434+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:18.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:18.466+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:18.535+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:18.534+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:22:18.591+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:18.591+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:22:18.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.247 seconds
[2023-09-30T20:22:48.878+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:48.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:22:48.882+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:48.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:48.912+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:22:49.081+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:49.081+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:22:49.113+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:22:49.113+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:22:49.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.273 seconds
[2023-09-30T20:23:19.294+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:19.296+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:23:19.297+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:19.297+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:19.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:19.343+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:19.342+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:23:19.371+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:19.371+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:23:19.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.104 seconds
[2023-09-30T20:23:49.481+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:49.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:23:49.483+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:49.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:49.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:23:49.529+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:49.529+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:23:49.560+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:23:49.560+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:23:49.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:24:19.767+0000] {processor.py:157} INFO - Started process (PID=223) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:24:19.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:24:19.772+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:24:19.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:24:19.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:24:19.831+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:24:19.831+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:24:19.869+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:24:19.869+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:24:19.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-09-30T20:25:52.803+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:25:52.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:25:52.807+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:25:52.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:25:52.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:25:53.093+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:25:53.093+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:25:53.131+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:25:53.131+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:25:53.166+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.369 seconds
[2023-09-30T20:26:23.448+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:23.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:26:23.476+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:23.471+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:23.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:23.752+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:23.752+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:26:23.809+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:23.809+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:26:23.835+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.453 seconds
[2023-09-30T20:26:54.158+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:54.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:26:54.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:54.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:54.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:26:54.218+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:54.218+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:26:54.248+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:26:54.248+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:26:54.271+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-09-30T20:27:24.459+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:24.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:27:24.465+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:24.464+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:24.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:24.524+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:24.524+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:27:24.554+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:24.554+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:27:24.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-09-30T20:27:54.827+0000] {processor.py:157} INFO - Started process (PID=69) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:54.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:27:54.830+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:54.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:54.856+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:27:54.914+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:54.913+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:27:54.979+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:27:54.977+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:27:55.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.219 seconds
[2023-09-30T20:28:25.171+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:25.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:28:25.181+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:25.180+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:25.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:25.230+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:25.229+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:28:25.259+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:25.259+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:28:25.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-09-30T20:28:55.467+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:55.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:28:55.471+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:55.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:55.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:28:55.564+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:55.563+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:28:55.639+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:28:55.638+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:28:55.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.232 seconds
[2023-09-30T20:43:47.366+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:43:47.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:43:47.372+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:43:47.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:43:47.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:43:48.064+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:43:48.064+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:43:48.160+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:43:48.160+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:43:48.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.854 seconds
[2023-09-30T20:44:18.456+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:18.463+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:44:18.464+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:18.464+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:18.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:18.526+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:18.526+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:44:18.570+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:18.569+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:44:18.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-09-30T20:44:48.769+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:48.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:44:48.772+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:48.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:48.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:44:48.855+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:48.855+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:44:48.905+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:44:48.904+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:44:48.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.168 seconds
[2023-09-30T20:45:19.159+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:19.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:45:19.162+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:19.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:19.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:19.212+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:19.212+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:45:19.248+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:19.248+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:45:19.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-09-30T20:45:49.453+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:49.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:45:49.457+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:49.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:49.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:45:49.511+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:49.511+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:45:49.540+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:45:49.540+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:45:49.564+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T20:46:19.859+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:19.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:46:19.864+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:19.863+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:19.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:19.918+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:19.918+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:46:19.949+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:19.949+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:46:19.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-09-30T20:46:50.154+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:50.156+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:46:50.158+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:50.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:50.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:46:50.213+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:50.213+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:46:50.244+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:46:50.244+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:46:50.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-09-30T20:47:20.521+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:20.522+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:47:20.524+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:20.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:20.539+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:20.571+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:20.571+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:47:20.602+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:20.602+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:47:20.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-09-30T20:47:50.876+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:50.878+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:47:50.879+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:50.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:50.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:50.928+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:50.927+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:47:50.956+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:50.956+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:47:50.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T20:47:59.975+0000] {processor.py:157} INFO - Started process (PID=116) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:47:59.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:47:59.979+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:47:59.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:48:00.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:48:00.086+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:48:00.086+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:48:00.143+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:48:00.142+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:48:00.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.211 seconds
[2023-09-30T20:48:06.114+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:48:06.116+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:48:06.117+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:48:06.117+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:48:06.131+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:48:06.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:48:06.163+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:48:06.205+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:48:06.205+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:48:06.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-09-30T20:49:57.827+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:49:57.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:49:57.847+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:49:57.846+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:49:58.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:49:58.814+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:49:58.814+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:49:58.898+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:49:58.898+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:49:58.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.219 seconds
[2023-09-30T20:51:39.657+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:51:39.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:51:39.664+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:51:39.663+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:51:39.725+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:51:40.673+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:51:40.673+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:51:40.731+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:51:40.731+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:51:40.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.153 seconds
[2023-09-30T20:52:11.537+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:11.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:52:11.594+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:11.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:12.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:12.595+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:12.595+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:52:12.733+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:12.733+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:52:12.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.426 seconds
[2023-09-30T20:52:43.205+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:43.207+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:52:43.209+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:43.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:43.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:52:43.286+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:43.285+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:52:43.338+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:52:43.338+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:52:43.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-09-30T20:53:13.459+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:13.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:53:13.469+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:13.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:13.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:13.565+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:13.565+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:53:13.609+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:13.609+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:53:13.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.190 seconds
[2023-09-30T20:53:43.951+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:43.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:53:43.965+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:43.964+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:44.015+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:53:44.070+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:44.070+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:53:44.116+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:53:44.116+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:53:44.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.228 seconds
[2023-09-30T20:54:14.369+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:14.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:54:14.375+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:14.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:14.392+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:14.430+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:14.430+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:54:14.464+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:14.463+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:54:14.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T20:54:44.677+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:44.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:54:44.680+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:44.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:44.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:54:44.732+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:44.731+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:54:44.763+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:54:44.763+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:54:44.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-09-30T20:55:15.113+0000] {processor.py:157} INFO - Started process (PID=105) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:55:15.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:55:15.115+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:55:15.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:55:15.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:55:15.164+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:55:15.164+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:55:15.197+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:55:15.197+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:55:15.221+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-09-30T20:56:59.060+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:56:59.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:56:59.155+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:56:59.142+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:56:59.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:57:00.190+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:57:00.189+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:57:00.235+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:57:00.235+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:57:00.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.279 seconds
[2023-09-30T20:57:30.734+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:57:30.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:57:30.768+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:57:30.764+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:57:31.022+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:57:31.737+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:57:31.737+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:57:32.121+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:57:32.120+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:57:32.236+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.685 seconds
[2023-09-30T20:58:02.921+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:02.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:58:02.959+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:02.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:03.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:03.751+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:03.750+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:58:03.910+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:03.910+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:58:04.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.199 seconds
[2023-09-30T20:58:34.265+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:34.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:58:34.273+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:34.273+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:34.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:58:34.800+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:34.799+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:58:35.012+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:58:35.012+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:58:35.056+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.812 seconds
[2023-09-30T20:59:05.351+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:05.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:59:05.359+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:05.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:05.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:05.483+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:05.483+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:59:05.558+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:05.558+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:59:05.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.269 seconds
[2023-09-30T20:59:35.788+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:35.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T20:59:35.793+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:35.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:35.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T20:59:35.861+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:35.861+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T20:59:35.906+0000] {logging_mixin.py:150} INFO - [2023-09-30T20:59:35.905+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T20:59:35.953+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-09-30T21:00:06.040+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:06.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:00:06.044+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:06.043+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:06.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:06.100+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:06.099+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:00:06.135+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:06.135+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:00:06.163+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-09-30T21:00:36.310+0000] {processor.py:157} INFO - Started process (PID=109) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:36.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:00:36.321+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:36.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:36.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:00:36.399+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:36.399+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:00:36.437+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:00:36.436+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:00:36.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.189 seconds
[2023-09-30T21:01:06.755+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:06.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:01:06.759+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:06.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:06.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:06.812+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:06.812+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:01:06.844+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:06.844+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:01:06.870+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T21:01:37.057+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:37.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:01:37.060+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:37.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:37.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:01:37.112+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:37.111+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:01:37.147+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:01:37.146+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:01:37.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-09-30T21:02:07.589+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:07.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:02:07.624+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:07.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:07.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:07.697+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:07.696+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:02:07.735+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:07.735+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:02:07.763+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.181 seconds
[2023-09-30T21:02:37.938+0000] {processor.py:157} INFO - Started process (PID=141) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:37.941+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:02:37.945+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:37.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:37.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:02:38.003+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:38.002+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:02:38.035+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:02:38.035+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:02:38.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-09-30T21:03:08.329+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:08.330+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:03:08.332+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:08.332+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:08.348+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:08.383+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:08.382+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:03:08.415+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:08.415+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:03:08.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T21:03:38.629+0000] {processor.py:157} INFO - Started process (PID=157) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:38.630+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:03:38.633+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:38.632+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:38.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:03:38.697+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:38.697+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:03:38.739+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:03:38.738+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:03:38.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-09-30T21:04:09.016+0000] {processor.py:157} INFO - Started process (PID=165) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:09.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:04:09.020+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:09.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:09.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:09.075+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:09.075+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:04:09.108+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:09.108+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:04:09.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-09-30T21:04:39.305+0000] {processor.py:157} INFO - Started process (PID=172) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:39.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:04:39.308+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:39.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:39.324+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:04:39.359+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:39.359+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:04:39.391+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:04:39.391+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:04:39.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-09-30T21:05:09.637+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:09.641+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:05:09.642+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:09.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:09.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:09.716+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:09.715+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:05:09.761+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:09.761+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:05:09.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-09-30T21:05:39.969+0000] {processor.py:157} INFO - Started process (PID=189) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:39.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:05:39.975+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:39.974+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:40.007+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:05:40.065+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:40.065+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:05:40.100+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:05:40.100+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:05:40.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-09-30T21:06:10.341+0000] {processor.py:157} INFO - Started process (PID=197) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:10.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:06:10.345+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:10.345+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:10.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:10.406+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:10.406+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:06:10.442+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:10.442+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:06:10.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-09-30T21:06:40.631+0000] {processor.py:157} INFO - Started process (PID=205) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:40.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:06:40.636+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:40.636+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:40.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:06:40.692+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:40.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:06:40.722+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:06:40.722+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:06:40.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-09-30T21:07:11.002+0000] {processor.py:157} INFO - Started process (PID=213) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:11.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:07:11.007+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:11.006+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:11.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:11.058+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:11.058+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:07:11.092+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:11.092+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:07:11.116+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-09-30T21:07:41.309+0000] {processor.py:157} INFO - Started process (PID=221) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:41.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:07:41.311+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:41.311+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:41.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:07:41.363+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:41.363+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:07:41.396+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:07:41.396+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:07:41.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T21:08:11.748+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:11.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:08:11.756+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:11.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:11.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:11.882+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:11.882+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:08:11.932+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:11.932+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:08:11.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.234 seconds
[2023-09-30T21:08:42.088+0000] {processor.py:157} INFO - Started process (PID=238) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:42.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:08:42.091+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:42.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:42.108+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:08:42.147+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:42.147+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:08:42.179+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:08:42.179+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:08:42.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-09-30T21:09:12.410+0000] {processor.py:157} INFO - Started process (PID=247) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:12.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:09:12.413+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:12.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:12.433+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:12.472+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:12.472+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:09:12.506+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:12.505+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:09:12.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-09-30T21:09:34.734+0000] {processor.py:157} INFO - Started process (PID=255) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:34.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:09:34.739+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:34.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:34.764+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:09:34.817+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:34.817+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:09:34.864+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:09:34.863+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:09:34.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-09-30T21:10:05.087+0000] {processor.py:157} INFO - Started process (PID=263) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:05.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:10:05.092+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:05.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:05.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:05.157+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:05.156+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:10:05.189+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:05.188+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:10:05.212+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T21:10:35.482+0000] {processor.py:157} INFO - Started process (PID=271) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:35.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:10:35.487+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:35.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:35.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:10:35.584+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:35.584+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:10:35.647+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:10:35.647+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:10:35.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.233 seconds
[2023-09-30T21:11:05.819+0000] {processor.py:157} INFO - Started process (PID=279) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:05.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:11:05.824+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:05.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:05.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:05.883+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:05.883+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:11:05.918+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:05.917+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:11:05.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T21:11:36.179+0000] {processor.py:157} INFO - Started process (PID=287) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:36.182+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:11:36.184+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:36.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:36.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:11:36.237+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:36.237+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:11:36.270+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:11:36.270+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:11:36.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-09-30T21:12:06.637+0000] {processor.py:157} INFO - Started process (PID=295) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:06.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:12:06.641+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:06.640+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:06.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:06.692+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:06.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:12:06.723+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:06.723+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:12:06.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-09-30T21:12:36.995+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:36.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:12:37.000+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:36.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:37.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:12:37.052+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:37.052+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:12:37.101+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:12:37.101+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:12:37.127+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-09-30T21:13:07.690+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:07.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:13:07.694+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:07.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:07.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:07.785+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:07.784+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:13:07.840+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:07.840+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:13:07.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.193 seconds
[2023-09-30T21:13:38.100+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:38.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:13:38.114+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:38.113+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:38.165+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:13:38.261+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:38.261+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:13:38.340+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:13:38.339+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:13:38.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.352 seconds
[2023-09-30T21:14:08.814+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:14:08.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-09-30T21:14:08.843+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:14:08.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:14:08.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-09-30T21:14:09.116+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:14:09.114+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-09-30T21:14:09.284+0000] {logging_mixin.py:150} INFO - [2023-09-30T21:14:09.284+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-09-30T21:14:09.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.737 seconds
