[2023-11-02T20:08:52.534+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:08:52.540+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:08:52.544+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:52.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:08:52.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:08:52.935+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:52.935+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:Google_Job_Data_Pipeline
[2023-11-02T20:08:52.962+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:52.962+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:Google_Job_Data_Pipeline
[2023-11-02T20:08:52.975+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:52.974+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:Google_Job_Data_Pipeline
[2023-11-02T20:08:53.000+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:52.999+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:08:53.028+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:53.027+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Data_Pipeline
[2023-11-02T20:08:53.052+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:08:53.052+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Data_Pipeline to None, run_after=None
[2023-11-02T20:08:53.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.561 seconds
[2023-11-02T20:09:23.518+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:23.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:09:23.523+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:23.522+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:23.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:23.686+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:23.686+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:09:23.787+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:23.787+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Data_Pipeline to None, run_after=None
[2023-11-02T20:09:23.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.396 seconds
[2023-11-02T20:09:54.419+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:54.426+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:09:54.428+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:54.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:54.462+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:09:54.500+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:54.499+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:09:54.536+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:09:54.535+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Data_Pipeline to None, run_after=None
[2023-11-02T20:09:54.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T20:10:24.681+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:24.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:10:24.685+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:24.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:24.715+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:24.763+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:24.762+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:10:24.828+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:24.828+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Data_Pipeline to None, run_after=None
[2023-11-02T20:10:24.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.198 seconds
[2023-11-02T20:10:39.015+0000] {processor.py:157} INFO - Started process (PID=68) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:39.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:10:39.018+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:39.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:10:39.265+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.264+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:Google_Job_Listings_Data_Pipeline
[2023-11-02T20:10:39.288+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.288+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:Google_Job_Listings_Data_Pipeline
[2023-11-02T20:10:39.309+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.309+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:Google_Job_Listings_Data_Pipeline
[2023-11-02T20:10:39.340+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.339+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:10:39.363+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.363+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:10:39.385+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:10:39.384+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:10:39.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.417 seconds
[2023-11-02T20:11:09.752+0000] {processor.py:157} INFO - Started process (PID=76) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:09.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:11:09.760+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:09.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:09.805+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:09.844+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:09.844+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:11:09.874+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:09.873+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:11:09.919+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.181 seconds
[2023-11-02T20:11:40.104+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:40.110+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:11:40.117+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:40.115+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:40.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:11:40.419+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:40.419+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:11:40.450+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:11:40.450+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:11:40.483+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.407 seconds
[2023-11-02T20:12:10.550+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:10.551+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:12:10.555+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:10.555+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:10.574+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:10.608+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:10.608+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:12:10.638+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:10.638+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:12:10.670+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T20:12:40.911+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:40.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:12:40.914+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:40.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:40.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:12:40.982+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:40.982+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:12:41.017+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:12:41.017+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:12:41.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-11-02T20:13:11.383+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:11.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:13:11.386+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:11.386+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:11.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:11.457+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:11.456+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:13:11.488+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:11.488+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:13:11.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-11-02T20:13:41.758+0000] {processor.py:157} INFO - Started process (PID=118) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:41.760+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:13:41.763+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:41.762+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:41.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:13:41.827+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:41.827+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:13:41.858+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:13:41.858+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:13:41.895+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T20:14:12.168+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:12.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:14:12.174+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:12.173+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:12.197+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:12.234+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:12.234+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:14:12.264+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:12.264+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:14:12.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T20:14:42.511+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:42.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:14:42.514+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:42.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:42.540+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:14:42.582+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:42.581+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:14:42.619+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:14:42.619+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:14:42.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T20:15:12.934+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:12.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:15:12.939+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:12.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:12.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:13.011+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:13.011+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:15:13.044+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:13.043+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:15:13.071+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T20:15:43.335+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:43.342+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:15:43.352+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:43.349+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:43.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:15:43.467+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:43.467+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:15:43.518+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:15:43.517+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:15:43.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.247 seconds
[2023-11-02T20:16:13.800+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:13.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:16:13.811+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:13.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:13.863+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:13.928+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:13.928+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:16:13.964+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:13.964+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:16:13.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.221 seconds
[2023-11-02T20:16:44.168+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:44.169+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:16:44.171+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:44.171+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:44.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:16:44.232+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:44.232+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:16:44.262+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:16:44.262+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:16:44.288+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T20:17:14.583+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:14.584+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:17:14.586+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:14.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:14.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:14.654+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:14.653+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:17:14.691+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:14.691+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:17:14.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-11-02T20:17:44.908+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:44.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:17:44.911+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:44.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:44.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:17:44.967+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:44.967+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:17:44.997+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:17:44.997+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:17:45.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-11-02T20:18:15.361+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:15.363+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:18:15.366+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:15.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:15.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:15.487+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:15.487+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:18:15.525+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:15.525+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:18:15.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.200 seconds
[2023-11-02T20:18:45.642+0000] {processor.py:157} INFO - Started process (PID=199) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:45.644+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:18:45.645+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:45.645+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:45.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:18:45.700+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:45.700+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:18:45.730+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:18:45.730+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:18:45.757+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-11-02T20:19:16.008+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:16.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:19:16.013+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:16.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:16.040+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:16.078+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:16.078+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:19:16.113+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:16.113+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:19:16.156+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-11-02T20:19:46.437+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:46.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:19:46.441+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:46.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:46.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:19:46.507+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:46.506+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:19:46.538+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:19:46.538+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:19:46.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-11-02T20:20:16.834+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:16.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:20:16.839+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:16.838+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:16.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:16.899+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:16.899+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:20:16.930+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:16.929+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:20:16.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-11-02T20:20:47.153+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:47.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:20:47.156+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:47.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:47.176+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:20:47.214+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:47.213+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:20:47.245+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:20:47.245+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:20:47.313+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-11-02T20:21:17.664+0000] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:17.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:21:17.668+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:17.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:17.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:17.738+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:17.737+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:21:17.774+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:17.774+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:21:17.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T20:21:26.803+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:26.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:21:26.810+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:26.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:26.825+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:26.820+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 724, in exec_module
  File "<frozen importlib._bootstrap_external>", line 860, in get_code
  File "<frozen importlib._bootstrap_external>", line 791, in source_to_code
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 67
    start_task >> docker_task >> feature_engineering>> upload_to_s3
    ^
IndentationError: unexpected indent
[2023-11-02T20:21:26.826+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:26.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-11-02T20:21:31.994+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:31.996+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:21:31.999+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:31.998+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:32.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:32.184+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:32.184+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:21:32.213+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:32.212+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:21:32.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.293 seconds
[2023-11-02T20:21:34.035+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:34.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:21:34.037+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:34.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:34.059+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:34.074+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:34.073+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:21:34.104+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:34.104+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:21:34.133+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.102 seconds
[2023-11-02T20:21:38.104+0000] {processor.py:157} INFO - Started process (PID=251) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:38.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:21:38.109+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:38.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:38.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:21:38.181+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:38.180+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:21:38.243+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:21:38.243+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:21:38.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.193 seconds
[2023-11-02T20:22:08.492+0000] {processor.py:157} INFO - Started process (PID=260) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:08.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:22:08.500+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:08.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:08.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:08.579+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:08.579+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:22:08.638+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:08.638+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:22:08.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.188 seconds
[2023-11-02T20:22:38.894+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:38.895+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:22:38.897+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:38.896+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:38.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:22:38.959+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:38.959+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:22:38.993+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:22:38.992+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:22:39.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T20:23:09.272+0000] {processor.py:157} INFO - Started process (PID=276) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:09.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:23:09.279+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:09.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:09.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:09.340+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:09.340+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:23:09.370+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:09.369+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:23:09.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-11-02T20:23:39.642+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:39.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:23:39.644+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:39.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:39.665+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:23:39.701+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:39.700+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:23:39.732+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:23:39.731+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:23:39.775+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-11-02T20:24:10.218+0000] {processor.py:157} INFO - Started process (PID=293) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:10.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:24:10.236+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:10.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:10.328+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:10.378+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:10.377+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:24:10.418+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:10.417+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:24:10.450+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.253 seconds
[2023-11-02T20:24:40.569+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:40.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:24:40.572+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:40.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:40.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:24:40.626+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:40.626+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:24:40.656+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:24:40.656+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:24:40.683+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-11-02T20:25:10.896+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:10.902+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:25:10.913+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:10.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:11.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:11.287+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:11.287+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:25:11.332+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:11.331+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:25:11.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.497 seconds
[2023-11-02T20:25:41.650+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:41.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:25:41.655+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:41.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:41.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:25:41.859+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:41.859+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:25:41.886+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:41.885+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:25:41.908+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:25:41.907+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:25:41.941+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.295 seconds
[2023-11-02T20:26:11.971+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:11.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:26:11.975+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:11.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:11.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:12.034+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:12.034+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:26:12.064+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:12.064+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:26:12.131+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-11-02T20:26:42.318+0000] {processor.py:157} INFO - Started process (PID=335) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:42.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:26:42.327+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:42.326+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:42.373+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:26:42.416+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:42.416+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:26:42.449+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:26:42.449+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:26:42.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.182 seconds
[2023-11-02T20:27:12.848+0000] {processor.py:157} INFO - Started process (PID=344) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:12.851+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:27:12.853+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:12.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:12.886+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:12.934+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:12.933+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:27:12.975+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:12.975+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:27:13.006+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-11-02T20:27:43.165+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:43.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:27:43.171+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:43.170+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:43.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:27:43.248+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:43.248+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:27:43.286+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:27:43.285+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:27:43.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-11-02T20:28:13.548+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:13.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:28:13.553+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:13.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:13.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:13.657+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:13.656+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:28:13.717+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:13.717+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:28:13.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.210 seconds
[2023-11-02T20:28:43.933+0000] {processor.py:157} INFO - Started process (PID=368) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:43.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:28:43.936+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:43.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:43.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:28:44.001+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:44.000+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:28:44.041+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:28:44.041+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:28:44.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-11-02T20:29:14.416+0000] {processor.py:157} INFO - Started process (PID=376) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:14.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:29:14.419+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:14.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:14.442+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:14.477+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:14.477+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:29:14.510+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:14.510+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:29:14.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-11-02T20:29:44.803+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:44.809+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:29:44.816+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:44.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:44.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:29:44.935+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:44.935+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:29:44.966+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:29:44.965+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:29:44.990+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.208 seconds
[2023-11-02T20:30:15.258+0000] {processor.py:157} INFO - Started process (PID=392) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:15.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:30:15.263+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:15.262+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:15.286+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:15.320+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:15.320+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:30:15.350+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:15.350+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:30:15.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-11-02T20:30:45.716+0000] {processor.py:157} INFO - Started process (PID=400) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:45.722+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:30:45.729+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:45.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:45.838+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:30:45.913+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:45.912+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:30:45.953+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:30:45.953+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:30:45.982+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.289 seconds
[2023-11-02T20:31:16.190+0000] {processor.py:157} INFO - Started process (PID=407) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:16.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:31:16.197+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:16.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:16.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:16.261+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:16.261+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:31:16.291+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:16.291+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:31:16.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T20:31:46.561+0000] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:46.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:31:46.565+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:46.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:46.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:31:46.620+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:46.620+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:31:46.651+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:31:46.651+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:31:46.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T20:32:16.846+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:16.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:32:16.850+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:16.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:16.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:16.920+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:16.920+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:32:16.959+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:16.958+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:32:16.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-11-02T20:32:47.302+0000] {processor.py:157} INFO - Started process (PID=431) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:47.304+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:32:47.308+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:47.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:47.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:32:47.396+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:47.396+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:32:47.432+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:32:47.432+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:32:47.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-11-02T20:33:17.682+0000] {processor.py:157} INFO - Started process (PID=439) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:33:17.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:33:17.686+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:33:17.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:33:17.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:33:17.782+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:33:17.781+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:33:17.832+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:33:17.832+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:33:17.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.199 seconds
[2023-11-02T20:35:12.473+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:12.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:35:12.494+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:12.492+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:12.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:13.261+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:13.261+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:35:13.307+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:13.307+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:35:13.373+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.912 seconds
[2023-11-02T20:35:43.666+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:43.675+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:35:43.680+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:43.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:43.740+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:35:43.809+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:43.808+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:35:43.887+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:35:43.887+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:35:43.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.288 seconds
[2023-11-02T20:36:14.625+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:14.637+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:36:14.648+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:14.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:14.892+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:15.147+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:15.146+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:36:15.277+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:15.277+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:36:15.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.793 seconds
[2023-11-02T20:36:45.732+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:45.736+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:36:45.741+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:45.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:45.791+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:36:46.129+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:46.129+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:36:46.151+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:46.151+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:36:46.188+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:36:46.185+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:36:46.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.529 seconds
[2023-11-02T20:37:16.568+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:16.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:37:16.584+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:16.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:16.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:17.081+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:17.081+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:37:17.141+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:17.141+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:37:17.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.854 seconds
[2023-11-02T20:37:47.725+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:47.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:37:47.740+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:47.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:47.853+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:37:47.931+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:47.930+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:37:47.984+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:37:47.983+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:37:48.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.323 seconds
[2023-11-02T20:38:18.369+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:18.375+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:38:18.379+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:18.378+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:18.426+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:18.492+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:18.492+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:38:18.530+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:18.530+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:38:18.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.206 seconds
[2023-11-02T20:38:48.710+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:48.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:38:48.751+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:48.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:48.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:38:48.842+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:48.842+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:38:48.876+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:38:48.876+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:38:48.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.206 seconds
[2023-11-02T20:39:19.111+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:19.118+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:39:19.125+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:19.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:19.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:19.269+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:19.269+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:39:19.309+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:19.309+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:39:19.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.277 seconds
[2023-11-02T20:39:49.603+0000] {processor.py:157} INFO - Started process (PID=117) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:49.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:39:49.616+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:49.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:49.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:39:49.879+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:49.879+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:39:49.906+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:49.906+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:39:49.923+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:39:49.923+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:39:49.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.381 seconds
[2023-11-02T20:40:20.216+0000] {processor.py:157} INFO - Started process (PID=125) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:20.219+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:40:20.221+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:20.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:20.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:20.314+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:20.314+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:40:20.361+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:20.360+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:40:20.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.531 seconds
[2023-11-02T20:40:51.048+0000] {processor.py:157} INFO - Started process (PID=133) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:51.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:40:51.056+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:51.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:51.274+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:40:51.363+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:51.363+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:40:51.436+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:40:51.435+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:40:51.471+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.432 seconds
[2023-11-02T20:41:21.799+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:21.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:41:21.803+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:21.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:21.826+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:21.861+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:21.860+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:41:21.892+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:21.892+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:41:21.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-11-02T20:41:52.167+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:52.168+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:41:52.170+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:52.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:52.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:41:52.230+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:52.230+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:41:52.264+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:41:52.264+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:41:52.317+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T20:42:22.647+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:22.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:42:22.652+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:22.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:22.691+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:22.768+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:22.767+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:42:22.815+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:22.815+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:42:22.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.253 seconds
[2023-11-02T20:42:52.965+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:52.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:42:52.968+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:52.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:52.993+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:42:53.034+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:53.034+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:42:53.067+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:42:53.067+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:42:53.094+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T20:43:23.396+0000] {processor.py:157} INFO - Started process (PID=175) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:23.405+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:43:23.417+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:23.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:23.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:23.517+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:23.516+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:43:23.560+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:23.560+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:43:23.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.227 seconds
[2023-11-02T20:43:53.789+0000] {processor.py:157} INFO - Started process (PID=183) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:53.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:43:53.793+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:53.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:53.817+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:43:53.852+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:53.851+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:43:53.883+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:43:53.883+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:43:53.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.156 seconds
[2023-11-02T20:44:24.225+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:24.227+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:44:24.228+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:24.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:24.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:24.286+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:24.285+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:44:24.318+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:24.317+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:44:24.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T20:44:54.594+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:54.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:44:54.599+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:54.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:54.627+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:44:54.668+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:54.668+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:44:54.704+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:44:54.703+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:44:54.731+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T20:45:25.044+0000] {processor.py:157} INFO - Started process (PID=209) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:25.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:45:25.051+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:25.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:25.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:25.121+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:25.121+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:45:25.154+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:25.154+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:45:25.177+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T20:45:55.400+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:55.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:45:55.412+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:55.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:55.470+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:45:55.549+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:55.548+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:45:55.599+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:45:55.598+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:45:55.639+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.249 seconds
[2023-11-02T20:46:25.838+0000] {processor.py:157} INFO - Started process (PID=225) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:25.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:46:25.843+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:25.842+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:25.872+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:25.910+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:25.910+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:46:25.941+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:25.941+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:46:25.966+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T20:46:56.331+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:56.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:46:56.334+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:56.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:56.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:46:56.466+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:56.465+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:46:56.497+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:46:56.497+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:46:56.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.226 seconds
[2023-11-02T20:47:26.697+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:26.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:47:26.701+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:26.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:26.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:26.770+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:26.770+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:47:26.815+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:26.815+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:47:26.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-11-02T20:47:57.206+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:57.208+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:47:57.210+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:57.209+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:57.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:47:57.282+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:57.282+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:47:57.313+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:47:57.313+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:47:57.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T20:48:27.587+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:27.592+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:48:27.595+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:27.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:27.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:27.682+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:27.681+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:48:27.756+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:27.756+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:48:27.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.233 seconds
[2023-11-02T20:48:58.005+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:58.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:48:58.024+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:58.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:58.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:48:58.303+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:58.303+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:48:58.321+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:58.321+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:48:58.335+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:48:58.334+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:48:58.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.386 seconds
[2023-11-02T20:49:28.477+0000] {processor.py:157} INFO - Started process (PID=274) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:28.489+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:49:28.495+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:28.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:28.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:28.753+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:28.752+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:49:28.845+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:28.844+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:49:28.985+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.548 seconds
[2023-11-02T20:49:59.463+0000] {processor.py:157} INFO - Started process (PID=282) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:59.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:49:59.469+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:59.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:59.532+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:49:59.595+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:59.594+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:49:59.759+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:49:59.759+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:50:00.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.719 seconds
[2023-11-02T20:50:30.643+0000] {processor.py:157} INFO - Started process (PID=290) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:50:30.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:50:30.659+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:50:30.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:50:30.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:50:30.904+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:50:30.904+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:50:30.950+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:50:30.950+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:50:30.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.355 seconds
[2023-11-02T20:51:01.045+0000] {processor.py:157} INFO - Started process (PID=298) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:01.048+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:51:01.050+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:01.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:01.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:01.114+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:01.114+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:51:01.145+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:01.145+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:51:01.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-11-02T20:51:31.433+0000] {processor.py:157} INFO - Started process (PID=307) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:31.441+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:51:31.449+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:31.446+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:31.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:51:31.546+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:31.546+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:51:31.578+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:51:31.578+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:51:31.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.194 seconds
[2023-11-02T20:52:01.901+0000] {processor.py:157} INFO - Started process (PID=316) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:01.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:52:01.915+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:01.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:01.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:02.035+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:02.035+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:52:02.070+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:02.070+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:52:02.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.282 seconds
[2023-11-02T20:52:32.339+0000] {processor.py:157} INFO - Started process (PID=325) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:32.341+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:52:32.344+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:32.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:32.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:52:32.437+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:32.437+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:52:32.482+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:52:32.482+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:52:32.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.288 seconds
[2023-11-02T20:53:02.798+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:02.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:53:02.803+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:02.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:02.836+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:03.078+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:03.077+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:53:03.098+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:03.098+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:53:03.115+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:03.114+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:53:03.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.351 seconds
[2023-11-02T20:53:33.195+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:33.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:53:33.200+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:33.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:33.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:53:33.311+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:33.311+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:53:33.352+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:53:33.352+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:53:33.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.197 seconds
[2023-11-02T20:54:03.703+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:03.705+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:54:03.707+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:03.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:03.730+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:03.775+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:03.775+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:54:03.811+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:03.811+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:54:03.850+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T20:54:34.113+0000] {processor.py:157} INFO - Started process (PID=360) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:34.119+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:54:34.128+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:34.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:34.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:54:34.223+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:34.223+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:54:34.264+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:54:34.264+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:54:34.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.227 seconds
[2023-11-02T20:55:04.529+0000] {processor.py:157} INFO - Started process (PID=375) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:04.530+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:55:04.532+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:04.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:04.553+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:04.597+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:04.596+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:55:04.645+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:04.645+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:55:04.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-11-02T20:55:35.057+0000] {processor.py:157} INFO - Started process (PID=383) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:35.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:55:35.061+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:35.060+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:35.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:55:35.124+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:35.124+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:55:35.157+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:55:35.156+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:55:35.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.182 seconds
[2023-11-02T20:56:05.433+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:05.437+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:56:05.442+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:05.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:05.485+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:05.531+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:05.531+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:56:05.577+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:05.577+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:56:05.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-11-02T20:56:35.921+0000] {processor.py:157} INFO - Started process (PID=399) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:35.923+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:56:35.925+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:35.925+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:35.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:56:35.985+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:35.985+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:56:36.017+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:56:36.017+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:56:36.051+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-11-02T20:57:06.287+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:06.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:57:06.302+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:06.301+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:06.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:06.433+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:06.432+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:57:06.470+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:06.469+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:57:06.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.341 seconds
[2023-11-02T20:57:36.678+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:36.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:57:36.683+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:36.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:36.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:57:36.756+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:36.756+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:57:36.803+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:57:36.803+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:57:36.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-11-02T20:58:07.062+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:07.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:58:07.071+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:07.070+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:07.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:07.255+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:07.255+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:58:07.367+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:07.367+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:58:07.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.376 seconds
[2023-11-02T20:58:37.523+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:37.527+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:58:37.530+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:37.529+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:37.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:58:37.842+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:37.842+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:58:37.883+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:37.882+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T20:58:37.921+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:58:37.920+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:58:37.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.479 seconds
[2023-11-02T20:59:08.240+0000] {processor.py:157} INFO - Started process (PID=437) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:08.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:59:08.246+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:08.245+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:08.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:08.348+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:08.348+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:59:08.418+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:08.418+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:59:08.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.278 seconds
[2023-11-02T20:59:38.775+0000] {processor.py:157} INFO - Started process (PID=445) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:38.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T20:59:38.782+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:38.781+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:38.850+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T20:59:38.921+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:38.921+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T20:59:39.006+0000] {logging_mixin.py:150} INFO - [2023-11-02T20:59:39.006+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T20:59:39.050+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.282 seconds
[2023-11-02T21:00:09.115+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:09.117+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:00:09.119+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:09.119+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:09.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:09.186+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:09.186+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:00:09.219+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:09.219+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:00:09.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T21:00:39.463+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:39.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:00:39.467+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:39.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:39.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:00:39.529+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:39.529+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:00:39.563+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:00:39.562+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:00:39.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-11-02T21:01:09.954+0000] {processor.py:157} INFO - Started process (PID=470) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:09.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:01:09.959+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:09.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:09.989+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:10.027+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:10.026+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:01:10.064+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:10.063+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:01:10.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-11-02T21:01:40.433+0000] {processor.py:157} INFO - Started process (PID=478) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:40.434+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:01:40.436+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:40.436+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:40.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:01:40.509+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:40.509+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:01:40.541+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:01:40.541+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:01:40.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.169 seconds
[2023-11-02T21:02:10.861+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:10.865+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:02:10.868+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:10.868+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:10.902+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:10.940+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:10.940+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:02:10.977+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:10.977+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:02:11.010+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-11-02T21:02:41.252+0000] {processor.py:157} INFO - Started process (PID=494) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:41.254+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:02:41.256+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:41.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:41.283+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:02:41.320+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:41.320+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:02:41.352+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:02:41.352+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:02:41.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T21:03:11.681+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:11.684+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:03:11.686+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:11.685+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:11.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:11.746+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:11.746+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:03:11.781+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:11.780+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:03:11.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T21:03:42.048+0000] {processor.py:157} INFO - Started process (PID=511) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:42.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:03:42.051+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:42.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:42.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:03:42.123+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:42.123+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:03:42.162+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:03:42.161+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:03:42.199+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-11-02T21:04:12.463+0000] {processor.py:157} INFO - Started process (PID=519) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:12.470+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:04:12.472+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:12.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:12.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:12.543+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:12.542+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:04:12.589+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:12.589+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:04:12.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.183 seconds
[2023-11-02T21:04:42.932+0000] {processor.py:157} INFO - Started process (PID=527) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:42.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:04:42.947+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:42.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:43.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:04:43.101+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:43.101+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:04:43.141+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:04:43.141+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:04:43.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.270 seconds
[2023-11-02T21:05:13.302+0000] {processor.py:157} INFO - Started process (PID=535) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:13.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:05:13.305+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:13.305+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:13.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:13.377+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:13.377+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:05:13.410+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:13.410+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:05:13.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-11-02T21:05:43.652+0000] {processor.py:157} INFO - Started process (PID=543) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:43.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:05:43.657+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:43.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:43.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:05:43.732+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:43.732+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:05:43.773+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:05:43.773+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:05:43.822+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.176 seconds
[2023-11-02T21:06:14.049+0000] {processor.py:157} INFO - Started process (PID=551) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:14.052+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:06:14.056+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:14.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:14.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:14.563+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:14.562+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:06:14.584+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:14.584+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:06:14.601+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:14.601+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:06:14.634+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.598 seconds
[2023-11-02T21:06:44.964+0000] {processor.py:157} INFO - Started process (PID=560) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:44.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:06:44.969+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:44.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:44.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:06:45.036+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:45.036+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:06:45.069+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:06:45.069+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:06:45.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-11-02T21:07:15.305+0000] {processor.py:157} INFO - Started process (PID=568) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:15.307+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:07:15.310+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:15.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:15.339+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:15.377+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:15.377+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:07:15.416+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:15.416+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:07:15.449+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-11-02T21:07:45.732+0000] {processor.py:157} INFO - Started process (PID=576) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:45.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:07:45.737+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:45.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:45.771+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:07:45.827+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:45.827+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:07:45.889+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:07:45.889+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:07:45.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.241 seconds
[2023-11-02T21:08:16.080+0000] {processor.py:157} INFO - Started process (PID=584) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:16.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:08:16.083+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:16.083+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:16.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:16.160+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:16.160+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:08:16.198+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:16.198+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:08:16.230+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-11-02T21:08:46.395+0000] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:46.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:08:46.400+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:46.400+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:46.430+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:08:46.480+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:46.480+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:08:46.522+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:08:46.522+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:08:46.562+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.177 seconds
[2023-11-02T21:09:16.815+0000] {processor.py:157} INFO - Started process (PID=600) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:16.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:09:16.818+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:16.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:16.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:16.888+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:16.888+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:09:16.923+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:16.923+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:09:16.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T21:09:47.109+0000] {processor.py:157} INFO - Started process (PID=608) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:47.130+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:09:47.133+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:47.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:47.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:09:47.220+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:47.219+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:09:47.272+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:09:47.271+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:09:47.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.200 seconds
[2023-11-02T21:10:17.509+0000] {processor.py:157} INFO - Started process (PID=616) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:17.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:10:17.513+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:17.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:17.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:17.578+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:17.577+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:10:17.610+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:17.610+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:10:17.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-11-02T21:10:47.878+0000] {processor.py:157} INFO - Started process (PID=624) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:47.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:10:47.882+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:47.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:47.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:10:47.962+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:47.962+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:10:48.007+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:10:48.007+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:10:48.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-11-02T21:11:18.283+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:18.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:11:18.287+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:18.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:18.314+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:18.352+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:18.351+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:11:18.385+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:18.385+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:11:18.416+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-11-02T21:11:48.752+0000] {processor.py:157} INFO - Started process (PID=640) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:48.753+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:11:48.756+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:48.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:48.781+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:11:48.818+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:48.817+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:11:48.850+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:11:48.850+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:11:48.939+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.194 seconds
[2023-11-02T21:12:19.127+0000] {processor.py:157} INFO - Started process (PID=647) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:19.129+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:12:19.133+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:19.132+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:19.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:19.219+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:19.219+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:12:19.258+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:19.258+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:12:19.289+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.174 seconds
[2023-11-02T21:12:49.649+0000] {processor.py:157} INFO - Started process (PID=656) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:49.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:12:49.655+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:49.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:49.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:12:49.721+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:49.721+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:12:49.756+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:12:49.756+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:12:49.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T21:13:20.019+0000] {processor.py:157} INFO - Started process (PID=664) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:20.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:13:20.023+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:20.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:20.048+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:20.239+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:20.239+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:13:20.260+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:20.260+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:13:20.277+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:20.277+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:13:20.308+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.295 seconds
[2023-11-02T21:13:50.452+0000] {processor.py:157} INFO - Started process (PID=672) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:50.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:13:50.460+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:50.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:50.497+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:13:50.535+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:50.535+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:13:50.566+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:13:50.566+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:13:50.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-11-02T21:14:20.743+0000] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:20.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:14:20.747+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:20.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:20.774+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:20.811+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:20.811+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:14:20.874+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:20.873+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:14:20.910+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-11-02T21:14:51.204+0000] {processor.py:157} INFO - Started process (PID=688) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:51.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:14:51.208+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:51.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:51.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:14:51.307+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:51.307+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:14:51.364+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:14:51.364+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:14:51.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.216 seconds
[2023-11-02T21:15:21.569+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:21.575+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:15:21.579+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:21.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:21.641+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:21.683+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:21.682+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:15:21.716+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:21.716+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:15:21.754+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.211 seconds
[2023-11-02T21:15:52.097+0000] {processor.py:157} INFO - Started process (PID=704) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:52.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:15:52.107+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:52.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:52.155+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:15:52.238+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:52.238+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:15:52.295+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:15:52.295+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:15:52.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.255 seconds
[2023-11-02T21:16:22.429+0000] {processor.py:157} INFO - Started process (PID=712) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:22.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:16:22.439+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:22.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:22.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:22.506+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:22.506+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:16:22.552+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:22.551+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:16:22.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.176 seconds
[2023-11-02T21:16:52.976+0000] {processor.py:157} INFO - Started process (PID=720) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:52.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:16:52.980+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:52.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:53.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:16:53.039+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:53.038+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:16:53.070+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:16:53.070+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:16:53.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.180 seconds
[2023-11-02T21:17:23.362+0000] {processor.py:157} INFO - Started process (PID=729) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:23.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:17:23.377+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:23.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:23.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:23.901+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:23.900+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:17:23.965+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:23.965+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:17:23.998+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:23.997+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:17:24.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.703 seconds
[2023-11-02T21:17:54.330+0000] {processor.py:157} INFO - Started process (PID=737) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:54.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:17:54.333+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:54.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:54.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:17:54.410+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:54.410+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:17:54.472+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:17:54.471+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:17:54.531+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.208 seconds
[2023-11-02T21:18:24.577+0000] {processor.py:157} INFO - Started process (PID=745) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:24.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:18:24.582+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:24.581+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:24.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:24.657+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:24.656+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:18:24.693+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:24.693+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:18:24.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-11-02T21:18:54.819+0000] {processor.py:157} INFO - Started process (PID=754) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:54.820+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:18:54.822+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:54.822+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:54.856+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:18:54.916+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:54.916+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:18:54.980+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:18:54.980+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:18:55.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.213 seconds
[2023-11-02T21:19:25.346+0000] {processor.py:157} INFO - Started process (PID=762) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:25.352+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:19:25.360+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:25.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:25.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:25.492+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:25.491+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:19:25.540+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:25.540+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:19:25.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.255 seconds
[2023-11-02T21:19:55.885+0000] {processor.py:157} INFO - Started process (PID=771) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:55.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:19:55.894+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:55.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:55.942+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:19:56.261+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:56.261+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:19:56.311+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:56.310+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:19:56.356+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:19:56.355+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:19:56.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.550 seconds
[2023-11-02T21:20:26.884+0000] {processor.py:157} INFO - Started process (PID=779) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:26.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:20:26.898+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:26.896+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:26.973+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:27.024+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:27.024+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:20:27.060+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:27.060+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:20:27.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.241 seconds
[2023-11-02T21:20:57.187+0000] {processor.py:157} INFO - Started process (PID=787) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:57.192+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:20:57.196+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:57.195+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:57.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:20:57.338+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:57.337+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:20:57.422+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:20:57.422+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:20:57.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.324 seconds
[2023-11-02T21:21:27.703+0000] {processor.py:157} INFO - Started process (PID=795) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:27.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:21:27.718+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:27.716+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:27.759+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:27.814+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:27.813+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:21:27.870+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:27.869+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:21:27.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.229 seconds
[2023-11-02T21:21:58.118+0000] {processor.py:157} INFO - Started process (PID=803) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:58.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:21:58.127+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:58.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:58.152+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:21:58.193+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:58.193+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:21:58.232+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:21:58.232+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:21:58.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-11-02T21:22:28.391+0000] {processor.py:157} INFO - Started process (PID=813) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:28.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:22:28.394+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:28.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:28.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:28.454+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:28.454+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:22:28.488+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:28.488+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:22:28.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-11-02T21:22:58.908+0000] {processor.py:157} INFO - Started process (PID=821) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:58.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:22:58.912+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:58.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:58.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:22:58.977+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:58.977+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:22:59.009+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:22:59.009+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:22:59.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T21:23:29.297+0000] {processor.py:157} INFO - Started process (PID=829) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:23:29.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:23:29.303+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:23:29.302+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:23:29.335+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:23:29.373+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:23:29.372+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:23:29.405+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:23:29.405+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:23:29.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.191 seconds
[2023-11-02T21:23:59.727+0000] {processor.py:157} INFO - Started process (PID=838) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:23:59.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:23:59.746+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:23:59.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:23:59.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:24:00.209+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:00.208+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:24:00.230+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:00.229+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:24:00.248+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:00.248+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:24:00.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.581 seconds
[2023-11-02T21:24:30.604+0000] {processor.py:157} INFO - Started process (PID=846) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:24:30.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:24:30.612+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:30.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:24:30.666+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:24:30.757+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:30.757+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:24:30.848+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:24:30.848+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:24:30.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.311 seconds
[2023-11-02T21:25:01.173+0000] {processor.py:157} INFO - Started process (PID=854) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:01.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:25:01.176+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:01.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:01.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:01.230+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:01.230+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:25:01.261+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:01.261+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:25:01.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-11-02T21:25:31.531+0000] {processor.py:157} INFO - Started process (PID=862) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:31.533+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:25:31.535+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:31.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:31.555+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:25:31.587+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:31.587+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:25:31.616+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:25:31.616+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:25:31.662+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T21:26:01.848+0000] {processor.py:157} INFO - Started process (PID=869) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:01.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:26:01.855+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:01.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:01.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:01.908+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:01.907+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:26:01.937+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:01.937+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:26:01.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T21:26:32.238+0000] {processor.py:157} INFO - Started process (PID=877) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:32.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:26:32.241+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:32.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:32.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:26:32.305+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:32.304+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:26:32.337+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:26:32.337+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:26:32.367+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T21:27:02.601+0000] {processor.py:157} INFO - Started process (PID=885) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:02.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:27:02.606+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:02.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:02.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:02.666+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:02.665+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:27:02.696+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:02.696+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:27:02.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-11-02T21:27:32.959+0000] {processor.py:157} INFO - Started process (PID=894) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:32.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:27:32.962+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:32.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:32.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:27:33.017+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:33.017+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:27:33.049+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:27:33.049+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:27:33.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-11-02T21:28:03.316+0000] {processor.py:157} INFO - Started process (PID=901) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:03.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:28:03.321+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:03.320+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:03.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:03.379+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:03.379+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:28:03.409+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:03.408+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:28:03.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-11-02T21:28:33.694+0000] {processor.py:157} INFO - Started process (PID=909) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:33.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:28:33.699+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:33.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:33.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:28:33.765+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:33.765+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:28:33.793+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:28:33.793+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:28:33.820+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-11-02T21:29:04.048+0000] {processor.py:157} INFO - Started process (PID=917) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:04.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:29:04.052+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:04.052+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:04.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:04.117+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:04.117+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:29:04.152+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:04.152+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:29:04.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-11-02T21:29:34.327+0000] {processor.py:157} INFO - Started process (PID=925) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:34.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:29:34.331+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:34.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:34.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:29:34.393+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:34.393+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:29:34.422+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:29:34.422+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:29:34.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-11-02T21:30:04.608+0000] {processor.py:157} INFO - Started process (PID=932) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:04.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:30:04.612+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:04.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:04.637+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:04.675+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:04.675+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:30:04.709+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:04.709+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:30:04.741+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-11-02T21:30:35.038+0000] {processor.py:157} INFO - Started process (PID=941) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:35.040+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:30:35.042+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:35.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:35.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:30:35.095+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:35.094+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:30:35.125+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:30:35.125+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:30:35.154+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-11-02T21:31:05.359+0000] {processor.py:157} INFO - Started process (PID=949) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:05.360+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:31:05.362+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:05.361+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:05.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:05.426+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:05.426+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:31:05.462+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:05.462+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:31:05.493+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-11-02T21:31:35.756+0000] {processor.py:157} INFO - Started process (PID=957) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:35.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:31:35.761+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:35.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:35.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:31:35.817+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:35.817+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:31:35.846+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:31:35.846+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:31:35.885+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T21:32:06.076+0000] {processor.py:157} INFO - Started process (PID=966) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:06.078+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:32:06.080+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:06.080+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:06.108+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:06.145+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:06.145+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:32:06.177+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:06.177+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:32:06.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-11-02T21:32:36.472+0000] {processor.py:157} INFO - Started process (PID=973) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:36.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:32:36.479+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:36.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:36.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:32:36.538+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:36.537+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:32:36.567+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:32:36.567+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:32:36.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T21:33:06.806+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:06.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:33:06.809+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:06.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:06.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:06.865+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:06.864+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:33:06.895+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:06.895+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:33:06.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-11-02T21:33:37.146+0000] {processor.py:157} INFO - Started process (PID=990) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:37.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:33:37.151+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:37.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:37.204+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:33:37.276+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:37.276+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:33:37.314+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:33:37.314+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:33:37.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.217 seconds
[2023-11-02T21:34:07.435+0000] {processor.py:157} INFO - Started process (PID=998) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:07.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:34:07.438+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:07.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:07.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:07.498+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:07.498+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:34:07.528+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:07.528+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:34:07.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T21:34:37.767+0000] {processor.py:157} INFO - Started process (PID=1006) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:37.769+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:34:37.772+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:37.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:37.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:34:37.839+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:37.838+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:34:37.875+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:34:37.875+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:34:37.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-11-02T21:35:08.174+0000] {processor.py:157} INFO - Started process (PID=1014) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:08.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:35:08.177+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:08.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:08.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:08.233+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:08.233+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:35:08.266+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:08.266+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:35:08.327+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-11-02T21:35:38.570+0000] {processor.py:157} INFO - Started process (PID=1022) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:38.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:35:38.577+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:38.576+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:38.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:35:38.644+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:38.643+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:35:38.672+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:35:38.672+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:35:38.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T21:36:08.879+0000] {processor.py:157} INFO - Started process (PID=1030) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:08.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:36:08.882+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:08.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:08.904+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:08.938+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:08.938+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:36:08.971+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:08.970+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:36:08.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-11-02T21:36:39.257+0000] {processor.py:157} INFO - Started process (PID=1038) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:39.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:36:39.259+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:39.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:39.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:36:39.323+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:39.323+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:36:39.360+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:36:39.359+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:36:39.383+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T21:37:09.592+0000] {processor.py:157} INFO - Started process (PID=1046) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:09.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:37:09.595+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:09.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:09.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:09.652+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:09.652+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:37:09.685+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:09.685+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:37:09.759+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.172 seconds
[2023-11-02T21:37:39.999+0000] {processor.py:157} INFO - Started process (PID=1055) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:40.001+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:37:40.003+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:40.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:40.025+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:37:40.059+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:40.059+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:37:40.088+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:37:40.088+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:37:40.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T21:38:10.387+0000] {processor.py:157} INFO - Started process (PID=1063) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:10.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:38:10.390+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:10.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:10.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:10.444+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:10.444+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:38:10.474+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:10.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:38:10.506+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T21:38:40.756+0000] {processor.py:157} INFO - Started process (PID=1071) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:40.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:38:40.762+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:40.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:40.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:38:40.819+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:40.818+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:38:40.847+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:38:40.847+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:38:40.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T21:39:11.117+0000] {processor.py:157} INFO - Started process (PID=1079) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:11.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:39:11.124+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:11.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:11.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:11.201+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:11.200+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:39:11.233+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:11.233+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:39:11.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-11-02T21:39:41.456+0000] {processor.py:157} INFO - Started process (PID=1087) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:41.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:39:41.459+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:41.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:41.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:39:41.516+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:41.516+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:39:41.545+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:39:41.545+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:39:41.574+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-11-02T21:40:11.831+0000] {processor.py:157} INFO - Started process (PID=1095) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:11.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:40:11.834+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:11.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:11.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:11.902+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:11.901+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:40:11.944+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:11.944+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:40:11.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T21:40:42.317+0000] {processor.py:157} INFO - Started process (PID=1104) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:42.319+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:40:42.322+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:42.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:42.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:40:42.379+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:42.379+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:40:42.409+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:40:42.408+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:40:42.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-11-02T21:41:12.670+0000] {processor.py:157} INFO - Started process (PID=1112) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:12.672+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:41:12.674+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:12.674+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:12.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:12.732+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:12.732+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:41:12.762+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:12.761+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:41:12.798+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T21:41:43.031+0000] {processor.py:157} INFO - Started process (PID=1120) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:43.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:41:43.035+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:43.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:43.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:41:43.372+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:43.372+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:41:43.416+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:43.413+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:41:43.445+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:41:43.445+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:41:43.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.473 seconds
[2023-11-02T21:42:13.722+0000] {processor.py:157} INFO - Started process (PID=1128) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:13.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:42:13.727+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:13.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:13.773+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:13.850+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:13.850+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:42:13.904+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:13.903+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:42:13.954+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.241 seconds
[2023-11-02T21:42:44.199+0000] {processor.py:157} INFO - Started process (PID=1136) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:44.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:42:44.203+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:44.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:44.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:42:44.273+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:44.273+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:42:44.314+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:42:44.314+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:42:44.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-11-02T21:43:14.498+0000] {processor.py:157} INFO - Started process (PID=1144) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:14.501+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:43:14.504+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:14.503+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:14.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:14.574+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:14.573+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:43:14.603+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:14.602+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:43:14.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-11-02T21:43:44.824+0000] {processor.py:157} INFO - Started process (PID=1152) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:44.826+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:43:44.828+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:44.827+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:44.854+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:43:44.896+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:44.895+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:43:44.930+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:43:44.930+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:43:44.955+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-11-02T21:44:15.189+0000] {processor.py:157} INFO - Started process (PID=1160) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:15.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:44:15.193+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:15.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:15.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:15.370+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:15.369+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:44:15.386+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:15.385+0000] {dag.py:2763} INFO - Creating ORM DAG for Google_Job_Listings_Data_Pipeline
[2023-11-02T21:44:15.400+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:15.400+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:44:15.435+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.252 seconds
[2023-11-02T21:44:45.515+0000] {processor.py:157} INFO - Started process (PID=1168) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:45.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:44:45.523+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:45.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:45.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:44:45.582+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:45.582+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:44:45.614+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:44:45.613+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:44:45.692+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.182 seconds
[2023-11-02T21:45:16.052+0000] {processor.py:157} INFO - Started process (PID=1176) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:16.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:45:16.055+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:16.054+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:16.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:16.111+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:16.110+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:45:16.141+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:16.141+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:45:16.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-11-02T21:45:46.380+0000] {processor.py:157} INFO - Started process (PID=1185) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:46.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:45:46.383+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:46.383+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:46.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:45:46.443+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:46.443+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:45:46.473+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:45:46.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:45:46.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T21:46:16.833+0000] {processor.py:157} INFO - Started process (PID=1192) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:16.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:46:16.837+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:16.836+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:16.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:16.893+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:16.893+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:46:16.923+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:16.923+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:46:16.952+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T21:46:47.140+0000] {processor.py:157} INFO - Started process (PID=1200) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:47.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:46:47.144+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:47.143+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:47.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:46:47.212+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:47.211+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:46:47.244+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:46:47.244+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:46:47.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-11-02T21:47:17.438+0000] {processor.py:157} INFO - Started process (PID=1207) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:17.439+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:47:17.441+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:17.440+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:17.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:17.501+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:17.501+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:47:17.535+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:17.535+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:47:17.566+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T21:47:47.736+0000] {processor.py:157} INFO - Started process (PID=1215) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:47.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:47:47.740+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:47.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:47.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:47:47.800+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:47.800+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:47:47.832+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:47:47.832+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:47:47.862+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T21:48:18.082+0000] {processor.py:157} INFO - Started process (PID=1224) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:18.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:48:18.087+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:18.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:18.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:18.144+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:18.144+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:48:18.175+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:18.175+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:48:18.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-11-02T21:48:48.472+0000] {processor.py:157} INFO - Started process (PID=1232) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:48.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:48:48.476+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:48.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:48.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:48:48.540+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:48.540+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:48:48.573+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:48:48.573+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:48:48.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T21:49:18.798+0000] {processor.py:157} INFO - Started process (PID=1241) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:18.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:49:18.803+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:18.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:18.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:18.871+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:18.871+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:49:18.908+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:18.908+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:49:18.942+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T21:49:49.173+0000] {processor.py:157} INFO - Started process (PID=1249) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:49.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:49:49.179+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:49.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:49.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:49:49.268+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:49.267+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:49:49.306+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:49:49.306+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:49:49.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.179 seconds
[2023-11-02T21:50:19.586+0000] {processor.py:157} INFO - Started process (PID=1264) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:19.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:50:19.591+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:19.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:19.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:19.648+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:19.648+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:50:19.679+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:19.679+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:50:19.710+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T21:50:49.889+0000] {processor.py:157} INFO - Started process (PID=1272) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:49.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:50:49.893+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:49.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:49.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:50:49.967+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:49.966+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:50:50.010+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:50:50.010+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:50:50.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-11-02T21:51:20.274+0000] {processor.py:157} INFO - Started process (PID=1280) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:20.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:51:20.278+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:20.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:20.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:20.337+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:20.337+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:51:20.369+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:20.369+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:51:20.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T21:51:50.650+0000] {processor.py:157} INFO - Started process (PID=1288) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:50.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:51:50.654+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:50.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:50.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:51:50.711+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:50.710+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:51:50.743+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:51:50.743+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:51:50.770+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-11-02T21:52:21.001+0000] {processor.py:157} INFO - Started process (PID=1297) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:21.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:52:21.005+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:21.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:21.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:21.062+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:21.061+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:52:21.093+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:21.092+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:52:21.122+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-11-02T21:52:51.388+0000] {processor.py:157} INFO - Started process (PID=1305) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:51.390+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:52:51.392+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:51.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:51.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:52:51.450+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:51.450+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:52:51.482+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:52:51.481+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:52:51.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-11-02T21:53:21.712+0000] {processor.py:157} INFO - Started process (PID=1313) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:21.714+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:53:21.716+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:21.715+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:21.739+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:21.774+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:21.774+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:53:21.807+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:21.807+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:53:21.833+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-11-02T21:53:52.063+0000] {processor.py:157} INFO - Started process (PID=1321) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:52.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:53:52.068+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:52.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:52.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:53:52.126+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:52.126+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:53:52.158+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:53:52.158+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:53:52.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T21:54:22.413+0000] {processor.py:157} INFO - Started process (PID=1329) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:22.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:54:22.418+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:22.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:22.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:22.480+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:22.480+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:54:22.516+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:22.516+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:54:22.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-11-02T21:54:52.789+0000] {processor.py:157} INFO - Started process (PID=1336) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:52.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:54:52.792+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:52.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:52.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:54:52.849+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:52.848+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:54:52.879+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:54:52.878+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:54:52.907+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-11-02T21:55:23.180+0000] {processor.py:157} INFO - Started process (PID=1344) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:23.183+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:55:23.186+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:23.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:23.210+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:23.243+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:23.242+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:55:23.272+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:23.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:55:23.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-11-02T21:55:53.502+0000] {processor.py:157} INFO - Started process (PID=1352) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:53.505+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:55:53.508+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:53.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:53.536+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:55:53.574+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:53.573+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:55:53.608+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:55:53.608+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:55:53.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-11-02T21:56:23.884+0000] {processor.py:157} INFO - Started process (PID=1360) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:23.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:56:23.886+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:23.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:23.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:23.937+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:23.937+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:56:23.969+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:23.969+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:56:23.996+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-11-02T21:56:54.163+0000] {processor.py:157} INFO - Started process (PID=1368) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:54.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:56:54.165+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:54.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:54.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:56:54.227+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:54.227+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:56:54.266+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:56:54.266+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:56:54.295+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T21:57:24.493+0000] {processor.py:157} INFO - Started process (PID=1376) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:24.494+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:57:24.496+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:24.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:24.519+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:24.561+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:24.561+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:57:24.594+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:24.594+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:57:24.635+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T21:57:54.890+0000] {processor.py:157} INFO - Started process (PID=1384) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:54.892+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:57:54.895+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:54.894+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:54.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:57:54.948+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:54.948+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:57:54.978+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:57:54.978+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:57:55.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T21:58:25.221+0000] {processor.py:157} INFO - Started process (PID=1392) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:25.223+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:58:25.226+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:25.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:25.251+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:25.284+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:25.284+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:58:25.315+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:25.315+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:58:25.345+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T21:58:55.579+0000] {processor.py:157} INFO - Started process (PID=1401) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:55.582+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:58:55.585+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:55.584+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:55.610+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:58:55.645+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:55.644+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:58:55.677+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:58:55.677+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:58:55.718+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T21:59:26.006+0000] {processor.py:157} INFO - Started process (PID=1409) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:26.008+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:59:26.011+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:26.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:26.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:26.078+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:26.077+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:59:26.112+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:26.112+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:59:26.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T21:59:56.355+0000] {processor.py:157} INFO - Started process (PID=1418) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:56.357+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T21:59:56.359+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:56.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:56.384+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T21:59:56.418+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:56.417+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T21:59:56.448+0000] {logging_mixin.py:150} INFO - [2023-11-02T21:59:56.448+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T21:59:56.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-11-02T22:00:26.714+0000] {processor.py:157} INFO - Started process (PID=1426) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:26.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:00:26.719+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:26.718+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:26.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:26.787+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:26.786+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:00:26.825+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:26.825+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:00:26.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-11-02T22:00:56.991+0000] {processor.py:157} INFO - Started process (PID=1434) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:56.992+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:00:56.994+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:56.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:57.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:00:57.057+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:57.057+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:00:57.094+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:00:57.093+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:00:57.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T22:01:27.454+0000] {processor.py:157} INFO - Started process (PID=1442) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:27.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:01:27.457+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:27.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:27.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:27.512+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:27.512+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:01:27.541+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:27.541+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:01:27.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-11-02T22:01:57.802+0000] {processor.py:157} INFO - Started process (PID=1449) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:57.804+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:01:57.806+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:57.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:57.830+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:01:57.868+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:57.868+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:01:57.907+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:01:57.907+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:01:57.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-11-02T22:02:28.201+0000] {processor.py:157} INFO - Started process (PID=1457) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:28.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:02:28.206+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:28.205+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:28.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:28.268+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:28.267+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:02:28.298+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:28.298+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:02:28.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-11-02T22:02:58.583+0000] {processor.py:157} INFO - Started process (PID=1465) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:58.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:02:58.589+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:58.589+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:58.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:02:58.658+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:58.658+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:02:58.689+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:02:58.689+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:02:58.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-11-02T22:03:28.948+0000] {processor.py:157} INFO - Started process (PID=1473) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:28.950+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:03:28.953+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:28.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:28.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:29.018+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:29.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:03:29.049+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:29.049+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:03:29.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T22:03:59.282+0000] {processor.py:157} INFO - Started process (PID=1481) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:59.289+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:03:59.291+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:59.290+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:59.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:03:59.347+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:59.347+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:03:59.381+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:03:59.381+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:03:59.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-11-02T22:04:29.606+0000] {processor.py:157} INFO - Started process (PID=1490) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:04:29.607+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:04:29.609+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:04:29.609+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:04:29.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:04:29.669+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:04:29.669+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:04:29.701+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:04:29.701+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:04:29.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T22:05:00.069+0000] {processor.py:157} INFO - Started process (PID=1498) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:00.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:05:00.073+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:00.072+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:00.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:00.129+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:00.129+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:05:00.159+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:00.159+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:05:00.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T22:05:30.379+0000] {processor.py:157} INFO - Started process (PID=1506) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:30.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:05:30.383+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:30.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:30.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:05:30.470+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:30.470+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:05:30.504+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:05:30.503+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:05:30.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-11-02T22:06:00.762+0000] {processor.py:157} INFO - Started process (PID=1514) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:00.764+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:06:00.767+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:00.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:00.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:00.830+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:00.830+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:06:00.861+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:00.861+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:06:00.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-11-02T22:06:31.176+0000] {processor.py:157} INFO - Started process (PID=1522) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:31.178+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:06:31.180+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:31.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:31.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:06:31.246+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:31.246+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:06:31.275+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:06:31.275+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:06:31.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-11-02T22:07:01.523+0000] {processor.py:157} INFO - Started process (PID=1530) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:01.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:07:01.527+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:01.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:01.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:01.594+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:01.594+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:07:01.635+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:01.635+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:07:01.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T22:07:31.933+0000] {processor.py:157} INFO - Started process (PID=1538) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:31.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:07:31.938+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:31.937+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:31.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:07:31.999+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:31.999+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:07:32.029+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:07:32.028+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:07:32.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:08:02.254+0000] {processor.py:157} INFO - Started process (PID=1546) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:02.256+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:08:02.258+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:02.258+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:02.286+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:02.320+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:02.320+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:08:02.349+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:02.349+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:08:02.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-11-02T22:08:32.671+0000] {processor.py:157} INFO - Started process (PID=1554) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:32.673+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:08:32.676+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:32.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:32.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:08:32.736+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:32.736+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:08:32.769+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:08:32.768+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:08:32.797+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T22:09:03.027+0000] {processor.py:157} INFO - Started process (PID=1562) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:03.029+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:09:03.031+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:03.030+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:03.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:03.103+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:03.103+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:09:03.149+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:03.148+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:09:03.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-11-02T22:09:33.376+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:33.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:09:33.389+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:33.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:33.416+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:09:33.450+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:33.450+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:09:33.480+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:09:33.479+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:09:33.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.166 seconds
[2023-11-02T22:10:03.756+0000] {processor.py:157} INFO - Started process (PID=1577) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:03.758+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:10:03.761+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:03.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:03.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:03.827+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:03.827+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:10:03.857+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:03.857+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:10:03.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T22:10:34.162+0000] {processor.py:157} INFO - Started process (PID=1586) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:34.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:10:34.165+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:34.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:34.191+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:10:34.233+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:34.233+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:10:34.277+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:10:34.277+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:10:34.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-11-02T22:11:04.491+0000] {processor.py:157} INFO - Started process (PID=1595) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:04.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:11:04.494+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:04.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:04.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:04.551+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:04.551+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:11:04.581+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:04.581+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:11:04.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-11-02T22:11:34.903+0000] {processor.py:157} INFO - Started process (PID=1604) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:34.904+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:11:34.906+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:34.906+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:34.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:11:34.968+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:34.968+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:11:34.999+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:11:34.999+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:11:35.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T22:12:05.197+0000] {processor.py:157} INFO - Started process (PID=1612) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:05.200+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:12:05.201+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:05.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:05.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:05.263+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:05.262+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:12:05.296+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:05.295+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:12:05.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-11-02T22:12:35.624+0000] {processor.py:157} INFO - Started process (PID=1620) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:35.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:12:35.627+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:35.627+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:35.649+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:12:35.684+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:35.684+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:12:35.719+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:12:35.719+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:12:35.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:13:05.929+0000] {processor.py:157} INFO - Started process (PID=1629) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:05.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:13:05.936+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:05.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:05.964+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:06.007+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:06.007+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:13:06.042+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:06.042+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:13:06.069+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-11-02T22:13:36.358+0000] {processor.py:157} INFO - Started process (PID=1637) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:36.360+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:13:36.363+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:36.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:36.390+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:13:36.427+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:36.427+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:13:36.463+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:13:36.463+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:13:36.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T22:14:06.668+0000] {processor.py:157} INFO - Started process (PID=1645) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:06.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:14:06.673+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:06.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:06.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:06.731+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:06.731+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:14:06.763+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:06.763+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:14:06.792+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T22:14:37.098+0000] {processor.py:157} INFO - Started process (PID=1653) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:37.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:14:37.106+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:37.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:37.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:14:37.163+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:37.162+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:14:37.193+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:14:37.193+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:14:37.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T22:15:07.410+0000] {processor.py:157} INFO - Started process (PID=1661) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:07.412+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:15:07.413+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:07.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:07.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:07.471+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:07.471+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:15:07.502+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:07.502+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:15:07.525+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:15:37.836+0000] {processor.py:157} INFO - Started process (PID=1668) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:37.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:15:37.839+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:37.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:37.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:15:37.894+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:37.894+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:15:37.923+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:15:37.923+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:15:37.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-11-02T22:16:08.178+0000] {processor.py:157} INFO - Started process (PID=1677) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:08.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:16:08.183+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:08.182+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:08.212+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:08.259+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:08.258+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:16:08.300+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:08.300+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:16:08.331+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-11-02T22:16:38.567+0000] {processor.py:157} INFO - Started process (PID=1685) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:38.568+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:16:38.570+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:38.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:38.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:16:38.624+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:38.624+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:16:38.653+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:16:38.653+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:16:38.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T22:17:08.941+0000] {processor.py:157} INFO - Started process (PID=1693) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:08.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:17:08.946+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:08.945+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:08.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:09.002+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:09.002+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:17:09.030+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:09.030+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:17:09.066+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-11-02T22:17:39.285+0000] {processor.py:157} INFO - Started process (PID=1702) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:39.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:17:39.289+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:39.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:39.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:17:39.345+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:39.345+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:17:39.375+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:17:39.375+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:17:39.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T22:18:09.655+0000] {processor.py:157} INFO - Started process (PID=1710) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:09.656+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:18:09.658+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:09.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:09.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:09.710+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:09.710+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:18:09.739+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:09.739+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:18:09.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-11-02T22:18:39.968+0000] {processor.py:157} INFO - Started process (PID=1718) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:39.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:18:39.971+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:39.970+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:39.990+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:18:40.030+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:40.030+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:18:40.062+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:18:40.061+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:18:40.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T22:19:10.363+0000] {processor.py:157} INFO - Started process (PID=1726) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:10.364+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:19:10.366+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:10.365+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:10.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:10.418+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:10.418+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:19:10.447+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:10.447+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:19:10.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:19:40.691+0000] {processor.py:157} INFO - Started process (PID=1734) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:40.692+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:19:40.693+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:40.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:40.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:19:40.753+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:40.753+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:19:40.783+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:19:40.782+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:19:40.806+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:20:11.142+0000] {processor.py:157} INFO - Started process (PID=1743) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:11.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:20:11.145+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:11.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:11.167+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:11.200+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:11.200+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:20:11.228+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:11.228+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:20:11.257+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-11-02T22:20:41.560+0000] {processor.py:157} INFO - Started process (PID=1751) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:41.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:20:41.564+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:41.563+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:41.589+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:20:41.621+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:41.621+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:20:41.651+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:20:41.651+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:20:41.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T22:21:11.931+0000] {processor.py:157} INFO - Started process (PID=1759) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:11.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:21:11.937+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:11.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:11.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:12.002+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:12.002+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:21:12.032+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:12.032+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:21:12.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-11-02T22:21:42.282+0000] {processor.py:157} INFO - Started process (PID=1767) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:42.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:21:42.286+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:42.285+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:42.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:21:42.352+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:42.352+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:21:42.388+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:21:42.388+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:21:42.417+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-11-02T22:22:12.724+0000] {processor.py:157} INFO - Started process (PID=1775) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:12.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:22:12.729+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:12.728+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:12.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:12.795+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:12.795+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:22:12.824+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:12.824+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:22:12.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:22:43.103+0000] {processor.py:157} INFO - Started process (PID=1783) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:43.104+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:22:43.107+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:43.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:43.135+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:22:43.167+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:43.167+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:22:43.196+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:22:43.196+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:22:43.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-11-02T22:23:13.468+0000] {processor.py:157} INFO - Started process (PID=1791) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:13.470+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:23:13.472+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:13.472+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:13.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:13.543+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:13.543+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:23:13.574+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:13.573+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:23:13.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-11-02T22:23:43.904+0000] {processor.py:157} INFO - Started process (PID=1799) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:43.906+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:23:43.908+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:43.907+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:43.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:23:43.965+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:43.965+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:23:43.995+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:23:43.995+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:23:44.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-11-02T22:24:14.221+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:14.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:24:14.224+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:14.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:14.248+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:14.286+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:14.285+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:24:14.320+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:14.320+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:24:14.363+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T22:24:44.666+0000] {processor.py:157} INFO - Started process (PID=1816) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:44.668+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:24:44.670+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:44.669+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:44.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:24:44.727+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:44.727+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:24:44.758+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:24:44.757+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:24:44.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-11-02T22:25:15.063+0000] {processor.py:157} INFO - Started process (PID=1824) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:15.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:25:15.067+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:15.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:15.091+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:15.125+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:15.125+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:25:15.154+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:15.154+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:25:15.182+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T22:25:45.478+0000] {processor.py:157} INFO - Started process (PID=1832) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:45.480+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:25:45.483+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:45.482+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:45.506+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:25:45.538+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:45.538+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:25:45.568+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:25:45.568+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:25:45.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-11-02T22:26:15.841+0000] {processor.py:157} INFO - Started process (PID=1840) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:15.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:26:15.846+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:15.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:15.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:15.910+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:15.910+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:26:15.949+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:15.949+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:26:15.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-11-02T22:26:46.146+0000] {processor.py:157} INFO - Started process (PID=1848) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:46.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:26:46.151+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:46.151+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:46.172+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:26:46.210+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:46.210+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:26:46.241+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:26:46.241+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:26:46.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-11-02T22:27:16.568+0000] {processor.py:157} INFO - Started process (PID=1856) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:16.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:27:16.577+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:16.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:16.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:16.687+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:16.687+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:27:16.740+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:16.739+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:27:16.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.215 seconds
[2023-11-02T22:27:46.868+0000] {processor.py:157} INFO - Started process (PID=1864) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:46.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:27:46.872+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:46.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:46.897+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:27:46.935+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:46.935+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:27:46.972+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:27:46.972+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:27:46.997+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T22:28:17.401+0000] {processor.py:157} INFO - Started process (PID=1873) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:17.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:28:17.406+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:17.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:17.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:17.515+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:17.515+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:28:17.563+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:17.563+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:28:17.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.206 seconds
[2023-11-02T22:28:47.753+0000] {processor.py:157} INFO - Started process (PID=1881) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:47.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:28:47.758+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:47.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:47.781+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:28:47.816+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:47.816+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:28:47.847+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:28:47.847+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:28:47.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-11-02T22:29:18.218+0000] {processor.py:157} INFO - Started process (PID=1891) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:18.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:29:18.222+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:18.221+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:18.247+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:18.286+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:18.285+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:29:18.322+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:18.322+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:29:18.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-11-02T22:29:48.606+0000] {processor.py:157} INFO - Started process (PID=1899) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:48.608+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:29:48.610+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:48.610+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:48.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:29:48.669+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:48.669+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:29:48.699+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:29:48.699+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:29:48.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-11-02T22:30:19.007+0000] {processor.py:157} INFO - Started process (PID=1908) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:19.009+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:30:19.013+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:19.012+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:19.040+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:19.073+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:19.073+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:30:19.101+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:19.101+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:30:19.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T22:30:49.435+0000] {processor.py:157} INFO - Started process (PID=1916) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:49.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:30:49.438+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:49.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:49.459+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:30:49.492+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:49.492+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:30:49.523+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:30:49.523+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:30:49.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-11-02T22:31:19.764+0000] {processor.py:157} INFO - Started process (PID=1924) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:19.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:31:19.768+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:19.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:19.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:19.825+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:19.825+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:31:19.855+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:19.855+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:31:19.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-11-02T22:31:50.209+0000] {processor.py:157} INFO - Started process (PID=1932) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:50.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:31:50.213+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:50.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:50.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:31:50.268+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:50.268+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:31:50.297+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:31:50.296+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:31:50.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:32:20.586+0000] {processor.py:157} INFO - Started process (PID=1940) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:20.588+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:32:20.590+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:20.590+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:20.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:20.649+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:20.649+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:32:20.679+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:20.679+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:32:20.703+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-11-02T22:32:50.993+0000] {processor.py:157} INFO - Started process (PID=1948) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:50.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:32:50.997+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:50.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:51.020+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:32:51.053+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:51.053+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:32:51.084+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:32:51.084+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:32:51.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T22:33:21.389+0000] {processor.py:157} INFO - Started process (PID=1956) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:21.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:33:21.400+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:21.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:21.441+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:21.473+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:21.473+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:33:21.502+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:21.502+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:33:21.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-11-02T22:33:51.764+0000] {processor.py:157} INFO - Started process (PID=1964) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:51.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:33:51.767+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:51.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:51.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:33:51.824+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:51.824+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:33:51.865+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:33:51.865+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:33:51.901+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-11-02T22:34:22.177+0000] {processor.py:157} INFO - Started process (PID=1972) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:22.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:34:22.183+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:22.183+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:22.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:22.240+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:22.239+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:34:22.272+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:22.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:34:22.301+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-11-02T22:34:52.524+0000] {processor.py:157} INFO - Started process (PID=1980) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:52.526+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:34:52.528+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:52.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:52.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:34:52.583+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:52.582+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:34:52.612+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:34:52.612+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:34:52.642+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T22:35:22.939+0000] {processor.py:157} INFO - Started process (PID=1988) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:22.940+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:35:22.942+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:22.941+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:22.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:23.002+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:23.001+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:35:23.032+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:23.032+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:35:23.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-11-02T22:35:53.277+0000] {processor.py:157} INFO - Started process (PID=1996) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:53.279+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:35:53.282+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:53.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:53.307+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:35:53.342+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:53.342+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:35:53.378+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:35:53.378+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:35:53.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-11-02T22:36:23.681+0000] {processor.py:157} INFO - Started process (PID=2005) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:23.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:36:23.685+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:23.684+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:23.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:23.739+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:23.739+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:36:23.767+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:23.767+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:36:23.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-11-02T22:36:54.033+0000] {processor.py:157} INFO - Started process (PID=2013) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:54.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:36:54.038+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:54.037+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:54.063+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:36:54.096+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:54.096+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:36:54.125+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:36:54.125+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:36:54.179+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-11-02T22:37:24.422+0000] {processor.py:157} INFO - Started process (PID=2021) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:24.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:37:24.427+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:24.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:24.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:24.488+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:24.488+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:37:24.518+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:24.518+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:37:24.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T22:37:54.875+0000] {processor.py:157} INFO - Started process (PID=2029) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:54.877+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:37:54.880+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:54.879+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:54.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:37:54.939+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:54.939+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:37:54.968+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:37:54.968+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:37:54.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T22:38:25.195+0000] {processor.py:157} INFO - Started process (PID=2037) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:25.197+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:38:25.199+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:25.199+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:25.228+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:25.260+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:25.260+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:38:25.290+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:25.290+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:38:25.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:38:55.547+0000] {processor.py:157} INFO - Started process (PID=2045) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:55.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:38:55.553+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:55.553+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:55.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:38:55.631+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:55.631+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:38:55.664+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:38:55.664+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:38:55.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-11-02T22:39:25.935+0000] {processor.py:157} INFO - Started process (PID=2054) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:25.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:39:25.940+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:25.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:25.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:26.022+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:26.021+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:39:26.058+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:26.058+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:39:26.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.175 seconds
[2023-11-02T22:39:56.325+0000] {processor.py:157} INFO - Started process (PID=2062) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:56.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:39:56.329+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:56.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:56.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:39:56.390+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:56.390+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:39:56.424+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:39:56.424+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:39:56.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-11-02T22:40:26.817+0000] {processor.py:157} INFO - Started process (PID=2070) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:26.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:40:26.821+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:26.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:26.843+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:26.877+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:26.876+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:40:26.906+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:26.906+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:40:26.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-11-02T22:40:57.120+0000] {processor.py:157} INFO - Started process (PID=2078) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:57.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:40:57.123+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:57.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:57.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:40:57.177+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:57.177+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:40:57.207+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:40:57.207+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:40:57.233+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:41:27.489+0000] {processor.py:157} INFO - Started process (PID=2086) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:27.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:41:27.492+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:27.491+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:27.514+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:27.547+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:27.547+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:41:27.580+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:27.580+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:41:27.604+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:41:57.804+0000] {processor.py:157} INFO - Started process (PID=2094) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:57.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:41:57.809+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:57.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:57.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:41:57.868+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:57.868+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:41:57.897+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:41:57.897+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:41:57.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-11-02T22:42:28.239+0000] {processor.py:157} INFO - Started process (PID=2103) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:28.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:42:28.244+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:28.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:28.268+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:28.300+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:28.300+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:42:28.330+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:28.330+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:42:28.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-11-02T22:42:58.599+0000] {processor.py:157} INFO - Started process (PID=2111) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:58.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:42:58.603+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:58.603+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:58.630+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:42:58.668+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:58.668+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:42:58.699+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:42:58.699+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:42:58.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T22:43:28.961+0000] {processor.py:157} INFO - Started process (PID=2119) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:28.962+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:43:28.964+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:28.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:28.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:29.018+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:29.017+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:43:29.047+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:29.047+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:43:29.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-11-02T22:43:59.344+0000] {processor.py:157} INFO - Started process (PID=2128) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:59.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:43:59.348+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:59.347+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:59.368+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:43:59.404+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:59.403+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:43:59.433+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:43:59.433+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:43:59.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:44:29.654+0000] {processor.py:157} INFO - Started process (PID=2137) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:44:29.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:44:29.657+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:44:29.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:44:29.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:44:29.715+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:44:29.714+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:44:29.746+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:44:29.746+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:44:29.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-11-02T22:45:00.058+0000] {processor.py:157} INFO - Started process (PID=2145) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:00.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:45:00.062+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:00.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:00.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:00.117+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:00.116+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:45:00.147+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:00.146+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:45:00.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-11-02T22:45:30.423+0000] {processor.py:157} INFO - Started process (PID=2153) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:30.425+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:45:30.428+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:30.427+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:30.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:45:30.488+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:30.488+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:45:30.518+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:45:30.518+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:45:30.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T22:46:00.799+0000] {processor.py:157} INFO - Started process (PID=2162) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:00.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:46:00.803+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:00.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:00.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:00.861+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:00.861+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:46:00.890+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:00.889+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:46:00.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-11-02T22:46:31.173+0000] {processor.py:157} INFO - Started process (PID=2170) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:31.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:46:31.177+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:31.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:31.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:46:31.244+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:31.244+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:46:31.276+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:46:31.275+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:46:31.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T22:47:01.521+0000] {processor.py:157} INFO - Started process (PID=2185) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:01.536+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:47:01.539+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:01.538+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:01.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:01.608+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:01.608+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:47:01.643+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:01.643+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:47:01.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-11-02T22:47:31.880+0000] {processor.py:157} INFO - Started process (PID=2193) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:31.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:47:31.882+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:31.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:31.902+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:47:31.935+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:31.935+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:47:31.965+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:47:31.965+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:47:31.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-11-02T22:48:02.297+0000] {processor.py:157} INFO - Started process (PID=2201) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:02.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:48:02.300+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:02.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:02.322+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:02.355+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:02.355+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:48:02.383+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:02.383+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:48:02.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-11-02T22:48:32.669+0000] {processor.py:157} INFO - Started process (PID=2209) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:32.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:48:32.674+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:32.673+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:32.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:48:32.733+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:32.733+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:48:32.764+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:48:32.763+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:48:32.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-11-02T22:49:03.001+0000] {processor.py:157} INFO - Started process (PID=2217) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:03.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:49:03.004+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:03.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:03.027+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:03.061+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:03.060+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:49:03.090+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:03.090+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:49:03.114+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-11-02T22:49:33.338+0000] {processor.py:157} INFO - Started process (PID=2226) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:33.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:49:33.341+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:33.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:33.370+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:49:33.414+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:33.413+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:49:33.457+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:49:33.456+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:49:33.492+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-11-02T22:50:03.650+0000] {processor.py:157} INFO - Started process (PID=2234) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:03.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:50:03.654+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:03.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:03.694+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:03.733+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:03.733+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:50:03.765+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:03.765+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:50:03.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-11-02T22:50:33.956+0000] {processor.py:157} INFO - Started process (PID=2243) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:33.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:50:33.962+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:33.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:33.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:50:34.057+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:34.057+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:50:34.108+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:50:34.108+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:50:34.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.197 seconds
[2023-11-02T22:51:04.172+0000] {processor.py:157} INFO - Started process (PID=2251) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:04.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:51:04.176+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:04.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:04.200+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:04.238+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:04.238+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:51:04.271+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:04.271+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:51:04.312+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-11-02T22:51:34.453+0000] {processor.py:157} INFO - Started process (PID=2259) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:34.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:51:34.458+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:34.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:34.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:51:34.526+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:34.526+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:51:34.559+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:51:34.559+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:51:34.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-11-02T22:52:04.860+0000] {processor.py:157} INFO - Started process (PID=2266) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:04.866+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:52:04.868+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:04.867+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:04.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:04.921+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:04.921+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:52:04.949+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:04.949+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:52:04.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-11-02T22:52:35.092+0000] {processor.py:157} INFO - Started process (PID=2274) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:35.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:52:35.096+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:35.095+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:35.120+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:52:35.164+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:35.164+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:52:35.203+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:52:35.203+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:52:35.239+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-11-02T22:53:05.371+0000] {processor.py:157} INFO - Started process (PID=2282) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:05.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:53:05.374+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:05.373+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:05.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:05.439+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:05.438+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:53:05.480+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:05.479+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:53:05.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-11-02T22:53:35.552+0000] {processor.py:157} INFO - Started process (PID=2290) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:35.553+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:53:35.555+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:35.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:35.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:53:35.622+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:35.622+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:53:35.660+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:53:35.660+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:53:35.705+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-11-02T22:54:05.879+0000] {processor.py:157} INFO - Started process (PID=2298) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:05.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:54:05.882+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:05.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:05.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:05.959+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:05.959+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:54:06.004+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:06.003+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:54:06.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-11-02T22:54:36.172+0000] {processor.py:157} INFO - Started process (PID=2306) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:36.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:54:36.177+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:36.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:36.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:54:36.243+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:36.242+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:54:36.275+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:54:36.274+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:54:36.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-11-02T22:55:06.564+0000] {processor.py:157} INFO - Started process (PID=2314) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:06.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:55:06.568+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:06.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:06.598+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:06.653+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:06.652+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:55:06.700+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:06.700+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:55:06.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.179 seconds
[2023-11-02T22:55:36.809+0000] {processor.py:157} INFO - Started process (PID=2322) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:36.811+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:55:36.814+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:36.813+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:36.842+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:55:36.885+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:36.884+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:55:36.921+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:55:36.921+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:55:36.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-11-02T22:56:07.398+0000] {processor.py:157} INFO - Started process (PID=2330) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:07.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:56:07.422+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:07.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:07.536+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:08.020+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:08.019+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:56:08.544+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:08.543+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:56:09.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 2.279 seconds
[2023-11-02T22:56:39.990+0000] {processor.py:157} INFO - Started process (PID=2338) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:39.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-11-02T22:56:39.995+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:39.994+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:40.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Google_Job_Listings_Data_Pipeline']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-11-02T22:56:40.210+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:40.209+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-11-02T22:56:40.284+0000] {logging_mixin.py:150} INFO - [2023-11-02T22:56:40.284+0000] {dag.py:3508} INFO - Setting next_dagrun for Google_Job_Listings_Data_Pipeline to None, run_after=None
[2023-11-02T22:56:40.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.387 seconds
