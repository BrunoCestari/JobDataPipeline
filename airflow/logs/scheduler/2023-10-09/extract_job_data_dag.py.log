[2023-10-09T00:05:35.767+0000] {processor.py:157} INFO - Started process (PID=49) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:05:35.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:05:35.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:05:35.771+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:05:35.811+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:05:35.803+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:05:35.815+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:05:35.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.092 seconds
[2023-10-09T00:06:06.068+0000] {processor.py:157} INFO - Started process (PID=57) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:06.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:06:06.075+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:06:06.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:06.179+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:06:06.169+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:06:06.180+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:06.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.247 seconds
[2023-10-09T00:06:36.383+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:36.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:06:36.386+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:06:36.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:36.399+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:06:36.397+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:06:36.400+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:06:36.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.049 seconds
[2023-10-09T00:07:06.700+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:06.701+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:07:06.703+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:07:06.703+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:06.721+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:07:06.719+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:07:06.722+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:06.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-10-09T00:07:36.996+0000] {processor.py:157} INFO - Started process (PID=82) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:36.998+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:07:37.000+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:07:36.999+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:37.017+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:07:37.014+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:07:37.017+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:07:37.040+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.050 seconds
[2023-10-09T00:08:07.352+0000] {processor.py:157} INFO - Started process (PID=90) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:07.353+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:08:07.356+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:08:07.355+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:07.371+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:08:07.369+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:08:07.372+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:07.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.065 seconds
[2023-10-09T00:08:37.699+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:37.700+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:08:37.703+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:08:37.702+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:37.720+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:08:37.718+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:08:37.721+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:08:37.751+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.058 seconds
[2023-10-09T00:09:08.047+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:08.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:09:08.060+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:09:08.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:08.097+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:09:08.094+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:09:08.098+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:08.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.089 seconds
[2023-10-09T00:09:38.419+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:38.420+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:09:38.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:09:38.421+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:38.448+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:09:38.446+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:09:38.449+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:09:38.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.059 seconds
[2023-10-09T00:10:08.754+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:08.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:10:08.757+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:10:08.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:08.772+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:10:08.770+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:10:08.773+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:08.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.062 seconds
[2023-10-09T00:10:39.216+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:39.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:10:39.220+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:10:39.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:39.235+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:10:39.233+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:10:39.236+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:10:39.261+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.055 seconds
[2023-10-09T00:11:09.571+0000] {processor.py:157} INFO - Started process (PID=140) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:09.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:11:09.576+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:09.575+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:09.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:09.589+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['../webscrape:/tmp/raw_data']}
[2023-10-09T00:11:09.593+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:09.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.058 seconds
[2023-10-09T00:11:21.716+0000] {processor.py:157} INFO - Started process (PID=141) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:21.718+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:11:21.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:21.719+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:21.734+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:21.732+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape/webscrape.py:/tmp/raw_data']}
[2023-10-09T00:11:21.734+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:21.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-09T00:11:52.106+0000] {processor.py:157} INFO - Started process (PID=149) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:52.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:11:52.109+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:52.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:52.124+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:52.121+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape/webscrape.py:/tmp/raw_data']}
[2023-10-09T00:11:52.125+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:52.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.074 seconds
[2023-10-09T00:11:54.153+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:54.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:11:54.160+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:54.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:54.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:54.675+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:54.675+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:11:54.717+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:54.717+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:11:54.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.615 seconds
[2023-10-09T00:11:59.845+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:59.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:11:59.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:59.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:59.862+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:11:59.860+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape/webscrape.py:/tmp/raw_data']}
[2023-10-09T00:11:59.863+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:11:59.888+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.048 seconds
[2023-10-09T00:12:30.158+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:30.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:12:30.162+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:12:30.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:30.177+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:12:30.175+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 46, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape/webscrape.py:/tmp/raw_data']}
[2023-10-09T00:12:30.178+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:30.202+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T00:12:36.360+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:36.369+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:12:36.378+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:12:36.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:36.518+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:12:36.610+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:12:36.610+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:12:36.657+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:12:36.657+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:12:36.694+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.357 seconds
[2023-10-09T00:13:07.029+0000] {processor.py:157} INFO - Started process (PID=175) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:07.032+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:13:07.035+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:07.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:07.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:07.098+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:07.097+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:13:07.129+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:07.128+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:13:07.153+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T00:13:37.366+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:37.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:13:37.371+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:37.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:37.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:13:37.442+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:37.442+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:13:37.486+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:13:37.485+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:13:37.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T00:14:07.821+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:07.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:14:07.826+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:07.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:07.864+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:07.903+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:07.902+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:14:07.934+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:07.933+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:14:07.969+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T00:14:38.147+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:38.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:14:38.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:38.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:38.173+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:14:38.211+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:38.210+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:14:38.248+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:14:38.248+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:14:38.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T00:15:08.571+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:08.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:15:08.578+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:08.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:08.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:08.633+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:08.633+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:15:08.663+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:08.663+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:15:08.687+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T00:15:38.917+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:38.919+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:15:38.922+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:38.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:38.944+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:15:38.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:38.979+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:15:39.012+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:15:39.012+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:15:39.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T00:16:09.309+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:09.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:16:09.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:09.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:09.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:09.366+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:09.366+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:16:09.396+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:09.396+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:16:09.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T00:16:39.647+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:39.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:16:39.653+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:39.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:39.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:16:39.733+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:39.733+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:16:39.766+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:16:39.766+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:16:39.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T00:17:10.001+0000] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:10.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:17:10.004+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:10.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:10.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:10.077+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:10.076+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:17:10.118+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:10.118+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:17:10.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.183 seconds
[2023-10-09T00:17:40.319+0000] {processor.py:157} INFO - Started process (PID=248) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:40.321+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:17:40.324+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:40.323+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:40.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:17:40.416+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:40.416+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:17:40.449+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:17:40.449+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:17:40.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-10-09T00:18:10.812+0000] {processor.py:157} INFO - Started process (PID=256) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:10.817+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:18:10.825+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:10.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:10.889+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:11.037+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:11.037+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:18:11.071+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:11.070+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:18:11.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.304 seconds
[2023-10-09T00:18:41.181+0000] {processor.py:157} INFO - Started process (PID=264) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:41.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:18:41.191+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:41.190+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:41.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:18:41.267+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:41.266+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:18:41.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:18:41.296+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:18:41.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-09T00:19:11.451+0000] {processor.py:157} INFO - Started process (PID=272) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:11.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:19:11.454+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:11.453+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:11.476+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:11.516+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:11.516+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:19:11.546+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:11.546+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:19:11.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T00:19:41.777+0000] {processor.py:157} INFO - Started process (PID=280) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:41.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:19:41.781+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:41.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:41.801+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:19:41.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:41.845+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:19:41.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:19:41.886+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:19:41.918+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T00:21:01.106+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:01.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:21:01.112+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:01.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:01.239+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:01.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:01.598+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:21:01.660+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:01.660+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:21:01.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.817 seconds
[2023-10-09T00:21:32.214+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:32.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:21:32.219+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:32.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:32.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:21:32.292+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:32.292+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:21:32.324+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:21:32.323+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:21:32.348+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T00:22:02.507+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:02.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:22:02.512+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:02.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:02.548+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:02.583+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:02.583+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:22:02.613+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:02.613+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:22:02.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T00:22:32.964+0000] {processor.py:157} INFO - Started process (PID=72) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:32.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:22:32.973+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:32.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:32.995+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:22:33.027+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:33.027+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:22:33.057+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:22:33.057+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:22:33.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T00:23:03.294+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:03.295+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:23:03.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:03.296+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:03.318+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:03.350+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:03.350+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:23:03.382+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:03.382+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:23:03.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T00:23:33.588+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:33.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:23:33.591+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:33.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:33.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:23:33.649+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:33.648+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:23:33.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:23:33.681+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:23:33.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T00:24:03.934+0000] {processor.py:157} INFO - Started process (PID=98) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:03.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:24:03.939+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:03.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:03.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:03.996+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:03.996+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:24:04.029+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:04.029+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:24:04.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T00:24:34.338+0000] {processor.py:157} INFO - Started process (PID=106) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:34.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:24:34.342+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:34.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:34.364+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:24:34.397+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:34.397+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:24:34.429+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:24:34.429+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:24:34.453+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T00:25:04.669+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:04.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:25:04.673+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:04.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:04.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:04.740+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:04.740+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:25:04.778+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:04.778+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:25:04.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T00:25:35.090+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:35.094+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:25:35.096+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:35.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:35.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:25:35.163+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:35.162+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:25:35.193+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:25:35.193+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:25:35.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T00:26:05.478+0000] {processor.py:157} INFO - Started process (PID=131) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:05.479+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:26:05.482+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:05.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:05.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:05.539+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:05.539+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:26:05.571+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:05.570+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:26:05.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T00:26:35.849+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:35.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:26:35.854+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:35.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:35.882+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:26:35.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:35.917+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:26:35.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:26:35.948+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:26:35.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T00:27:06.273+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:06.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:27:06.276+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:06.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:06.297+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:06.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:06.330+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:27:06.361+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:06.360+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:27:06.414+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T00:27:36.562+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:36.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:27:36.564+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:36.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:36.583+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:27:36.617+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:36.616+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:27:36.649+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:27:36.649+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:27:36.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T00:28:06.997+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:07.003+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:28:07.005+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:07.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:07.039+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:07.112+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:07.112+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:28:07.188+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:07.188+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:28:07.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.237 seconds
[2023-10-09T00:28:37.375+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:37.381+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:28:37.387+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:37.386+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:37.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:28:37.652+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:37.651+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:28:37.764+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:28:37.763+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:28:37.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.504 seconds
[2023-10-09T00:29:08.217+0000] {processor.py:157} INFO - Started process (PID=180) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:08.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:29:08.220+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:08.219+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:08.245+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:08.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:08.282+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:29:08.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:08.314+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:29:08.347+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T00:29:38.504+0000] {processor.py:157} INFO - Started process (PID=187) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:38.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:29:38.509+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:38.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:38.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:29:38.571+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:38.570+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:29:38.604+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:29:38.604+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:29:38.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T00:30:09.004+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:09.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:30:09.009+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:09.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:09.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:09.072+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:09.072+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:30:09.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:09.110+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:30:09.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T00:30:39.303+0000] {processor.py:157} INFO - Started process (PID=204) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:39.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:30:39.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:39.306+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:39.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:30:39.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:39.358+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:30:39.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:30:39.389+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:30:39.412+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T00:31:09.841+0000] {processor.py:157} INFO - Started process (PID=212) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:09.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:31:09.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:09.844+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:09.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:09.898+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:09.898+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:31:09.928+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:09.927+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:31:09.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T00:31:40.138+0000] {processor.py:157} INFO - Started process (PID=220) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:40.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:31:40.145+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:40.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:40.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:31:40.204+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:40.203+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:31:40.233+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:31:40.233+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:31:40.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T00:32:10.622+0000] {processor.py:157} INFO - Started process (PID=227) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:10.623+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:32:10.625+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:10.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:10.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:10.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:10.681+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:32:10.710+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:10.710+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:32:10.749+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T00:32:40.955+0000] {processor.py:157} INFO - Started process (PID=236) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:40.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:32:40.958+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:40.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:40.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:32:41.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:41.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:32:41.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:32:41.056+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:32:41.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T00:33:11.307+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:11.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:33:11.310+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:11.309+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:11.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:11.368+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:11.368+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:33:11.399+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:11.398+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:33:11.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T00:33:41.605+0000] {processor.py:157} INFO - Started process (PID=252) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:41.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:33:41.607+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:41.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:41.629+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:33:41.670+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:41.670+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:33:41.714+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:33:41.713+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:33:41.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T00:34:12.019+0000] {processor.py:157} INFO - Started process (PID=260) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:12.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:34:12.022+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:12.021+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:12.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:12.076+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:12.076+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:34:12.108+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:12.107+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:34:12.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T00:34:42.378+0000] {processor.py:157} INFO - Started process (PID=268) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:42.380+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:34:42.382+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:42.382+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:42.417+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:34:42.462+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:42.462+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:34:42.494+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:34:42.494+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:34:42.517+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T00:35:12.722+0000] {processor.py:157} INFO - Started process (PID=276) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:12.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:35:12.725+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:12.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:12.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:12.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:12.780+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:35:12.812+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:12.812+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:35:12.836+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T00:35:43.098+0000] {processor.py:157} INFO - Started process (PID=284) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:43.099+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:35:43.100+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:43.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:43.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:35:43.157+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:43.157+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:35:43.203+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:35:43.203+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:35:43.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-10-09T00:36:13.509+0000] {processor.py:157} INFO - Started process (PID=293) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:13.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:36:13.513+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:13.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:13.534+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:13.567+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:13.567+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:36:13.597+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:13.597+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:36:13.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T00:36:43.866+0000] {processor.py:157} INFO - Started process (PID=301) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:43.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:36:43.871+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:43.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:43.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:36:43.932+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:43.931+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:36:43.963+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:36:43.963+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:36:43.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T00:37:14.246+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:14.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:37:14.252+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:14.251+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:14.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:14.317+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:14.317+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:37:14.347+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:14.347+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:37:14.372+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T00:37:44.600+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:44.602+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:37:44.604+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:44.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:44.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:37:44.660+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:44.660+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:37:44.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:37:44.690+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:37:44.745+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T00:38:14.948+0000] {processor.py:157} INFO - Started process (PID=327) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:14.956+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:38:14.961+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:14.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:14.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:15.015+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:15.015+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:38:15.044+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:15.044+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:38:15.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T00:38:45.301+0000] {processor.py:157} INFO - Started process (PID=335) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:45.303+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:38:45.305+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:45.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:45.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:38:45.369+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:45.368+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:38:45.403+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:38:45.402+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:38:45.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.196 seconds
[2023-10-09T00:39:15.719+0000] {processor.py:157} INFO - Started process (PID=343) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:15.721+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:39:15.724+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:15.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:15.751+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:15.784+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:15.784+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:39:15.814+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:15.814+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:39:15.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T00:39:46.124+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:46.131+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:39:46.138+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:46.136+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:46.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:39:46.257+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:46.257+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:39:46.293+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:39:46.292+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:39:46.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.231 seconds
[2023-10-09T00:40:16.494+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:16.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:40:16.498+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:16.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:16.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:16.582+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:16.582+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:40:16.615+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:16.615+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:40:16.643+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.156 seconds
[2023-10-09T00:40:46.972+0000] {processor.py:157} INFO - Started process (PID=367) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:46.974+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:40:46.976+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:46.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:46.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:40:47.031+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:47.031+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:40:47.061+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:40:47.061+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:40:47.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T00:41:17.311+0000] {processor.py:157} INFO - Started process (PID=375) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:17.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:41:17.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:17.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:17.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:17.381+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:17.380+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:41:17.416+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:17.416+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:41:17.441+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T00:41:47.615+0000] {processor.py:157} INFO - Started process (PID=382) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:47.617+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:41:47.620+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:47.619+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:47.644+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:41:47.678+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:47.678+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:41:47.707+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:41:47.707+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:41:47.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T00:42:18.036+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:18.038+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:42:18.041+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:18.040+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:18.068+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:18.114+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:18.114+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:42:18.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:18.150+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:42:18.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T00:42:48.311+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:48.313+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:42:48.315+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:48.314+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:48.340+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:42:48.378+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:48.378+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:42:48.413+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:42:48.412+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:42:48.438+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T00:43:18.661+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:18.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:43:18.664+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:18.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:18.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:18.728+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:18.728+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:43:18.762+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:18.762+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:43:18.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T00:43:49.073+0000] {processor.py:157} INFO - Started process (PID=415) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:49.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:43:49.079+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:49.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:49.106+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:43:49.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:49.172+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:43:49.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:43:49.205+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:43:49.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.175 seconds
[2023-10-09T00:44:19.435+0000] {processor.py:157} INFO - Started process (PID=423) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:19.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:44:19.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:19.438+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:19.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:19.490+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:19.490+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T00:44:19.526+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:19.526+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T00:44:19.552+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T00:44:22.582+0000] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:22.583+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:44:22.586+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:22.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:22.616+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:22.612+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:44:22.616+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:22.647+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.070 seconds
[2023-10-09T00:44:52.907+0000] {processor.py:157} INFO - Started process (PID=432) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:52.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:44:52.912+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:52.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:52.933+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:44:52.930+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:44:52.933+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:44:52.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.061 seconds
[2023-10-09T00:45:23.274+0000] {processor.py:157} INFO - Started process (PID=440) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:23.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:45:23.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:23.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:23.292+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:23.290+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:45:23.293+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:23.319+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T00:45:53.575+0000] {processor.py:157} INFO - Started process (PID=449) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:53.576+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:45:53.578+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:53.577+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:53.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:53.590+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:45:53.593+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:53.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.055 seconds
[2023-10-09T00:45:57.641+0000] {processor.py:157} INFO - Started process (PID=450) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:57.643+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:45:57.647+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:57.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:57.675+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:45:57.672+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:45:57.676+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:45:57.701+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.070 seconds
[2023-10-09T00:46:00.709+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:00.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:46:00.712+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:46:00.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:00.729+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:46:00.726+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:46:00.729+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:00.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.049 seconds
[2023-10-09T00:46:31.134+0000] {processor.py:157} INFO - Started process (PID=460) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:31.135+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:46:31.137+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:46:31.137+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:31.151+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:46:31.149+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:46:31.152+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:46:31.184+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T00:47:01.428+0000] {processor.py:157} INFO - Started process (PID=468) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:01.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:47:01.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:47:01.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:01.443+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:47:01.441+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:47:01.444+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:01.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-10-09T00:47:31.804+0000] {processor.py:157} INFO - Started process (PID=476) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:31.813+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:47:31.815+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:47:31.815+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:31.833+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:47:31.830+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:47:31.834+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:47:31.858+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-10-09T00:48:02.161+0000] {processor.py:157} INFO - Started process (PID=484) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:02.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:48:02.164+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:02.163+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:02.181+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:02.178+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'docker_volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp/raw_data']}
[2023-10-09T00:48:02.181+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:02.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T00:48:22.360+0000] {processor.py:157} INFO - Started process (PID=492) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:22.361+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:48:22.363+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:22.362+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:22.382+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:22.379+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp']}
[2023-10-09T00:48:22.383+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:22.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T00:48:52.708+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:52.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:48:52.712+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:52.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:52.725+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:48:52.723+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp']}
[2023-10-09T00:48:52.726+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:48:52.758+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.059 seconds
[2023-10-09T00:49:23.097+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:23.099+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:49:23.101+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:49:23.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:23.116+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:49:23.113+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp']}
[2023-10-09T00:49:23.117+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:23.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-10-09T00:49:53.446+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:53.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:49:53.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:49:53.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:53.465+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:49:53.463+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 44, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'volumes': ['/home/bccestari/Desktop/repos/JobDataPipeline/webscrape:/tmp']}
[2023-10-09T00:49:53.466+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:49:53.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T00:50:09.630+0000] {processor.py:157} INFO - Started process (PID=525) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:09.631+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:50:09.633+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:50:09.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:09.650+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:50:09.649+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:50:09.651+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:09.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T00:50:40.000+0000] {processor.py:157} INFO - Started process (PID=534) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:40.002+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:50:40.005+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:50:40.004+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:40.024+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:50:40.022+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:50:40.025+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:50:40.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.057 seconds
[2023-10-09T00:51:10.470+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:10.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:51:10.473+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:51:10.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:10.486+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:51:10.484+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:51:10.487+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:10.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.046 seconds
[2023-10-09T00:51:40.815+0000] {processor.py:157} INFO - Started process (PID=550) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:40.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:51:40.818+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:51:40.818+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:40.833+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:51:40.831+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:51:40.833+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:51:40.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.059 seconds
[2023-10-09T00:52:11.164+0000] {processor.py:157} INFO - Started process (PID=558) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:11.166+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:52:11.167+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:52:11.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:11.182+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:52:11.180+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:52:11.182+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:11.210+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.053 seconds
[2023-10-09T00:52:41.490+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:41.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:52:41.494+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:52:41.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:41.508+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:52:41.506+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:52:41.509+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:52:41.533+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-09T00:53:11.832+0000] {processor.py:157} INFO - Started process (PID=575) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:11.834+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:53:11.836+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:53:11.835+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:11.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:53:11.848+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:53:11.850+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:11.875+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.050 seconds
[2023-10-09T00:53:42.167+0000] {processor.py:157} INFO - Started process (PID=583) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:42.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:53:42.174+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:53:42.174+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:42.189+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:53:42.187+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:53:42.190+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:53:42.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.057 seconds
[2023-10-09T00:54:12.541+0000] {processor.py:157} INFO - Started process (PID=592) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:12.543+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:54:12.546+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:54:12.545+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:12.565+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:54:12.562+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:54:12.566+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:12.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.071 seconds
[2023-10-09T00:54:42.900+0000] {processor.py:157} INFO - Started process (PID=601) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:42.902+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:54:42.905+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:54:42.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:42.922+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:54:42.920+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:54:42.923+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:54:42.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.070 seconds
[2023-10-09T00:55:13.223+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:13.224+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:55:13.225+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:55:13.225+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:13.240+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:55:13.238+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:55:13.240+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:13.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-09T00:55:43.618+0000] {processor.py:157} INFO - Started process (PID=617) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:43.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:55:43.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:55:43.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:43.635+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:55:43.633+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:55:43.636+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:55:43.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-10-09T00:56:13.994+0000] {processor.py:157} INFO - Started process (PID=624) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:13.995+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:56:13.997+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:56:13.996+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:14.008+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:56:14.006+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:56:14.008+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:14.049+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-10-09T00:56:44.337+0000] {processor.py:157} INFO - Started process (PID=632) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:44.338+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:56:44.340+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:56:44.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:44.355+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:56:44.353+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:56:44.355+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:56:44.384+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T00:57:14.689+0000] {processor.py:157} INFO - Started process (PID=640) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:14.691+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:57:14.693+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:57:14.693+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:14.707+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:57:14.705+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:57:14.708+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:14.748+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.066 seconds
[2023-10-09T00:57:45.064+0000] {processor.py:157} INFO - Started process (PID=648) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:45.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:57:45.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:57:45.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:45.082+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:57:45.080+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:57:45.082+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:57:45.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.049 seconds
[2023-10-09T00:58:15.415+0000] {processor.py:157} INFO - Started process (PID=656) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:15.416+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:58:15.418+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:58:15.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:15.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:58:15.430+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:58:15.432+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:15.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T00:58:45.735+0000] {processor.py:157} INFO - Started process (PID=664) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:45.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:58:45.739+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:58:45.739+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:45.755+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:58:45.753+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:58:45.756+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:58:45.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T00:59:16.079+0000] {processor.py:157} INFO - Started process (PID=672) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:16.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:59:16.082+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:59:16.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:16.095+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:59:16.093+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:59:16.095+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:16.120+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.045 seconds
[2023-10-09T00:59:46.421+0000] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:46.423+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T00:59:46.425+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:59:46.425+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:46.439+0000] {logging_mixin.py:150} INFO - [2023-10-09T00:59:46.437+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T00:59:46.440+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T00:59:46.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.054 seconds
[2023-10-09T01:00:16.781+0000] {processor.py:157} INFO - Started process (PID=688) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:16.783+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:00:16.785+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:00:16.784+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:16.799+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:00:16.798+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:00:16.800+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:16.826+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T01:00:47.152+0000] {processor.py:157} INFO - Started process (PID=695) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:47.154+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:00:47.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:00:47.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:47.169+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:00:47.168+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:00:47.170+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:00:47.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-10-09T01:01:17.529+0000] {processor.py:157} INFO - Started process (PID=703) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:17.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:01:17.533+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:01:17.533+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:17.550+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:01:17.548+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:01:17.551+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:17.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T01:01:47.873+0000] {processor.py:157} INFO - Started process (PID=711) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:47.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:01:47.877+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:01:47.876+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:47.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:01:47.889+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:01:47.892+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:01:47.920+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.055 seconds
[2023-10-09T01:02:18.195+0000] {processor.py:157} INFO - Started process (PID=719) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:18.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:02:18.201+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:02:18.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:18.222+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:02:18.220+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:02:18.223+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:18.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.062 seconds
[2023-10-09T01:02:48.541+0000] {processor.py:157} INFO - Started process (PID=728) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:48.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:02:48.545+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:02:48.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:48.557+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:02:48.556+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:02:48.558+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:02:48.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.080 seconds
[2023-10-09T01:03:18.901+0000] {processor.py:157} INFO - Started process (PID=736) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:18.903+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:03:18.905+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:03:18.904+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:18.919+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:03:18.917+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:03:18.920+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:18.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T01:03:49.221+0000] {processor.py:157} INFO - Started process (PID=744) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:49.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:03:49.224+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:03:49.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:49.237+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:03:49.235+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:03:49.238+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:03:49.264+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-09T01:04:19.575+0000] {processor.py:157} INFO - Started process (PID=753) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:19.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:04:19.579+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:04:19.579+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:19.593+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:04:19.590+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:04:19.595+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:19.622+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T01:04:49.911+0000] {processor.py:157} INFO - Started process (PID=761) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:49.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:04:49.914+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:04:49.914+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:49.928+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:04:49.926+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:04:49.929+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:04:49.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.058 seconds
[2023-10-09T01:05:20.251+0000] {processor.py:157} INFO - Started process (PID=769) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:20.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:05:20.255+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:05:20.255+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:20.269+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:05:20.267+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:05:20.270+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:20.302+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.058 seconds
[2023-10-09T01:05:50.594+0000] {processor.py:157} INFO - Started process (PID=777) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:50.595+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:05:50.597+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:05:50.596+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:50.610+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:05:50.608+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:05:50.611+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:05:50.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-10-09T01:06:20.960+0000] {processor.py:157} INFO - Started process (PID=785) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:20.961+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:06:20.964+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:06:20.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:20.980+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:06:20.978+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:06:20.981+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:21.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T01:06:51.280+0000] {processor.py:157} INFO - Started process (PID=793) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:51.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:06:51.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:06:51.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:51.295+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:06:51.293+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:06:51.295+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:06:51.336+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-10-09T01:07:21.649+0000] {processor.py:157} INFO - Started process (PID=801) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:21.652+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:07:21.655+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:07:21.654+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:21.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:07:21.679+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:07:21.682+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:21.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.073 seconds
[2023-10-09T01:07:51.983+0000] {processor.py:157} INFO - Started process (PID=810) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:51.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:07:51.989+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:07:51.989+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:52.006+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:07:52.004+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:07:52.006+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:07:52.032+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.056 seconds
[2023-10-09T01:08:22.299+0000] {processor.py:157} INFO - Started process (PID=819) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:22.300+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:08:22.301+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:08:22.301+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:22.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:08:22.312+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:08:22.314+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:22.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-09T01:08:52.659+0000] {processor.py:157} INFO - Started process (PID=826) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:52.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:08:52.663+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:08:52.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:52.678+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:08:52.676+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:08:52.679+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:08:52.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.066 seconds
[2023-10-09T01:09:22.980+0000] {processor.py:157} INFO - Started process (PID=835) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:22.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:09:22.984+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:09:22.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:23.002+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:09:23.000+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:09:23.003+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:23.038+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.069 seconds
[2023-10-09T01:09:53.335+0000] {processor.py:157} INFO - Started process (PID=843) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:53.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:09:53.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:09:53.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:53.354+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:09:53.352+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:09:53.355+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:09:53.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.051 seconds
[2023-10-09T01:10:23.641+0000] {processor.py:157} INFO - Started process (PID=851) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:23.642+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:10:23.644+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:10:23.644+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:23.657+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:10:23.655+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:10:23.658+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:23.680+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-10-09T01:10:53.935+0000] {processor.py:157} INFO - Started process (PID=859) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:53.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:10:53.940+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:10:53.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:53.960+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:10:53.957+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:10:53.962+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:10:53.994+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.065 seconds
[2023-10-09T01:11:24.484+0000] {processor.py:157} INFO - Started process (PID=867) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:24.486+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:11:24.488+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:11:24.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:24.503+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:11:24.502+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 43, in <module>
    mounts= Mount(source="/home/bccestari/Desktop/repos/JobDataPipeline/webscrape", target="/tmp", type="bind"),
NameError: name 'Mount' is not defined
[2023-10-09T01:11:24.504+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:24.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.057 seconds
[2023-10-09T01:11:38.658+0000] {processor.py:157} INFO - Started process (PID=868) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:38.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:11:38.662+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:11:38.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:38.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:11:38.877+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:11:38.876+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:11:38.907+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:11:38.907+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:11:38.943+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.291 seconds
[2023-10-09T01:12:09.241+0000] {processor.py:157} INFO - Started process (PID=876) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:09.244+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:12:09.246+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:09.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:09.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:09.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:09.314+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:12:09.355+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:09.355+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:12:09.380+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T01:12:39.544+0000] {processor.py:157} INFO - Started process (PID=885) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:39.546+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:12:39.549+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:39.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:39.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:12:39.612+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:39.611+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:12:39.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:12:39.642+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:12:39.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T01:13:10.017+0000] {processor.py:157} INFO - Started process (PID=893) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:10.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:13:10.021+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:10.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:10.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:10.084+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:10.084+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:13:10.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:10.115+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:13:10.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-10-09T01:13:40.374+0000] {processor.py:157} INFO - Started process (PID=900) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:40.377+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:13:40.380+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:40.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:40.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:13:40.444+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:40.444+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:13:40.474+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:13:40.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:13:40.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T01:14:10.821+0000] {processor.py:157} INFO - Started process (PID=908) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:10.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:14:10.824+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:10.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:10.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:11.017+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:11.017+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:14:11.079+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:11.079+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:14:11.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.288 seconds
[2023-10-09T01:14:41.156+0000] {processor.py:157} INFO - Started process (PID=924) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:41.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:14:41.159+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:41.158+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:41.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:14:41.211+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:41.211+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:14:41.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:14:41.242+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:14:41.283+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T01:15:11.417+0000] {processor.py:157} INFO - Started process (PID=933) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:11.419+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:15:11.421+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:11.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:11.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:11.479+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:11.479+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:15:11.509+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:11.509+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:15:11.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T01:15:41.765+0000] {processor.py:157} INFO - Started process (PID=942) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:41.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:15:41.770+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:41.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:41.797+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:15:41.829+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:41.829+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:15:41.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:15:41.858+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:15:41.882+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T01:16:12.119+0000] {processor.py:157} INFO - Started process (PID=950) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:12.120+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:16:12.122+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:12.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:12.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:12.178+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:12.178+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:16:12.209+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:12.209+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:16:12.234+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T01:16:42.416+0000] {processor.py:157} INFO - Started process (PID=958) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:42.418+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:16:42.421+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:42.420+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:42.450+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:16:42.486+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:42.485+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:16:42.518+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:16:42.518+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:16:42.554+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T01:17:12.816+0000] {processor.py:157} INFO - Started process (PID=967) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:12.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:17:12.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:12.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:12.839+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:12.870+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:12.870+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:17:12.901+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:12.900+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:17:12.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T01:17:43.173+0000] {processor.py:157} INFO - Started process (PID=974) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:43.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:17:43.177+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:43.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:43.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:17:43.233+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:43.233+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:17:43.262+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:17:43.262+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:17:43.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T01:18:13.561+0000] {processor.py:157} INFO - Started process (PID=982) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:13.563+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:18:13.566+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:13.566+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:13.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:13.625+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:13.624+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:18:13.656+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:13.656+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:18:13.679+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T01:18:43.943+0000] {processor.py:157} INFO - Started process (PID=990) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:43.945+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:18:43.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:43.947+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:43.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:18:44.015+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:44.015+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:18:44.049+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:18:44.049+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:18:44.078+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T01:19:14.273+0000] {processor.py:157} INFO - Started process (PID=999) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:14.275+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:19:14.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:14.277+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:14.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:14.338+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:14.338+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:19:14.374+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:14.373+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:19:14.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T01:19:44.702+0000] {processor.py:157} INFO - Started process (PID=1007) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:44.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:19:44.707+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:44.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:44.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:19:44.768+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:44.768+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:19:44.804+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:19:44.804+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:19:44.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T01:20:15.058+0000] {processor.py:157} INFO - Started process (PID=1015) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:15.060+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:20:15.062+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:15.062+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:15.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:15.119+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:15.119+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:20:15.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:15.156+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:20:15.181+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T01:20:45.409+0000] {processor.py:157} INFO - Started process (PID=1023) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:45.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:20:45.417+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:45.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:45.446+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:20:45.481+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:45.481+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:20:45.513+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:20:45.513+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:20:45.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-10-09T01:21:15.816+0000] {processor.py:157} INFO - Started process (PID=1032) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:15.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:21:15.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:15.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:15.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:15.873+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:15.873+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:21:15.904+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:15.904+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:21:15.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T01:21:46.144+0000] {processor.py:157} INFO - Started process (PID=1041) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:46.145+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:21:46.147+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:46.146+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:46.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:21:46.203+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:46.203+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:21:46.235+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:21:46.235+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:21:46.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T01:22:16.549+0000] {processor.py:157} INFO - Started process (PID=1049) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:16.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:22:16.551+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:16.551+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:16.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:16.601+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:16.601+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:22:16.636+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:16.635+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:22:16.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T01:22:46.906+0000] {processor.py:157} INFO - Started process (PID=1057) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:46.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:22:46.914+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:46.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:46.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:22:46.993+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:46.993+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:22:47.028+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:22:47.028+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:22:47.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.181 seconds
[2023-10-09T01:23:17.299+0000] {processor.py:157} INFO - Started process (PID=1065) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:17.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:23:17.304+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:17.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:17.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:17.372+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:17.372+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:23:17.400+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:17.400+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:23:17.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T01:23:47.660+0000] {processor.py:157} INFO - Started process (PID=1074) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:47.661+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:23:47.663+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:47.662+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:47.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:23:47.731+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:47.731+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:23:47.773+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:23:47.773+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:23:47.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T01:24:17.999+0000] {processor.py:157} INFO - Started process (PID=1082) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:18.001+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:24:18.004+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:18.003+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:18.034+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:18.073+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:18.072+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:24:18.107+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:18.107+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:24:18.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T01:24:48.360+0000] {processor.py:157} INFO - Started process (PID=1091) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:48.362+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:24:48.365+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:48.364+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:48.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:24:48.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:48.422+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:24:48.451+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:24:48.451+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:24:48.474+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T01:25:18.729+0000] {processor.py:157} INFO - Started process (PID=1099) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:25:18.731+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:25:18.732+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:25:18.732+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:25:18.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:25:18.800+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:25:18.800+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:25:18.840+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:25:18.840+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:25:18.869+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T01:30:38.072+0000] {processor.py:157} INFO - Started process (PID=40) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:30:38.081+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:30:38.082+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:30:38.082+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:30:38.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:30:38.467+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:30:38.467+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:30:38.507+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:30:38.506+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:30:38.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.473 seconds
[2023-10-09T01:31:08.887+0000] {processor.py:157} INFO - Started process (PID=48) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:08.891+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:31:08.896+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:08.893+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:09.016+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:09.200+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:09.199+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:31:09.319+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:09.319+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:31:09.359+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.573 seconds
[2023-10-09T01:31:39.591+0000] {processor.py:157} INFO - Started process (PID=56) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:39.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:31:39.594+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:39.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:39.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:31:39.654+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:39.654+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:31:39.685+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:31:39.685+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:31:39.708+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T01:32:09.942+0000] {processor.py:157} INFO - Started process (PID=64) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:09.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:32:09.946+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:09.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:09.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:10.006+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:10.006+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:32:10.038+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:10.037+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:32:10.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T01:32:40.352+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:40.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:32:40.356+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:40.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:40.386+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:32:40.421+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:40.421+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:32:40.452+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:32:40.452+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:32:40.476+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T01:33:10.668+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:10.670+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:33:10.673+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:10.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:10.693+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:10.728+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:10.727+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:33:10.762+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:10.761+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:33:10.785+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T01:33:41.120+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:41.122+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:33:41.124+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:41.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:41.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:33:41.183+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:41.182+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:33:41.213+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:33:41.213+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:33:41.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T01:34:11.469+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:11.471+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:34:11.474+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:11.473+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:11.496+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:11.535+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:11.534+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:34:11.564+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:11.564+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:34:11.589+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T01:34:41.927+0000] {processor.py:157} INFO - Started process (PID=103) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:41.929+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:34:41.932+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:41.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:41.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:34:41.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:41.987+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:34:42.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:34:42.019+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:34:42.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T01:35:12.283+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:12.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:35:12.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:12.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:12.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:12.345+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:12.345+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:35:12.376+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:12.376+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:35:12.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T01:35:42.835+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:42.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:35:42.842+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:42.841+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:42.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:35:42.904+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:42.904+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:35:42.933+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:35:42.933+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:35:42.987+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-10-09T01:36:13.091+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:13.093+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:36:13.097+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:13.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:13.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:13.173+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:13.173+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:36:13.204+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:13.204+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:36:13.232+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T01:36:43.429+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:43.430+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:36:43.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:43.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:43.453+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:36:43.489+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:43.489+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:36:43.522+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:36:43.522+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:36:43.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T01:37:13.873+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:13.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:37:13.878+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:13.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:13.903+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:13.940+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:13.939+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:37:13.973+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:13.973+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:37:14.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-09T01:37:44.152+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:44.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:37:44.158+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:44.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:44.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:37:44.234+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:44.234+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:37:44.265+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:37:44.265+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:37:44.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T01:38:14.600+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:14.606+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:38:14.608+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:14.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:14.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:14.670+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:14.669+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:38:14.703+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:14.702+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:38:14.727+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T01:38:44.952+0000] {processor.py:157} INFO - Started process (PID=173) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:44.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:38:44.956+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:44.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:44.980+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:38:45.020+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:45.019+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:38:45.054+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:38:45.053+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:38:45.077+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T01:39:15.310+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:15.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:39:15.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:15.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:15.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:15.371+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:15.371+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:39:15.403+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:15.403+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:39:15.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T01:39:45.653+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:45.655+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:39:45.658+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:45.657+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:45.686+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:39:45.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:45.719+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:39:45.749+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:39:45.748+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:39:45.783+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T01:40:16.041+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:16.043+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:40:16.047+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:16.046+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:16.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:16.111+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:16.111+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:40:16.145+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:16.144+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:40:16.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T01:40:46.485+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:46.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:40:46.490+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:46.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:46.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:40:46.595+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:46.595+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:40:46.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:40:46.642+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:40:46.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-10-09T01:41:16.764+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:16.765+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:41:16.767+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:16.766+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:16.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:16.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:16.820+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:41:16.854+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:16.854+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:41:16.886+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T01:41:47.088+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:47.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:41:47.095+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:47.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:47.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:41:47.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:47.156+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:41:47.189+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:41:47.189+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:41:47.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T01:42:17.474+0000] {processor.py:157} INFO - Started process (PID=229) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:17.475+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:42:17.477+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:17.477+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:17.502+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:17.537+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:17.537+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:42:17.571+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:17.571+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:42:17.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T01:42:47.807+0000] {processor.py:157} INFO - Started process (PID=237) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:47.810+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:42:47.812+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:47.811+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:47.843+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:42:47.879+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:47.879+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:42:47.915+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:42:47.915+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:42:47.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T01:43:18.239+0000] {processor.py:157} INFO - Started process (PID=245) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:18.241+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:43:18.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:18.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:18.262+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:18.299+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:18.299+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:43:18.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:18.329+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:43:18.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T01:43:48.608+0000] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:48.610+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:43:48.612+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:48.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:48.646+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:43:48.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:48.681+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:43:48.715+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:43:48.715+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:43:48.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-09T01:44:18.942+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:18.943+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:44:18.944+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:18.944+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:18.964+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:19.000+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:19.000+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:44:19.030+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:19.030+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:44:19.053+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T01:44:49.283+0000] {processor.py:157} INFO - Started process (PID=269) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:49.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:44:49.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:49.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:49.309+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:44:49.341+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:49.341+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:44:49.371+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:44:49.371+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:44:49.398+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T01:45:19.593+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:19.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:45:19.595+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:19.595+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:19.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:19.650+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:19.650+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:45:19.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:19.681+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:45:19.717+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T01:45:50.045+0000] {processor.py:157} INFO - Started process (PID=286) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:50.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:45:50.048+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:50.047+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:50.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:45:50.099+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:50.099+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:45:50.130+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:45:50.130+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:45:50.152+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-10-09T01:46:20.333+0000] {processor.py:157} INFO - Started process (PID=294) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:20.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:46:20.336+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:20.336+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:20.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:20.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:20.389+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:46:20.419+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:20.419+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:46:20.443+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T01:46:50.765+0000] {processor.py:157} INFO - Started process (PID=303) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:50.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:46:50.769+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:50.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:50.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:46:50.827+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:50.826+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:46:50.857+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:46:50.857+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:46:50.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T01:47:21.121+0000] {processor.py:157} INFO - Started process (PID=311) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:21.125+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:47:21.128+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:21.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:21.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:21.202+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:21.201+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:47:21.232+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:21.232+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:47:21.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T01:47:51.515+0000] {processor.py:157} INFO - Started process (PID=319) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:51.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:47:51.520+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:51.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:51.558+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:47:51.641+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:51.641+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:47:51.693+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:47:51.693+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:47:51.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.265 seconds
[2023-10-09T01:48:21.906+0000] {processor.py:157} INFO - Started process (PID=328) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:21.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:48:21.910+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:21.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:21.933+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:21.980+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:21.980+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:48:22.014+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:22.013+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:48:22.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T01:48:52.324+0000] {processor.py:157} INFO - Started process (PID=337) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:52.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:48:52.328+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:52.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:52.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:48:52.382+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:52.382+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:48:52.412+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:48:52.412+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:48:52.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T01:49:22.621+0000] {processor.py:157} INFO - Started process (PID=345) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:22.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:49:22.629+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:22.629+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:22.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:22.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:22.690+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:49:22.720+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:22.720+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:49:22.744+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T01:49:53.022+0000] {processor.py:157} INFO - Started process (PID=353) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:53.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:49:53.026+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:53.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:53.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:49:53.085+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:53.085+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:49:53.114+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:49:53.114+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:49:53.170+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-10-09T01:50:23.448+0000] {processor.py:157} INFO - Started process (PID=361) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:23.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:50:23.453+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:23.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:23.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:23.513+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:23.513+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:50:23.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:23.542+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:50:23.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T01:50:53.842+0000] {processor.py:157} INFO - Started process (PID=370) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:53.856+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:50:53.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:53.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:53.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:53.919+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:53.919+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:50:53.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:53.948+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:50:53.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T01:50:57.962+0000] {processor.py:157} INFO - Started process (PID=371) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:57.964+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:50:57.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:57.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:57.994+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:50:57.989+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:50:57.995+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:50:58.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.078 seconds
[2023-10-09T01:51:03.090+0000] {processor.py:157} INFO - Started process (PID=372) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:03.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:51:03.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:51:03.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:03.112+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:51:03.109+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:51:03.113+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:03.146+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.063 seconds
[2023-10-09T01:51:33.449+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:33.450+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:51:33.453+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:51:33.452+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:33.468+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:51:33.466+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:51:33.469+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:51:33.498+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.057 seconds
[2023-10-09T01:52:03.770+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:03.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:52:03.793+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:52:03.791+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:03.826+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:52:03.823+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:52:03.827+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:03.857+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.093 seconds
[2023-10-09T01:52:34.088+0000] {processor.py:157} INFO - Started process (PID=396) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:34.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:52:34.091+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:52:34.090+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:34.105+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:52:34.103+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:52:34.106+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:52:34.141+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.060 seconds
[2023-10-09T01:53:04.486+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:04.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:53:04.490+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:53:04.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:04.507+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:53:04.505+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:53:04.508+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:04.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.055 seconds
[2023-10-09T01:53:34.833+0000] {processor.py:157} INFO - Started process (PID=411) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:34.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:53:34.840+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:53:34.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:34.860+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:53:34.857+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:53:34.862+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:53:34.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.068 seconds
[2023-10-09T01:54:05.154+0000] {processor.py:157} INFO - Started process (PID=420) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:05.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:54:05.157+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:54:05.156+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:05.173+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:54:05.171+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:54:05.174+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:05.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.053 seconds
[2023-10-09T01:54:35.532+0000] {processor.py:157} INFO - Started process (PID=428) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:35.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:54:35.536+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:54:35.536+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:35.555+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:54:35.552+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:54:35.556+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:54:35.581+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.055 seconds
[2023-10-09T01:55:05.854+0000] {processor.py:157} INFO - Started process (PID=437) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:05.857+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:55:05.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:55:05.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:05.875+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:55:05.873+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 48, in <module>
    dag=dag,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/docker/operators/docker.py", line 227, in __init__
    super().__init__(**kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 429, in apply_defaults
    result = func(self, **kwargs, default_args=default_args)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/baseoperator.py", line 789, in __init__
    f"Invalid arguments were passed to {self.__class__.__name__} (task_id: {task_id}). "
airflow.exceptions.AirflowException: Invalid arguments were passed to DockerOperator (task_id: run_script_in_docker). Invalid arguments were:
**kwargs: {'mount': [{'Target': '/tmp', 'Source': '/home/bccestari/Desktop/repos/JobDataPipeline/webscrape', 'Type': 'bind', 'ReadOnly': False}]}
[2023-10-09T01:55:05.876+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:05.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.057 seconds
[2023-10-09T01:55:34.131+0000] {processor.py:157} INFO - Started process (PID=445) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:34.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:55:34.135+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:55:34.134+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:34.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:55:34.375+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:55:34.375+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:55:34.411+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:55:34.410+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:55:34.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.328 seconds
[2023-10-09T01:56:04.545+0000] {processor.py:157} INFO - Started process (PID=453) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:04.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:56:04.548+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:04.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:04.571+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:04.608+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:04.607+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:56:04.647+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:04.647+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:56:04.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T01:56:34.846+0000] {processor.py:157} INFO - Started process (PID=461) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:34.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:56:34.849+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:34.849+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:34.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:56:34.912+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:34.912+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:56:34.944+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:56:34.944+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:56:34.977+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T01:57:05.224+0000] {processor.py:157} INFO - Started process (PID=469) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:05.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:57:05.228+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:05.227+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:05.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:05.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:05.290+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:57:05.325+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:05.325+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:57:05.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T01:57:35.504+0000] {processor.py:157} INFO - Started process (PID=477) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:35.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:57:35.508+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:35.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:35.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:57:35.575+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:35.575+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:57:35.619+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:57:35.619+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:57:35.648+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T01:58:05.921+0000] {processor.py:157} INFO - Started process (PID=485) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:05.922+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:58:05.924+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:05.924+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:05.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:05.976+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:05.976+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:58:06.009+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:06.009+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:58:06.036+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T01:58:36.187+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:36.190+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:58:36.192+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:36.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:36.216+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:58:36.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:36.251+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:58:36.284+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:58:36.283+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:58:36.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T01:59:06.537+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:06.539+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:59:06.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:06.541+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:06.576+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:06.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:06.621+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:59:06.659+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:06.658+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:59:06.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T01:59:36.882+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:36.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T01:59:36.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:36.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:36.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T01:59:36.990+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:36.990+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T01:59:37.029+0000] {logging_mixin.py:150} INFO - [2023-10-09T01:59:37.029+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T01:59:37.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.183 seconds
[2023-10-09T02:00:07.317+0000] {processor.py:157} INFO - Started process (PID=518) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:07.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:00:07.327+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:07.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:07.884+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:07.928+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:07.928+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:00:07.983+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:07.983+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:00:08.008+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.704 seconds
[2023-10-09T02:00:38.158+0000] {processor.py:157} INFO - Started process (PID=526) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:38.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:00:38.161+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:38.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:38.187+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:00:38.228+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:38.227+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:00:38.270+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:00:38.269+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:00:38.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T02:01:08.679+0000] {processor.py:157} INFO - Started process (PID=534) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:08.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:01:08.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:08.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:08.733+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:08.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:08.787+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:01:09.042+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:09.042+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:01:09.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.556 seconds
[2023-10-09T02:01:39.570+0000] {processor.py:157} INFO - Started process (PID=542) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:39.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:01:39.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:39.574+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:39.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:01:39.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:39.642+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:01:39.677+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:01:39.676+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:01:39.704+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T02:02:09.861+0000] {processor.py:157} INFO - Started process (PID=550) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:09.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:02:09.875+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:09.873+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:09.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:09.958+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:09.958+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:02:09.992+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:09.991+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:02:10.024+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.168 seconds
[2023-10-09T02:02:40.327+0000] {processor.py:157} INFO - Started process (PID=558) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:40.328+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:02:40.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:40.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:40.349+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:02:40.380+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:40.380+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:02:40.409+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:02:40.409+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:02:40.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-10-09T02:03:10.673+0000] {processor.py:157} INFO - Started process (PID=566) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:10.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:03:10.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:10.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:10.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:10.741+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:10.741+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:03:10.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:10.771+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:03:10.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T02:03:41.017+0000] {processor.py:157} INFO - Started process (PID=574) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:41.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:03:41.022+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:41.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:41.055+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:03:41.108+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:41.107+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:03:41.148+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:03:41.148+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:03:41.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.169 seconds
[2023-10-09T02:04:11.369+0000] {processor.py:157} INFO - Started process (PID=582) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:04:11.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:04:11.373+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:04:11.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:04:11.402+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:04:11.453+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:04:11.453+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:04:11.496+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:04:11.495+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:04:11.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.176 seconds
[2023-10-09T02:06:16.572+0000] {processor.py:157} INFO - Started process (PID=37) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:16.579+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:06:16.587+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:16.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:16.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:16.733+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:16.732+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:06:16.795+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:16.794+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:06:16.839+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.275 seconds
[2023-10-09T02:06:46.973+0000] {processor.py:157} INFO - Started process (PID=45) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:46.975+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:06:46.976+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:46.976+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:47.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:06:47.045+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:47.044+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:06:47.084+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:06:47.084+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:06:47.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T02:07:17.350+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:17.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:07:17.353+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:17.353+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:17.374+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:17.411+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:17.411+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:07:17.445+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:17.445+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:07:17.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T02:07:48.051+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:48.053+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:07:48.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:48.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:48.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:07:48.190+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:48.189+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:07:48.260+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:07:48.259+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:07:48.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.290 seconds
[2023-10-09T02:08:18.781+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:18.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:08:18.810+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:18.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:19.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:19.578+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:19.577+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:08:20.449+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:20.449+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:08:21.042+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 2.506 seconds
[2023-10-09T02:08:51.661+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:51.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:08:51.737+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:51.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:51.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:08:52.662+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:52.662+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:08:52.717+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:08:52.717+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:08:52.863+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.221 seconds
[2023-10-09T02:09:22.917+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:09:22.921+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:09:22.923+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:09:22.922+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:09:22.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:09:23.112+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:09:23.111+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:09:23.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:09:23.276+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:09:23.341+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.432 seconds
[2023-10-09T02:13:01.017+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:01.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:13:01.022+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:01.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:01.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:01.528+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:01.527+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:13:01.589+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:01.589+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:13:01.629+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.615 seconds
[2023-10-09T02:13:31.851+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:31.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:13:31.854+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:31.853+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:31.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:13:31.953+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:31.953+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:13:32.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:13:32.002+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:13:32.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.214 seconds
[2023-10-09T02:14:02.091+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:02.092+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:14:02.094+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:02.094+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:02.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:02.163+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:02.162+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:14:02.197+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:02.197+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:14:02.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T02:14:25.283+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:25.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:14:25.287+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:25.287+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:25.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:25.354+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:25.353+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:14:25.392+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:25.392+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:14:25.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T02:14:55.751+0000] {processor.py:157} INFO - Started process (PID=77) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:55.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:14:55.759+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:55.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:55.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:14:56.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:56.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:14:56.128+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:14:56.127+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:14:56.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.464 seconds
[2023-10-09T02:15:26.479+0000] {processor.py:157} INFO - Started process (PID=85) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:26.483+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:15:26.484+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:26.484+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:26.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:26.568+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:26.567+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:15:26.617+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:26.617+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:15:26.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.180 seconds
[2023-10-09T02:15:56.728+0000] {processor.py:157} INFO - Started process (PID=93) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:56.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:15:56.739+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:56.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:56.802+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:15:56.846+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:56.846+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:15:56.882+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:15:56.882+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:15:56.914+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.204 seconds
[2023-10-09T02:16:27.089+0000] {processor.py:157} INFO - Started process (PID=101) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:27.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:16:27.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:27.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:27.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:27.174+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:27.174+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:16:27.219+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:27.219+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:16:27.247+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.166 seconds
[2023-10-09T02:16:57.354+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:57.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:16:57.357+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:57.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:57.377+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:16:57.414+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:57.413+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:16:57.448+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:16:57.447+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:16:57.477+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T02:17:23.726+0000] {processor.py:157} INFO - Started process (PID=111) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:23.727+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:17:23.729+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:23.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:23.762+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:23.803+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:23.803+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:17:23.839+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:23.839+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:17:23.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T02:17:54.015+0000] {processor.py:157} INFO - Started process (PID=119) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:54.018+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:17:54.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:54.019+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:54.042+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:17:54.081+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:54.081+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:17:54.113+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:17:54.113+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:17:54.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T02:18:04.254+0000] {processor.py:157} INFO - Started process (PID=127) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:04.255+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:18:04.257+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:04.256+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:04.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:04.343+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:04.343+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:18:04.397+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:04.396+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:18:04.431+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.182 seconds
[2023-10-09T02:18:09.377+0000] {processor.py:157} INFO - Started process (PID=128) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:09.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:18:09.393+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:09.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:09.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:09.521+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:09.521+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:18:09.572+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:09.572+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:18:09.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.259 seconds
[2023-10-09T02:18:39.775+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:39.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:18:39.779+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:39.778+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:39.804+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:18:39.843+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:39.843+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:18:39.881+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:18:39.881+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:18:39.922+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T02:19:10.200+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:10.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:19:10.203+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:10.202+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:10.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:10.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:10.297+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:19:10.326+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:10.325+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:19:10.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T02:19:40.458+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:40.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:19:40.462+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:40.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:40.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:19:40.556+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:40.556+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:19:40.612+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:19:40.611+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:19:40.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.201 seconds
[2023-10-09T02:20:10.931+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:10.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:20:10.934+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:10.933+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:10.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:10.995+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:10.995+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:20:11.029+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:11.029+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:20:11.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T02:20:41.220+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:41.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:20:41.224+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:41.224+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:41.256+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:20:41.303+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:41.303+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:20:41.344+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:20:41.344+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:20:41.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-10-09T02:21:11.600+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:11.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:21:11.612+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:11.609+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:11.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:11.768+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:11.768+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:21:11.884+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:11.884+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:21:11.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.380 seconds
[2023-10-09T02:21:42.238+0000] {processor.py:157} INFO - Started process (PID=187) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:42.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:21:42.241+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:42.240+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:42.266+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:21:42.428+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:42.428+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:21:42.519+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:21:42.519+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:21:42.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.330 seconds
[2023-10-09T02:22:12.865+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:12.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:22:12.871+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:12.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:12.899+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:12.943+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:12.943+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:22:12.984+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:12.983+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:22:13.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.169 seconds
[2023-10-09T02:22:43.107+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:43.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:22:43.113+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:43.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:43.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:22:43.198+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:43.197+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:22:43.244+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:22:43.243+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:22:43.281+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.181 seconds
[2023-10-09T02:23:13.599+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:13.601+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:23:13.603+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:13.602+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:13.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:13.674+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:13.674+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:23:13.711+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:13.711+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:23:13.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T02:23:20.674+0000] {processor.py:157} INFO - Started process (PID=215) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:20.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:23:20.678+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:20.677+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:20.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:23:20.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:20.780+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:23:20.838+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:23:20.837+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:23:20.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.222 seconds
[2023-10-09T02:28:01.259+0000] {processor.py:157} INFO - Started process (PID=292) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:01.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:28:01.264+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:01.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:01.294+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:01.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:01.339+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:28:01.388+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:01.388+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:28:01.421+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-09T02:28:31.574+0000] {processor.py:157} INFO - Started process (PID=300) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:31.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:28:31.587+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:31.585+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:31.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:28:31.709+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:31.709+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:28:31.748+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:28:31.748+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:28:31.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.226 seconds
[2023-10-09T02:29:01.957+0000] {processor.py:157} INFO - Started process (PID=309) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:01.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:29:01.961+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:01.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:01.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:02.029+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:02.029+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:29:02.064+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:02.064+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:29:02.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T02:29:32.321+0000] {processor.py:157} INFO - Started process (PID=316) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:32.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:29:32.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:32.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:32.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:29:32.407+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:32.407+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:29:32.442+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:29:32.441+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:29:32.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-10-09T02:30:02.643+0000] {processor.py:157} INFO - Started process (PID=324) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:02.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:30:02.647+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:02.646+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:02.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:02.749+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:02.749+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:30:02.778+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:02.778+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:30:02.825+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.189 seconds
[2023-10-09T02:30:33.056+0000] {processor.py:157} INFO - Started process (PID=333) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:33.058+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:30:33.060+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:33.059+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:33.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:30:33.121+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:33.120+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:30:33.163+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:30:33.163+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:30:33.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T02:31:03.310+0000] {processor.py:157} INFO - Started process (PID=341) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:03.311+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:31:03.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:03.312+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:03.337+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:03.373+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:03.373+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:31:03.405+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:03.405+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:31:03.465+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T02:31:33.730+0000] {processor.py:157} INFO - Started process (PID=349) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:33.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:31:33.734+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:33.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:33.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:31:33.790+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:33.789+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:31:33.821+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:31:33.821+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:31:33.854+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T02:32:04.057+0000] {processor.py:157} INFO - Started process (PID=358) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:04.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:32:04.061+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:04.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:04.084+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:04.118+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:04.118+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:32:04.149+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:04.148+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:32:04.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T02:32:34.415+0000] {processor.py:157} INFO - Started process (PID=366) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:34.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:32:34.419+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:34.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:34.440+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:32:34.472+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:34.472+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:32:34.506+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:32:34.506+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:32:34.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T02:33:04.780+0000] {processor.py:157} INFO - Started process (PID=373) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:04.782+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:33:04.783+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:04.783+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:04.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:04.842+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:04.842+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:33:04.872+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:04.872+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:33:04.896+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T02:33:35.171+0000] {processor.py:157} INFO - Started process (PID=381) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:35.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:33:35.176+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:35.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:35.202+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:33:35.235+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:35.235+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:33:35.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:33:35.266+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:33:35.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T02:34:05.494+0000] {processor.py:157} INFO - Started process (PID=390) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:05.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:34:05.498+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:05.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:05.522+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:05.555+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:05.555+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:34:05.589+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:05.589+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:34:05.651+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-10-09T02:34:35.893+0000] {processor.py:157} INFO - Started process (PID=398) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:35.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:34:35.899+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:35.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:35.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:34:35.966+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:35.966+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:34:36.002+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:34:36.001+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:34:36.027+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T02:35:06.237+0000] {processor.py:157} INFO - Started process (PID=406) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:06.238+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:35:06.240+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:06.239+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:06.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:06.296+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:06.296+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:35:06.327+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:06.327+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:35:06.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T02:35:36.585+0000] {processor.py:157} INFO - Started process (PID=414) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:36.587+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:35:36.590+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:36.589+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:36.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:35:36.683+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:36.683+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:35:36.714+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:35:36.714+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:35:36.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-10-09T02:36:06.851+0000] {processor.py:157} INFO - Started process (PID=422) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:06.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:36:06.856+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:06.855+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:06.885+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:06.942+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:06.942+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:36:06.995+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:06.995+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:36:07.057+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.214 seconds
[2023-10-09T02:36:37.182+0000] {processor.py:157} INFO - Started process (PID=430) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:37.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:36:37.187+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:37.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:37.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:36:37.307+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:37.306+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:36:37.357+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:36:37.357+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:36:37.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.211 seconds
[2023-10-09T02:37:07.608+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:07.609+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:37:07.611+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:07.611+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:07.632+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:07.667+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:07.667+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:37:07.699+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:07.698+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:37:07.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T02:37:38.019+0000] {processor.py:157} INFO - Started process (PID=446) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:38.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:37:38.024+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:38.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:38.051+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:37:38.088+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:38.088+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:37:38.121+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:37:38.121+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:37:38.149+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T02:38:08.319+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:08.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:38:08.322+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:08.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:08.343+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:08.378+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:08.378+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:38:08.407+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:08.407+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:38:08.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T02:38:38.648+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:38.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:38:38.651+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:38.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:38.679+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:38:38.715+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:38.715+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:38:38.755+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:38:38.754+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:38:38.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T02:39:08.950+0000] {processor.py:157} INFO - Started process (PID=470) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:08.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:39:08.954+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:08.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:08.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:09.031+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:09.031+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:39:09.062+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:09.062+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:39:09.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T02:39:39.324+0000] {processor.py:157} INFO - Started process (PID=478) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:39.326+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:39:39.328+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:39.327+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:39.354+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:39:39.390+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:39.389+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:39:39.425+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:39:39.425+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:39:39.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T02:40:09.693+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:09.695+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:40:09.697+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:09.696+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:09.721+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:09.755+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:09.755+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:40:09.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:09.788+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:40:09.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T02:40:40.022+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:40.024+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:40:40.026+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:40.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:40.053+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:40:40.088+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:40.088+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:40:40.119+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:40:40.119+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:40:40.142+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T02:41:10.365+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:10.367+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:41:10.370+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:10.369+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:10.394+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:10.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:10.430+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:41:10.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:10.460+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:41:10.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T02:41:40.730+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:40.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:41:40.733+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:40.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:40.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:41:40.789+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:40.789+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:41:40.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:41:40.820+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:41:40.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T02:42:11.083+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:11.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:42:11.086+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:11.086+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:11.110+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:11.144+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:11.143+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:42:11.174+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:11.173+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:42:11.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T02:42:41.391+0000] {processor.py:157} INFO - Started process (PID=525) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:41.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:42:41.394+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:41.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:41.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:42:41.448+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:41.448+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:42:41.480+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:42:41.480+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:42:41.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T02:43:11.894+0000] {processor.py:157} INFO - Started process (PID=533) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:11.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:43:11.899+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:11.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:11.920+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:11.953+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:11.953+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:43:11.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:11.987+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:43:12.011+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T02:43:42.273+0000] {processor.py:157} INFO - Started process (PID=540) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:42.277+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:43:42.280+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:42.280+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:42.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:43:42.353+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:42.352+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:43:42.383+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:43:42.383+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:43:42.405+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T02:44:12.695+0000] {processor.py:157} INFO - Started process (PID=548) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:12.696+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:44:12.698+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:12.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:12.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:12.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:12.771+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:44:12.802+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:12.802+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:44:12.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T02:44:43.018+0000] {processor.py:157} INFO - Started process (PID=556) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:43.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:44:43.023+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:43.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:43.057+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:44:43.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:43.089+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:44:43.118+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:44:43.118+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:44:43.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T02:45:13.412+0000] {processor.py:157} INFO - Started process (PID=564) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:13.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:45:13.415+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:13.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:13.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:13.467+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:13.466+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:45:13.496+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:13.496+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:45:13.534+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T02:45:43.754+0000] {processor.py:157} INFO - Started process (PID=572) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:43.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:45:43.758+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:43.757+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:43.779+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:45:43.817+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:43.816+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:45:43.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:45:43.848+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:45:43.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T02:46:14.071+0000] {processor.py:157} INFO - Started process (PID=580) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:14.072+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:46:14.074+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:14.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:14.096+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:14.129+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:14.129+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:46:14.159+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:14.159+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:46:14.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T02:46:44.466+0000] {processor.py:157} INFO - Started process (PID=589) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:44.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:46:44.469+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:44.469+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:44.492+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:46:44.526+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:44.526+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:46:44.555+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:46:44.555+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:46:44.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T02:47:14.806+0000] {processor.py:157} INFO - Started process (PID=597) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:14.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:47:14.810+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:14.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:14.831+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:14.865+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:14.865+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:47:14.893+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:14.893+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:47:14.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T02:47:45.181+0000] {processor.py:157} INFO - Started process (PID=605) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:45.183+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:47:45.186+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:45.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:45.220+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:47:45.262+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:45.261+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:47:45.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:47:45.290+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:47:45.314+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T02:48:15.617+0000] {processor.py:157} INFO - Started process (PID=613) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:15.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:48:15.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:15.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:15.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:15.673+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:15.673+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:48:15.703+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:15.703+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:48:15.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T02:48:45.967+0000] {processor.py:157} INFO - Started process (PID=621) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:45.969+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:48:45.971+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:45.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:46.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:48:46.034+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:46.034+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:48:46.065+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:48:46.065+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:48:46.089+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T02:49:16.280+0000] {processor.py:157} INFO - Started process (PID=629) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:16.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:49:16.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:16.283+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:16.305+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:16.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:16.339+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:49:16.368+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:16.368+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:49:16.411+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T02:49:46.717+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:46.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:49:46.721+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:46.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:46.741+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:49:46.774+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:46.774+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:49:46.804+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:49:46.804+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:49:46.830+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T02:50:17.054+0000] {processor.py:157} INFO - Started process (PID=645) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:17.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:50:17.059+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:17.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:17.083+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:17.116+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:17.116+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:50:17.145+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:17.144+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:50:17.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T02:50:47.449+0000] {processor.py:157} INFO - Started process (PID=653) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:47.452+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:50:47.455+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:47.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:47.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:50:47.521+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:47.520+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:50:47.550+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:50:47.550+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:50:47.579+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T02:51:17.801+0000] {processor.py:157} INFO - Started process (PID=661) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:17.802+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:51:17.804+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:17.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:17.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:17.859+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:17.859+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:51:17.893+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:17.893+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:51:17.917+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T02:51:48.182+0000] {processor.py:157} INFO - Started process (PID=669) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:48.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:51:48.186+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:48.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:48.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:51:48.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:48.241+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:51:48.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:51:48.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:51:48.294+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T02:52:18.544+0000] {processor.py:157} INFO - Started process (PID=677) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:18.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:52:18.550+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:18.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:18.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:18.611+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:18.611+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:52:18.640+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:18.640+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:52:18.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T02:52:48.899+0000] {processor.py:157} INFO - Started process (PID=685) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:48.901+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:52:48.903+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:48.902+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:48.924+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:52:48.956+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:48.956+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:52:48.985+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:52:48.985+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:52:49.019+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T02:53:19.285+0000] {processor.py:157} INFO - Started process (PID=693) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:19.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:53:19.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:19.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:19.310+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:19.341+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:19.341+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:53:19.370+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:19.370+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:53:19.404+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T02:53:49.622+0000] {processor.py:157} INFO - Started process (PID=702) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:49.624+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:53:49.626+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:49.625+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:49.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:53:49.683+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:49.683+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:53:49.715+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:53:49.714+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:53:49.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T02:54:20.008+0000] {processor.py:157} INFO - Started process (PID=710) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:20.011+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:54:20.013+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:20.013+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:20.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:20.070+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:20.070+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:54:20.100+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:20.100+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:54:20.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T02:54:50.347+0000] {processor.py:157} INFO - Started process (PID=718) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:50.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:54:50.351+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:50.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:50.375+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:54:50.408+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:50.408+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:54:50.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:54:50.438+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:54:50.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T02:55:20.739+0000] {processor.py:157} INFO - Started process (PID=726) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:20.741+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:55:20.744+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:20.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:20.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:20.808+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:20.808+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:55:20.837+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:20.837+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:55:20.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T02:55:51.032+0000] {processor.py:157} INFO - Started process (PID=734) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:51.034+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:55:51.036+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:51.035+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:51.060+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:55:51.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:51.092+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:55:51.123+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:55:51.123+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:55:51.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T02:56:21.511+0000] {processor.py:157} INFO - Started process (PID=743) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:21.512+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:56:21.515+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:21.514+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:21.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:21.570+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:21.570+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:56:21.600+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:21.599+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:56:21.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T02:56:51.857+0000] {processor.py:157} INFO - Started process (PID=751) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:51.859+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:56:51.862+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:51.861+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:51.895+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:56:51.930+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:51.930+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:56:51.959+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:56:51.959+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:56:51.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T02:57:22.258+0000] {processor.py:157} INFO - Started process (PID=759) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:22.260+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:57:22.262+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:22.261+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:22.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:22.316+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:22.316+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:57:22.346+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:22.346+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:57:22.369+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T02:57:52.664+0000] {processor.py:157} INFO - Started process (PID=767) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:52.665+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:57:52.667+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:52.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:52.687+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:57:52.718+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:52.718+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:57:52.748+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:57:52.747+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:57:52.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T02:58:23.038+0000] {processor.py:157} INFO - Started process (PID=775) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:23.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:58:23.041+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:23.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:23.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:23.095+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:23.094+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:58:23.124+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:23.124+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:58:23.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T02:58:53.355+0000] {processor.py:157} INFO - Started process (PID=783) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:53.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:58:53.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:53.358+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:53.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:58:53.416+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:53.416+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:58:53.445+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:58:53.445+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:58:53.468+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T02:59:23.774+0000] {processor.py:157} INFO - Started process (PID=791) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:23.775+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:59:23.778+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:23.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:23.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:23.831+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:23.831+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:59:23.861+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:23.860+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:59:23.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T02:59:54.088+0000] {processor.py:157} INFO - Started process (PID=799) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:54.089+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T02:59:54.091+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:54.091+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:54.110+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T02:59:54.146+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:54.146+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T02:59:54.180+0000] {logging_mixin.py:150} INFO - [2023-10-09T02:59:54.180+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T02:59:54.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T03:00:24.452+0000] {processor.py:157} INFO - Started process (PID=807) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:24.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:00:24.457+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:24.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:24.483+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:24.517+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:24.517+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:00:24.547+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:24.547+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:00:24.576+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T03:00:54.758+0000] {processor.py:157} INFO - Started process (PID=815) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:54.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:00:54.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:54.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:54.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:00:54.819+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:54.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:00:54.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:00:54.848+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:00:54.884+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T03:01:25.150+0000] {processor.py:157} INFO - Started process (PID=823) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:25.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:01:25.153+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:25.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:25.176+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:25.208+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:25.208+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:01:25.237+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:25.237+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:01:25.273+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T03:01:55.487+0000] {processor.py:157} INFO - Started process (PID=831) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:55.488+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:01:55.490+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:55.489+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:55.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:01:55.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:55.543+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:01:55.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:01:55.573+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:01:55.607+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T03:02:25.907+0000] {processor.py:157} INFO - Started process (PID=839) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:25.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:02:25.911+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:25.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:25.932+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:25.964+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:25.964+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:02:25.993+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:25.993+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:02:26.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:02:56.244+0000] {processor.py:157} INFO - Started process (PID=848) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:56.246+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:02:56.248+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:56.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:56.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:02:56.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:56.306+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:02:56.336+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:02:56.335+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:02:56.364+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:03:26.657+0000] {processor.py:157} INFO - Started process (PID=856) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:26.659+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:03:26.660+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:26.660+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:26.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:26.711+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:26.711+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:03:26.740+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:26.740+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:03:26.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T03:03:56.964+0000] {processor.py:157} INFO - Started process (PID=865) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:56.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:03:56.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:56.968+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:56.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:03:57.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:57.033+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:03:57.062+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:03:57.062+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:03:57.085+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:04:27.337+0000] {processor.py:157} INFO - Started process (PID=873) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:27.339+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:04:27.341+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:27.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:27.365+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:27.398+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:27.398+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:04:27.427+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:27.427+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:04:27.448+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:04:57.669+0000] {processor.py:157} INFO - Started process (PID=881) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:57.671+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:04:57.673+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:57.672+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:57.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:04:57.729+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:57.729+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:04:57.758+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:04:57.757+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:04:57.782+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:05:28.005+0000] {processor.py:157} INFO - Started process (PID=889) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:28.006+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:05:28.008+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:28.008+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:28.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:28.063+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:28.062+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:05:28.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:28.093+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:05:28.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:05:58.383+0000] {processor.py:157} INFO - Started process (PID=897) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:58.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:05:58.387+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:58.386+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:58.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:05:58.443+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:58.443+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:05:58.475+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:05:58.475+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:05:58.502+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:06:28.758+0000] {processor.py:157} INFO - Started process (PID=905) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:28.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:06:28.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:28.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:28.781+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:28.814+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:28.813+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:06:28.843+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:28.843+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:06:28.871+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:06:59.145+0000] {processor.py:157} INFO - Started process (PID=913) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:59.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:06:59.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:59.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:59.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:06:59.209+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:59.208+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:06:59.238+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:06:59.237+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:06:59.265+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T03:07:29.493+0000] {processor.py:157} INFO - Started process (PID=921) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:29.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:07:29.497+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:29.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:29.523+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:29.559+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:29.559+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:07:29.588+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:29.588+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:07:29.623+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T03:07:59.909+0000] {processor.py:157} INFO - Started process (PID=929) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:59.910+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:07:59.912+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:59.912+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:59.935+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:07:59.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:59.967+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:07:59.999+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:07:59.999+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:08:00.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:08:30.243+0000] {processor.py:157} INFO - Started process (PID=937) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:08:30.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:08:30.246+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:08:30.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:08:30.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:08:30.308+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:08:30.307+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:08:30.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:08:30.338+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:08:30.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:09:00.663+0000] {processor.py:157} INFO - Started process (PID=946) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:00.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:09:00.668+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:00.667+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:00.690+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:00.722+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:00.722+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:09:00.752+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:00.751+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:09:00.779+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T03:09:30.977+0000] {processor.py:157} INFO - Started process (PID=954) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:30.978+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:09:30.981+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:30.980+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:31.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:09:31.041+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:31.040+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:09:31.070+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:09:31.069+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:09:31.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T03:10:01.363+0000] {processor.py:157} INFO - Started process (PID=962) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:01.365+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:10:01.368+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:01.367+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:01.392+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:01.424+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:01.424+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:10:01.455+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:01.455+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:10:01.478+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T03:10:31.684+0000] {processor.py:157} INFO - Started process (PID=970) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:31.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:10:31.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:31.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:31.712+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:10:31.745+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:31.745+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:10:31.782+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:10:31.782+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:10:31.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T03:11:02.123+0000] {processor.py:157} INFO - Started process (PID=978) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:02.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:11:02.128+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:02.127+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:02.149+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:02.183+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:02.183+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:11:02.212+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:02.212+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:11:02.237+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:11:32.452+0000] {processor.py:157} INFO - Started process (PID=986) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:32.455+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:11:32.458+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:32.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:32.485+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:11:32.519+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:32.519+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:11:32.549+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:11:32.549+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:11:32.578+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T03:12:02.863+0000] {processor.py:157} INFO - Started process (PID=994) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:02.867+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:12:02.871+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:02.870+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:02.898+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:02.930+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:02.930+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:12:02.959+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:02.959+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:12:02.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T03:12:33.202+0000] {processor.py:157} INFO - Started process (PID=1002) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:33.204+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:12:33.206+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:33.206+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:33.236+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:12:33.271+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:33.271+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:12:33.300+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:12:33.300+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:12:33.350+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.156 seconds
[2023-10-09T03:13:03.594+0000] {processor.py:157} INFO - Started process (PID=1010) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:03.596+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:13:03.599+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:03.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:03.623+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:03.657+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:03.657+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:13:03.685+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:03.685+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:13:03.709+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:13:34.021+0000] {processor.py:157} INFO - Started process (PID=1018) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:34.023+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:13:34.026+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:34.025+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:34.049+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:13:34.081+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:34.081+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:13:34.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:13:34.110+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:13:34.134+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:14:04.381+0000] {processor.py:157} INFO - Started process (PID=1027) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:04.383+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:14:04.385+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:04.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:04.407+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:04.440+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:04.439+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:14:04.469+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:04.469+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:14:04.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T03:14:34.768+0000] {processor.py:157} INFO - Started process (PID=1035) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:34.770+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:14:34.773+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:34.772+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:34.799+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:14:34.831+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:34.831+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:14:34.863+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:14:34.862+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:14:34.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:15:05.101+0000] {processor.py:157} INFO - Started process (PID=1043) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:05.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:15:05.105+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:05.104+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:05.125+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:05.159+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:05.159+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:15:05.188+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:05.188+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:15:05.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T03:15:35.540+0000] {processor.py:157} INFO - Started process (PID=1051) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:35.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:15:35.544+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:35.543+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:35.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:15:35.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:35.597+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:15:35.626+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:15:35.626+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:15:35.663+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T03:16:05.900+0000] {processor.py:157} INFO - Started process (PID=1059) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:05.902+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:16:05.903+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:05.903+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:05.923+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:05.957+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:05.956+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:16:05.991+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:05.990+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:16:06.015+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T03:16:36.330+0000] {processor.py:157} INFO - Started process (PID=1067) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:36.332+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:16:36.334+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:36.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:36.356+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:16:36.388+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:36.387+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:16:36.416+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:16:36.416+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:16:36.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T03:17:06.681+0000] {processor.py:157} INFO - Started process (PID=1075) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:06.682+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:17:06.684+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:06.683+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:06.703+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:06.736+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:06.736+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:17:06.767+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:06.767+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:17:06.794+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:17:37.089+0000] {processor.py:157} INFO - Started process (PID=1083) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:37.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:17:37.092+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:37.092+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:37.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:17:37.149+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:37.149+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:17:37.182+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:17:37.182+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:17:37.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T03:18:07.465+0000] {processor.py:157} INFO - Started process (PID=1091) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:07.467+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:18:07.468+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:07.468+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:07.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:07.527+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:07.526+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:18:07.556+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:07.555+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:18:07.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:18:37.787+0000] {processor.py:157} INFO - Started process (PID=1099) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:37.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:18:37.790+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:37.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:37.814+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:18:37.861+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:37.860+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:18:37.904+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:18:37.904+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:18:37.929+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T03:19:08.148+0000] {processor.py:157} INFO - Started process (PID=1107) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:08.149+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:19:08.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:08.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:08.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:08.202+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:08.202+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:19:08.233+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:08.232+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:19:08.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T03:19:38.540+0000] {processor.py:157} INFO - Started process (PID=1115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:38.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:19:38.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:38.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:38.564+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:19:38.599+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:38.599+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:19:38.629+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:19:38.629+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:19:38.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:20:08.913+0000] {processor.py:157} INFO - Started process (PID=1124) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:08.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:20:08.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:08.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:08.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:08.975+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:08.974+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:20:09.008+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:09.007+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:20:09.031+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T03:20:39.241+0000] {processor.py:157} INFO - Started process (PID=1139) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:39.242+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:20:39.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:39.243+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:39.263+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:20:39.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:39.297+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:20:39.327+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:20:39.327+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:20:39.371+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T03:21:09.636+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:09.639+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:21:09.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:09.642+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:09.668+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:09.700+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:09.699+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:21:09.730+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:09.729+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:21:09.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:21:39.959+0000] {processor.py:157} INFO - Started process (PID=1155) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:39.961+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:21:39.964+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:39.963+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:39.994+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:21:40.028+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:40.028+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:21:40.058+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:21:40.057+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:21:40.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T03:22:10.348+0000] {processor.py:157} INFO - Started process (PID=1163) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:10.350+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:22:10.353+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:10.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:10.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:10.413+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:10.413+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:22:10.443+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:10.442+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:22:10.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:22:40.676+0000] {processor.py:157} INFO - Started process (PID=1171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:40.678+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:22:40.680+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:40.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:40.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:22:40.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:40.742+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:22:40.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:22:40.771+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:22:40.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T03:23:11.094+0000] {processor.py:157} INFO - Started process (PID=1179) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:11.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:23:11.097+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:11.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:11.118+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:11.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:11.150+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:23:11.180+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:11.180+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:23:11.214+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T03:23:41.426+0000] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:41.429+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:23:41.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:41.431+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:41.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:23:41.499+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:41.499+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:23:41.528+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:23:41.528+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:23:41.556+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T03:24:11.866+0000] {processor.py:157} INFO - Started process (PID=1195) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:11.868+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:24:11.870+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:11.869+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:11.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:11.924+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:11.924+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:24:11.954+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:11.954+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:24:11.978+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:24:42.207+0000] {processor.py:157} INFO - Started process (PID=1203) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:42.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:24:42.214+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:42.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:42.244+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:24:42.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:42.277+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:24:42.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:24:42.306+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:24:42.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T03:25:12.603+0000] {processor.py:157} INFO - Started process (PID=1212) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:12.605+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:25:12.607+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:12.607+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:12.634+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:12.665+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:12.665+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:25:12.695+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:12.695+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:25:12.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T03:25:42.932+0000] {processor.py:157} INFO - Started process (PID=1220) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:42.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:25:42.935+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:42.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:42.960+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:25:43.009+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:43.009+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:25:43.055+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:25:43.054+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:25:43.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.179 seconds
[2023-10-09T03:26:13.316+0000] {processor.py:157} INFO - Started process (PID=1228) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:13.317+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:26:13.319+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:13.318+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:13.338+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:13.374+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:13.373+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:26:13.405+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:13.404+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:26:13.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T03:26:43.741+0000] {processor.py:157} INFO - Started process (PID=1236) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:43.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:26:43.745+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:43.744+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:43.767+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:26:43.800+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:43.800+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:26:43.829+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:26:43.828+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:26:43.851+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:27:14.044+0000] {processor.py:157} INFO - Started process (PID=1244) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:14.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:27:14.049+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:14.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:14.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:14.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:14.110+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:27:14.139+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:14.139+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:27:14.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T03:27:44.426+0000] {processor.py:157} INFO - Started process (PID=1252) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:44.427+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:27:44.429+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:44.429+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:44.451+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:27:44.483+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:44.483+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:27:44.514+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:27:44.513+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:27:44.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:28:14.844+0000] {processor.py:157} INFO - Started process (PID=1260) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:14.846+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:28:14.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:14.847+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:14.870+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:14.901+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:14.901+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:28:14.931+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:14.931+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:28:14.959+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T03:28:45.198+0000] {processor.py:157} INFO - Started process (PID=1268) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:45.201+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:28:45.203+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:45.203+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:45.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:28:45.263+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:45.263+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:28:45.293+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:28:45.293+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:28:45.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T03:29:15.630+0000] {processor.py:157} INFO - Started process (PID=1276) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:15.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:29:15.635+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:15.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:15.661+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:15.694+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:15.693+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:29:15.724+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:15.723+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:29:15.746+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:29:45.965+0000] {processor.py:157} INFO - Started process (PID=1284) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:45.967+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:29:45.970+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:45.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:45.996+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:29:46.034+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:46.034+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:29:46.063+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:29:46.062+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:29:46.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T03:30:16.338+0000] {processor.py:157} INFO - Started process (PID=1293) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:16.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:30:16.343+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:16.343+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:16.371+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:16.403+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:16.403+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:30:16.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:16.432+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:30:16.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T03:30:46.685+0000] {processor.py:157} INFO - Started process (PID=1302) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:46.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:30:46.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:46.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:46.719+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:30:46.752+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:46.751+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:30:46.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:30:46.780+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:30:46.807+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:31:17.000+0000] {processor.py:157} INFO - Started process (PID=1311) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:17.001+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:31:17.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:17.002+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:17.023+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:17.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:17.056+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:31:17.087+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:17.086+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:31:17.111+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T03:31:47.400+0000] {processor.py:157} INFO - Started process (PID=1319) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:47.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:31:47.405+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:47.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:47.428+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:31:47.462+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:47.461+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:31:47.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:31:47.492+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:31:47.515+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T03:32:17.745+0000] {processor.py:157} INFO - Started process (PID=1327) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:17.746+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:32:17.749+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:17.748+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:17.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:17.808+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:17.808+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:32:17.838+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:17.838+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:32:17.865+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:32:48.152+0000] {processor.py:157} INFO - Started process (PID=1335) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:48.155+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:32:48.157+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:48.157+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:48.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:32:48.212+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:48.212+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:32:48.241+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:32:48.241+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:32:48.268+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T03:33:18.554+0000] {processor.py:157} INFO - Started process (PID=1343) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:18.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:33:18.557+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:18.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:18.580+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:18.612+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:18.612+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:33:18.645+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:18.645+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:33:18.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T03:33:48.917+0000] {processor.py:157} INFO - Started process (PID=1351) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:48.918+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:33:48.921+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:48.920+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:48.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:33:48.976+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:48.975+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:33:49.006+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:33:49.006+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:33:49.030+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T03:34:19.257+0000] {processor.py:157} INFO - Started process (PID=1359) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:19.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:34:19.260+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:19.259+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:19.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:19.321+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:19.321+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:34:19.351+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:19.351+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:34:19.374+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:34:49.583+0000] {processor.py:157} INFO - Started process (PID=1367) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:49.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:34:49.586+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:49.586+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:49.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:34:49.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:49.642+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:34:49.673+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:34:49.673+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:34:49.696+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:35:19.935+0000] {processor.py:157} INFO - Started process (PID=1375) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:19.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:35:19.939+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:19.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:19.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:19.997+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:19.996+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:35:20.027+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:20.027+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:35:20.052+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T03:35:50.248+0000] {processor.py:157} INFO - Started process (PID=1383) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:50.249+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:35:50.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:50.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:50.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:35:50.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:50.313+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:35:50.343+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:35:50.342+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:35:50.366+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:36:20.644+0000] {processor.py:157} INFO - Started process (PID=1391) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:20.645+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:36:20.647+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:20.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:20.667+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:20.700+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:20.700+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:36:20.730+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:20.729+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:36:20.788+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T03:36:50.958+0000] {processor.py:157} INFO - Started process (PID=1399) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:50.959+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:36:50.962+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:50.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:50.983+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:36:51.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:51.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:36:51.048+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:36:51.048+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:36:51.073+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:37:21.414+0000] {processor.py:157} INFO - Started process (PID=1407) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:21.415+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:37:21.417+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:21.416+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:21.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:21.470+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:21.470+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:37:21.501+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:21.500+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:37:21.524+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:37:51.776+0000] {processor.py:157} INFO - Started process (PID=1415) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:51.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:37:51.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:51.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:51.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:37:51.839+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:51.839+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:37:51.868+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:37:51.868+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:37:51.905+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T03:38:22.217+0000] {processor.py:157} INFO - Started process (PID=1423) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:22.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:38:22.220+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:22.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:22.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:22.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:22.277+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:38:22.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:22.306+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:38:22.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T03:38:52.516+0000] {processor.py:157} INFO - Started process (PID=1431) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:52.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:38:52.520+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:52.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:52.541+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:38:52.573+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:52.573+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:38:52.603+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:38:52.603+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:38:52.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T03:39:22.991+0000] {processor.py:157} INFO - Started process (PID=1439) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:22.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:39:22.995+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:22.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:23.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:23.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:23.055+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:39:23.085+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:23.084+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:39:23.110+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:39:53.307+0000] {processor.py:157} INFO - Started process (PID=1447) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:53.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:39:53.311+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:53.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:53.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:39:53.364+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:53.364+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:39:53.395+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:39:53.394+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:39:53.430+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T03:40:23.731+0000] {processor.py:157} INFO - Started process (PID=1455) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:23.732+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:40:23.734+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:23.733+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:23.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:23.789+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:23.789+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:40:23.819+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:23.819+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:40:23.848+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:40:54.029+0000] {processor.py:157} INFO - Started process (PID=1463) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:54.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:40:54.032+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:54.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:54.052+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:40:54.086+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:54.086+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:40:54.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:40:54.115+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:40:54.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T03:41:24.400+0000] {processor.py:157} INFO - Started process (PID=1471) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:24.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:41:24.404+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:24.404+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:24.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:24.471+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:24.471+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:41:24.500+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:24.499+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:41:24.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T03:41:54.796+0000] {processor.py:157} INFO - Started process (PID=1480) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:54.798+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:41:54.800+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:54.800+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:54.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:41:54.853+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:54.853+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:41:54.883+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:41:54.882+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:41:54.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T03:42:25.090+0000] {processor.py:157} INFO - Started process (PID=1488) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:25.091+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:42:25.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:25.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:25.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:25.147+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:25.147+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:42:25.176+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:25.176+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:42:25.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T03:42:55.451+0000] {processor.py:157} INFO - Started process (PID=1496) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:55.453+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:42:55.454+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:55.454+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:55.473+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:42:55.510+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:55.510+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:42:55.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:42:55.543+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:42:55.567+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T03:43:25.818+0000] {processor.py:157} INFO - Started process (PID=1504) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:25.819+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:43:25.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:25.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:25.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:25.872+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:25.871+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:43:25.903+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:25.902+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:43:25.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-09T03:43:56.139+0000] {processor.py:157} INFO - Started process (PID=1512) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:56.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:43:56.146+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:56.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:56.178+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:43:56.213+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:56.213+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:43:56.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:43:56.241+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:43:56.270+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T03:44:26.546+0000] {processor.py:157} INFO - Started process (PID=1520) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:26.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:44:26.549+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:26.548+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:26.569+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:26.601+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:26.601+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:44:26.630+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:26.630+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:44:26.657+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:44:56.949+0000] {processor.py:157} INFO - Started process (PID=1529) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:56.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:44:56.953+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:56.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:56.979+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:44:57.013+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:57.013+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:44:57.047+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:44:57.047+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:44:57.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T03:45:27.244+0000] {processor.py:157} INFO - Started process (PID=1537) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:27.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:45:27.247+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:27.246+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:27.268+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:27.311+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:27.311+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:45:27.344+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:27.344+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:45:27.368+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T03:45:57.683+0000] {processor.py:157} INFO - Started process (PID=1545) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:57.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:45:57.687+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:57.687+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:57.710+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:45:57.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:57.742+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:45:57.773+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:45:57.773+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:45:57.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T03:46:27.992+0000] {processor.py:157} INFO - Started process (PID=1553) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:27.994+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:46:27.996+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:27.995+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:28.017+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:28.050+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:28.050+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:46:28.080+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:28.080+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:46:28.104+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:46:58.347+0000] {processor.py:157} INFO - Started process (PID=1561) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:58.349+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:46:58.350+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:58.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:58.376+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:46:58.408+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:58.407+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:46:58.437+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:46:58.437+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:46:58.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T03:47:28.646+0000] {processor.py:157} INFO - Started process (PID=1569) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:28.648+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:47:28.650+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:28.649+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:28.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:28.706+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:28.706+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:47:28.738+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:28.738+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:47:28.772+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T03:47:59.029+0000] {processor.py:157} INFO - Started process (PID=1578) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:59.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:47:59.034+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:59.034+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:59.061+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:47:59.092+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:59.092+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:47:59.121+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:47:59.121+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:47:59.151+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T03:48:29.399+0000] {processor.py:157} INFO - Started process (PID=1586) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:29.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:48:29.406+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:29.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:29.427+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:29.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:29.460+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:48:29.491+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:29.490+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:48:29.518+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T03:48:59.789+0000] {processor.py:157} INFO - Started process (PID=1594) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:59.791+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:48:59.793+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:59.793+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:59.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:48:59.849+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:59.849+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:48:59.880+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:48:59.879+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:48:59.903+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T03:49:30.086+0000] {processor.py:157} INFO - Started process (PID=1602) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:49:30.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:49:30.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:49:30.089+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:49:30.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:49:30.147+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:49:30.147+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:49:30.177+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:49:30.177+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:49:30.226+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T03:50:00.550+0000] {processor.py:157} INFO - Started process (PID=1610) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:00.552+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:50:00.554+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:00.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:00.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:00.611+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:00.611+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:50:00.641+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:00.641+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:50:00.667+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T03:50:30.816+0000] {processor.py:157} INFO - Started process (PID=1618) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:30.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:50:30.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:30.819+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:30.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:50:30.875+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:30.875+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:50:30.904+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:50:30.904+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:50:30.927+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T03:51:01.185+0000] {processor.py:157} INFO - Started process (PID=1626) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:01.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:51:01.188+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:01.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:01.209+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:01.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:01.242+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:51:01.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:01.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:51:01.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T03:51:31.559+0000] {processor.py:157} INFO - Started process (PID=1634) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:31.561+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:51:31.566+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:31.565+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:31.592+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:51:31.625+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:31.625+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:51:31.655+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:51:31.655+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:51:31.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T03:52:01.936+0000] {processor.py:157} INFO - Started process (PID=1642) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:01.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:52:01.939+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:01.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:01.958+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:01.993+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:01.993+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:52:02.024+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:02.024+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:52:02.048+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T03:52:32.383+0000] {processor.py:157} INFO - Started process (PID=1650) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:32.386+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:52:32.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:32.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:32.412+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:52:32.444+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:32.444+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:52:32.473+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:52:32.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:52:32.501+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T03:53:02.697+0000] {processor.py:157} INFO - Started process (PID=1659) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:02.698+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:53:02.700+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:02.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:02.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:02.756+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:02.756+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:53:02.786+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:02.786+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:53:02.811+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T03:53:33.170+0000] {processor.py:157} INFO - Started process (PID=1667) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:33.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:53:33.173+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:33.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:33.193+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:53:33.224+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:33.224+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:53:33.254+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:53:33.253+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:53:33.293+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:54:03.458+0000] {processor.py:157} INFO - Started process (PID=1675) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:03.460+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:54:03.463+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:03.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:03.489+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:03.523+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:03.522+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:54:03.554+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:03.554+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:54:03.592+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T03:54:33.874+0000] {processor.py:157} INFO - Started process (PID=1683) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:33.876+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:54:33.878+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:33.878+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:33.900+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:54:33.932+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:33.932+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:54:33.962+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:54:33.962+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:54:33.999+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T03:55:04.198+0000] {processor.py:157} INFO - Started process (PID=1691) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:04.199+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:55:04.201+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:04.201+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:04.221+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:04.254+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:04.254+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:55:04.284+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:04.283+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:55:04.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-10-09T03:55:34.584+0000] {processor.py:157} INFO - Started process (PID=1699) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:34.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:55:34.588+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:34.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:34.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:55:34.642+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:34.642+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:55:34.671+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:55:34.671+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:55:34.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T03:56:04.933+0000] {processor.py:157} INFO - Started process (PID=1707) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:04.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:56:04.936+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:04.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:04.963+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:05.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:05.003+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:56:05.032+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:05.032+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:56:05.055+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T03:56:35.304+0000] {processor.py:157} INFO - Started process (PID=1715) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:35.305+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:56:35.308+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:35.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:35.333+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:56:35.366+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:35.365+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:56:35.395+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:56:35.395+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:56:35.423+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T03:57:05.721+0000] {processor.py:157} INFO - Started process (PID=1723) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:05.724+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:57:05.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:05.726+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:05.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:05.784+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:05.784+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:57:05.817+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:05.816+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:57:05.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T03:57:36.043+0000] {processor.py:157} INFO - Started process (PID=1732) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:36.044+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:57:36.046+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:36.045+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:36.067+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:57:36.100+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:36.100+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:57:36.131+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:57:36.131+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:57:36.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T03:58:06.376+0000] {processor.py:157} INFO - Started process (PID=1740) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:06.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:58:06.381+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:06.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:06.406+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:06.441+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:06.441+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:58:06.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:06.493+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:58:06.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-10-09T03:58:36.785+0000] {processor.py:157} INFO - Started process (PID=1748) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:36.786+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:58:36.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:36.788+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:36.812+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:58:36.846+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:36.846+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:58:36.875+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:58:36.875+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:58:36.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:59:07.102+0000] {processor.py:157} INFO - Started process (PID=1756) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:07.104+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:59:07.106+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:07.106+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:07.128+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:07.161+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:07.161+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:59:07.191+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:07.191+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:59:07.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T03:59:37.485+0000] {processor.py:157} INFO - Started process (PID=1764) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:37.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T03:59:37.489+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:37.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:37.511+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T03:59:37.544+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:37.544+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T03:59:37.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T03:59:37.574+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T03:59:37.605+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T04:00:07.835+0000] {processor.py:157} INFO - Started process (PID=1772) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:07.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:00:07.841+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:07.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:07.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:07.941+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:07.941+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:00:07.982+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:07.982+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:00:08.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.179 seconds
[2023-10-09T04:00:38.179+0000] {processor.py:157} INFO - Started process (PID=1780) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:38.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:00:38.182+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:38.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:38.208+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:00:38.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:38.241+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:00:38.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:00:38.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:00:38.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T04:01:08.523+0000] {processor.py:157} INFO - Started process (PID=1788) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:08.524+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:01:08.526+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:08.526+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:08.549+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:08.583+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:08.583+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:01:08.613+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:08.612+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:01:08.641+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:01:38.906+0000] {processor.py:157} INFO - Started process (PID=1796) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:38.908+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:01:38.911+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:38.910+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:38.934+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:01:38.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:38.968+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:01:38.998+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:01:38.998+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:01:39.022+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:02:09.223+0000] {processor.py:157} INFO - Started process (PID=1804) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:09.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:02:09.230+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:09.229+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:09.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:09.291+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:09.291+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:02:09.321+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:09.321+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:02:09.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T04:02:39.592+0000] {processor.py:157} INFO - Started process (PID=1812) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:39.594+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:02:39.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:39.598+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:39.620+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:02:39.654+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:39.653+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:02:39.682+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:02:39.682+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:02:39.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T04:03:09.949+0000] {processor.py:157} INFO - Started process (PID=1821) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:09.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:03:09.953+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:09.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:09.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:10.007+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:10.006+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:03:10.037+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:10.037+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:03:10.063+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T04:03:40.290+0000] {processor.py:157} INFO - Started process (PID=1829) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:40.292+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:03:40.293+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:40.293+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:40.316+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:03:40.352+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:40.352+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:03:40.381+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:03:40.381+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:03:40.409+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:04:10.677+0000] {processor.py:157} INFO - Started process (PID=1837) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:10.680+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:04:10.682+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:10.681+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:10.711+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:10.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:10.743+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:04:10.773+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:10.772+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:04:10.808+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T04:04:41.049+0000] {processor.py:157} INFO - Started process (PID=1845) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:41.051+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:04:41.054+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:41.053+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:41.076+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:04:41.108+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:41.108+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:04:41.137+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:04:41.137+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:04:41.173+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T04:05:11.426+0000] {processor.py:157} INFO - Started process (PID=1853) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:11.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:05:11.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:11.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:11.458+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:11.492+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:11.491+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:05:11.522+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:11.522+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:05:11.546+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T04:05:41.819+0000] {processor.py:157} INFO - Started process (PID=1861) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:41.821+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:05:41.825+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:41.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:41.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:05:41.879+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:41.879+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:05:41.911+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:05:41.910+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:05:41.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T04:06:12.187+0000] {processor.py:157} INFO - Started process (PID=1869) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:12.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:06:12.192+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:12.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:12.214+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:12.246+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:12.245+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:06:12.276+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:12.276+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:06:12.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T04:06:42.510+0000] {processor.py:157} INFO - Started process (PID=1877) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:42.513+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:06:42.516+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:42.515+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:42.546+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:06:42.585+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:42.585+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:06:42.614+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:06:42.613+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:06:42.636+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T04:07:12.914+0000] {processor.py:157} INFO - Started process (PID=1885) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:12.915+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:07:12.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:12.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:12.941+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:12.974+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:12.974+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:07:13.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:13.003+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:07:13.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:07:43.298+0000] {processor.py:157} INFO - Started process (PID=1894) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:43.301+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:07:43.304+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:43.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:43.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:07:43.364+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:43.364+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:07:43.393+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:07:43.393+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:07:43.427+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T04:08:13.632+0000] {processor.py:157} INFO - Started process (PID=1902) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:13.634+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:08:13.636+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:13.635+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:13.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:13.692+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:13.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:08:13.722+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:13.721+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:08:13.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T04:08:44.048+0000] {processor.py:157} INFO - Started process (PID=1910) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:44.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:08:44.051+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:44.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:44.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:08:44.105+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:44.105+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:08:44.136+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:08:44.136+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:08:44.172+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T04:09:14.457+0000] {processor.py:157} INFO - Started process (PID=1918) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:14.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:09:14.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:14.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:14.482+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:14.514+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:14.514+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:09:14.544+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:14.544+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:09:14.572+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T04:09:44.781+0000] {processor.py:157} INFO - Started process (PID=1926) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:44.784+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:09:44.787+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:44.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:44.816+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:09:44.852+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:44.852+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:09:44.881+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:09:44.881+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:09:44.904+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T04:10:15.177+0000] {processor.py:157} INFO - Started process (PID=1934) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:15.179+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:10:15.181+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:15.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:15.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:15.239+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:15.239+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:10:15.269+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:15.268+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:10:15.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T04:10:45.531+0000] {processor.py:157} INFO - Started process (PID=1943) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:45.532+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:10:45.535+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:45.534+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:45.557+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:10:45.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:45.592+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:10:45.622+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:10:45.622+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:10:45.653+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T04:11:15.936+0000] {processor.py:157} INFO - Started process (PID=1951) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:15.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:11:15.941+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:15.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:15.967+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:16.000+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:16.000+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:11:16.031+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:16.031+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:11:16.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T04:11:46.310+0000] {processor.py:157} INFO - Started process (PID=1959) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:46.312+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:11:46.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:46.313+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:46.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:11:46.368+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:46.367+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:11:46.397+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:11:46.397+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:11:46.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T04:12:16.649+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:16.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:12:16.652+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:16.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:16.672+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:16.705+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:16.704+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:12:16.735+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:16.735+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:12:16.764+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T04:12:47.020+0000] {processor.py:157} INFO - Started process (PID=1975) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:47.021+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:12:47.023+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:47.023+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:47.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:12:47.077+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:47.077+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:12:47.107+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:12:47.107+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:12:47.143+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T04:13:17.391+0000] {processor.py:157} INFO - Started process (PID=1983) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:17.394+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:13:17.396+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:17.396+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:17.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:17.459+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:17.459+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:13:17.488+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:17.488+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:13:17.512+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T04:13:47.797+0000] {processor.py:157} INFO - Started process (PID=1991) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:47.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:13:47.803+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:47.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:47.834+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:13:47.867+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:47.867+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:13:47.896+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:13:47.896+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:13:47.926+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T04:14:18.160+0000] {processor.py:157} INFO - Started process (PID=1999) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:18.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:14:18.164+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:18.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:18.188+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:18.221+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:18.220+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:14:18.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:18.251+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:14:18.274+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T04:14:48.505+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:48.506+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:14:48.508+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:48.507+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:48.528+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:14:48.564+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:48.564+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:14:48.597+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:14:48.596+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:14:48.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T04:15:18.897+0000] {processor.py:157} INFO - Started process (PID=2015) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:18.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:15:18.902+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:18.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:18.924+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:18.957+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:18.957+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:15:18.986+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:18.986+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:15:19.025+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T04:15:49.220+0000] {processor.py:157} INFO - Started process (PID=2024) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:49.222+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:15:49.223+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:49.223+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:49.243+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:15:49.280+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:49.279+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:15:49.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:15:49.314+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:15:49.337+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:16:19.672+0000] {processor.py:157} INFO - Started process (PID=2040) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:19.674+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:16:19.677+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:19.676+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:19.702+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:19.735+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:19.734+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:16:19.765+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:19.764+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:16:19.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T04:16:50.015+0000] {processor.py:157} INFO - Started process (PID=2048) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:50.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:16:50.021+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:50.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:50.050+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:16:50.086+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:50.086+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:16:50.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:16:50.115+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:16:50.140+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T04:17:20.355+0000] {processor.py:157} INFO - Started process (PID=2057) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:20.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:17:20.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:20.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:20.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:20.416+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:20.416+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:17:20.459+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:20.459+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:17:20.486+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T04:17:50.788+0000] {processor.py:157} INFO - Started process (PID=2066) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:50.790+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:17:50.793+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:50.792+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:50.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:17:50.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:50.844+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:17:50.874+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:17:50.874+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:17:50.912+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T04:18:21.119+0000] {processor.py:157} INFO - Started process (PID=2074) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:21.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:18:21.123+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:21.123+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:21.145+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:21.180+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:21.180+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:18:21.210+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:21.210+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:18:21.246+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T04:18:51.533+0000] {processor.py:157} INFO - Started process (PID=2082) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:51.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:18:51.537+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:51.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:51.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:18:51.593+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:51.593+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:18:51.623+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:18:51.623+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:18:51.659+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T04:19:21.833+0000] {processor.py:157} INFO - Started process (PID=2090) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:21.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:19:21.844+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:21.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:21.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:21.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:21.917+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:19:21.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:21.947+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:19:21.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T04:19:52.237+0000] {processor.py:157} INFO - Started process (PID=2098) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:52.243+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:19:52.244+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:52.244+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:52.267+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:19:52.301+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:52.300+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:19:52.331+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:19:52.331+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:19:52.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T04:20:22.595+0000] {processor.py:157} INFO - Started process (PID=2106) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:22.597+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:20:22.600+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:22.599+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:22.624+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:22.662+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:22.662+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:20:22.691+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:22.691+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:20:22.720+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T04:20:52.982+0000] {processor.py:157} INFO - Started process (PID=2115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:52.984+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:20:52.988+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:52.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:53.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:20:53.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:53.056+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:20:53.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:20:53.093+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:20:53.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T04:21:23.368+0000] {processor.py:157} INFO - Started process (PID=2123) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:23.372+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:21:23.376+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:23.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:23.423+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:23.459+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:23.459+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:21:23.488+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:23.488+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:21:23.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T04:21:53.772+0000] {processor.py:157} INFO - Started process (PID=2132) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:53.773+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:21:53.775+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:53.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:53.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:21:53.835+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:53.835+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:21:53.868+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:21:53.867+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:21:53.963+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.196 seconds
[2023-10-09T04:22:24.110+0000] {processor.py:157} INFO - Started process (PID=2140) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:24.112+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:22:24.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:24.114+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:24.148+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:24.187+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:24.187+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:22:24.221+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:24.221+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:22:24.249+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T04:22:54.549+0000] {processor.py:157} INFO - Started process (PID=2148) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:54.551+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:22:54.553+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:54.552+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:54.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:22:54.618+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:54.618+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:22:54.654+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:22:54.654+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:22:54.685+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T04:23:24.856+0000] {processor.py:157} INFO - Started process (PID=2156) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:24.857+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:23:24.859+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:24.858+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:24.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:24.927+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:24.927+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:23:24.977+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:24.977+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:23:25.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-10-09T04:23:55.307+0000] {processor.py:157} INFO - Started process (PID=2164) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:55.308+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:23:55.310+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:55.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:55.331+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:23:55.366+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:55.366+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:23:55.400+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:23:55.400+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:23:55.426+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T04:24:25.644+0000] {processor.py:157} INFO - Started process (PID=2173) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:25.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:24:25.648+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:25.647+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:25.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:25.711+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:25.711+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:24:25.741+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:25.741+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:24:25.769+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T04:24:56.100+0000] {processor.py:157} INFO - Started process (PID=2181) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:56.103+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:24:56.106+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:56.105+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:56.130+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:24:56.170+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:56.169+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:24:56.199+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:24:56.199+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:24:56.223+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T04:25:26.413+0000] {processor.py:157} INFO - Started process (PID=2189) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:26.414+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:25:26.415+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:26.415+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:26.434+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:26.473+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:26.473+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:25:26.503+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:26.503+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:25:26.528+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T04:25:56.817+0000] {processor.py:157} INFO - Started process (PID=2197) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:56.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:25:56.821+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:56.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:56.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:25:56.878+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:56.878+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:25:56.909+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:25:56.908+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:25:56.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T04:26:27.170+0000] {processor.py:157} INFO - Started process (PID=2205) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:27.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:26:27.176+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:27.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:27.201+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:27.234+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:27.233+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:26:27.264+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:27.264+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:26:27.291+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T04:26:57.564+0000] {processor.py:157} INFO - Started process (PID=2213) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:57.567+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:26:57.569+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:57.569+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:57.590+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:26:57.623+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:57.623+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:26:57.653+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:26:57.653+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:26:57.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T04:27:27.932+0000] {processor.py:157} INFO - Started process (PID=2221) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:27.934+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:27:27.936+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:27.935+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:27.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:28.013+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:28.012+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:27:28.058+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:28.057+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:27:28.118+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-10-09T04:27:58.284+0000] {processor.py:157} INFO - Started process (PID=2229) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:58.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:27:58.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:58.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:58.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:27:58.351+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:58.351+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:27:58.384+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:27:58.384+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:27:58.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T04:28:28.822+0000] {processor.py:157} INFO - Started process (PID=2237) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:28.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:28:28.826+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:28.825+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:28.849+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:28.886+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:28.886+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:28:28.920+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:28.919+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:28:28.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T04:28:59.122+0000] {processor.py:157} INFO - Started process (PID=2245) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:59.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:28:59.127+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:59.126+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:59.159+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:28:59.194+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:59.194+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:28:59.225+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:28:59.225+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:28:59.260+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T04:29:29.477+0000] {processor.py:157} INFO - Started process (PID=2253) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:29.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:29:29.480+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:29.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:29.503+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:29.539+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:29.538+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:29:29.571+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:29.571+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:29:29.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T04:29:52.701+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:52.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:29:52.705+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:52.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:52.746+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:29:52.783+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:52.783+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:29:52.815+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:29:52.815+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:29:52.847+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T04:30:23.063+0000] {processor.py:157} INFO - Started process (PID=2269) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:23.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:30:23.066+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:23.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:23.088+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:23.121+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:23.121+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:30:23.152+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:23.152+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:30:23.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T04:30:53.372+0000] {processor.py:157} INFO - Started process (PID=2278) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:53.373+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:30:53.374+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:53.374+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:53.395+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:30:53.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:53.438+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:30:53.474+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:30:53.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:30:53.511+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T04:31:13.714+0000] {processor.py:157} INFO - Started process (PID=2279) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:13.716+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:31:13.718+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:13.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:13.744+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:13.777+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:13.776+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:31:13.807+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:13.807+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:31:13.838+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T04:31:44.014+0000] {processor.py:157} INFO - Started process (PID=2288) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:44.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:31:44.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:44.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:44.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:31:44.084+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:44.084+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:31:44.124+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:31:44.124+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:31:44.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T04:32:14.329+0000] {processor.py:157} INFO - Started process (PID=2296) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:14.331+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:32:14.333+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:14.333+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:14.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:14.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:14.430+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:32:14.490+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:14.489+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:32:14.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.203 seconds
[2023-10-09T04:32:44.687+0000] {processor.py:157} INFO - Started process (PID=2305) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:44.690+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:32:44.693+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:44.692+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:44.722+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:32:44.765+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:44.765+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:32:44.798+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:32:44.798+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:32:44.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T04:33:15.002+0000] {processor.py:157} INFO - Started process (PID=2313) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:15.004+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:33:15.005+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:15.005+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:15.030+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:15.070+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:15.070+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:33:15.117+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:15.116+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:33:15.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T04:33:45.460+0000] {processor.py:157} INFO - Started process (PID=2321) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:45.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:33:45.464+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:45.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:45.489+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:33:45.528+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:45.528+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:33:45.558+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:33:45.557+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:33:45.582+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T04:34:15.805+0000] {processor.py:157} INFO - Started process (PID=2328) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:15.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:34:15.810+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:15.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:15.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:15.880+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:15.880+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:34:15.913+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:15.912+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:34:15.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T04:34:46.142+0000] {processor.py:157} INFO - Started process (PID=2336) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:46.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:34:46.144+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:46.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:46.164+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:34:46.199+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:46.199+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:34:46.229+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:34:46.229+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:34:46.255+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T04:35:16.521+0000] {processor.py:157} INFO - Started process (PID=2344) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:16.523+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:35:16.525+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:16.524+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:16.547+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:16.581+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:16.581+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:35:16.610+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:16.609+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:35:16.666+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T04:35:46.801+0000] {processor.py:157} INFO - Started process (PID=2360) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:46.803+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:35:46.805+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:46.805+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:46.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:35:46.878+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:46.878+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:35:46.925+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:35:46.925+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:35:46.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T04:36:17.155+0000] {processor.py:157} INFO - Started process (PID=2369) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:17.157+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:36:17.160+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:17.159+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:17.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:17.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:17.272+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:36:17.342+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:17.342+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:36:17.385+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.242 seconds
[2023-10-09T04:36:47.496+0000] {processor.py:157} INFO - Started process (PID=2377) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:47.498+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:36:47.500+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:47.499+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:47.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:36:47.559+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:47.559+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:36:47.591+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:36:47.591+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:36:47.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T04:37:17.846+0000] {processor.py:157} INFO - Started process (PID=2385) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:17.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:37:17.853+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:17.852+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:17.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:17.915+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:17.914+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:37:17.945+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:17.945+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:37:17.976+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T04:37:48.258+0000] {processor.py:157} INFO - Started process (PID=2393) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:48.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:37:48.263+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:48.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:48.284+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:37:48.318+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:48.318+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:37:48.347+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:37:48.347+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:37:48.375+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T04:38:18.666+0000] {processor.py:157} INFO - Started process (PID=2401) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:18.667+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:38:18.669+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:18.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:18.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:18.722+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:18.722+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:38:18.752+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:18.751+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:38:18.790+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T04:38:48.971+0000] {processor.py:157} INFO - Started process (PID=2409) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:48.973+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:38:48.975+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:48.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:49.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:38:49.036+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:49.036+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:38:49.066+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:38:49.066+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:38:49.088+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T04:39:19.411+0000] {processor.py:157} INFO - Started process (PID=2417) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:19.413+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:39:19.415+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:19.414+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:19.436+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:19.473+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:19.473+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:39:19.506+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:19.506+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:39:19.532+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T04:39:49.738+0000] {processor.py:157} INFO - Started process (PID=2425) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:49.739+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:39:49.741+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:49.741+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:49.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:39:49.803+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:49.803+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:39:49.834+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:39:49.834+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:39:49.860+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T04:40:20.145+0000] {processor.py:157} INFO - Started process (PID=2433) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:20.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:40:20.149+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:20.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:20.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:20.203+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:20.202+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:40:20.233+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:20.232+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:40:20.256+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T04:40:50.476+0000] {processor.py:157} INFO - Started process (PID=2441) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:50.479+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:40:50.482+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:50.481+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:50.508+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:40:50.542+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:50.541+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:40:50.575+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:40:50.574+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:40:50.609+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T04:41:20.933+0000] {processor.py:157} INFO - Started process (PID=2449) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:20.935+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:41:20.937+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:20.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:20.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:20.993+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:20.992+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:41:21.023+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:21.023+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:41:21.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T04:41:51.286+0000] {processor.py:157} INFO - Started process (PID=2457) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:51.288+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:41:51.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:51.289+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:51.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:41:51.346+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:51.346+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:41:51.376+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:41:51.376+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:41:51.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T04:42:21.684+0000] {processor.py:157} INFO - Started process (PID=2465) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:42:21.686+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T04:42:21.688+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:42:21.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:42:21.713+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T04:42:21.748+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:42:21.748+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T04:42:21.785+0000] {logging_mixin.py:150} INFO - [2023-10-09T04:42:21.784+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T04:42:21.809+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T05:14:15.129+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:15.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:14:15.139+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:15.138+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:15.197+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:15.599+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:15.598+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:14:15.649+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:15.649+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:14:15.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.569 seconds
[2023-10-09T05:14:45.928+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:45.930+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:14:45.932+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:45.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:45.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:14:45.995+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:45.995+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:14:46.041+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:14:46.041+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:14:46.125+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.201 seconds
[2023-10-09T05:15:16.209+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:16.211+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:15:16.213+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:16.212+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:16.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:16.292+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:16.292+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:15:16.326+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:16.325+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:15:16.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T05:15:46.632+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:46.633+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:15:46.634+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:46.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:46.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:15:46.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:46.689+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:15:46.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:15:46.719+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:15:46.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T05:16:16.935+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:16.936+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:16:16.939+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:16.938+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:16.956+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:17.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:17.019+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:16:17.051+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:17.051+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:16:17.082+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T05:16:47.317+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:47.318+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:16:47.320+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:47.319+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:47.344+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:16:47.376+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:47.376+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:16:47.412+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:16:47.412+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:16:47.434+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T05:17:17.631+0000] {processor.py:157} INFO - Started process (PID=95) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:17:17.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:17:17.634+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:17:17.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:17:17.656+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:17:17.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:17:17.690+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:17:17.718+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:17:17.717+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:17:17.740+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T05:20:15.579+0000] {processor.py:157} INFO - Started process (PID=46) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:15.585+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:20:15.587+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:15.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:15.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:16.087+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:16.087+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:20:16.143+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:16.142+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:20:16.183+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.610 seconds
[2023-10-09T05:20:46.431+0000] {processor.py:157} INFO - Started process (PID=54) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:46.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:20:46.434+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:46.433+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:46.461+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:20:46.503+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:46.502+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:20:46.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:20:46.541+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:20:46.568+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T05:21:16.786+0000] {processor.py:157} INFO - Started process (PID=62) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:16.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:21:16.790+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:16.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:16.811+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:16.847+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:16.847+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:21:16.882+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:16.881+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:21:16.906+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T05:21:47.147+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:47.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:21:47.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:47.149+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:47.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:21:47.206+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:47.206+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:21:47.241+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:21:47.241+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:21:47.267+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T05:22:17.452+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:17.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:22:17.457+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:17.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:17.551+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:17.721+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:17.720+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:22:17.785+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:17.785+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:22:17.817+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.383 seconds
[2023-10-09T05:22:48.039+0000] {processor.py:157} INFO - Started process (PID=87) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:48.045+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:22:48.050+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:48.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:48.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:22:48.244+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:48.244+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:22:48.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:22:48.330+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:22:48.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.354 seconds
[2023-10-09T05:23:18.635+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:18.636+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:23:18.638+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:18.638+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:18.663+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:18.702+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:18.701+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:23:18.735+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:18.735+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:23:18.768+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T05:23:48.956+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:48.957+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:23:48.959+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:48.958+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:48.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:23:49.022+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:49.021+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:23:49.053+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:23:49.053+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:23:49.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T05:24:19.332+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:19.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:24:19.335+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:19.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:19.357+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:19.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:19.389+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:24:19.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:19.422+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:24:19.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T05:24:49.678+0000] {processor.py:157} INFO - Started process (PID=118) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:49.679+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:24:49.681+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:49.680+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:49.707+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:24:49.754+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:49.753+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:24:49.794+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:24:49.794+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:24:49.821+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T05:25:20.097+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:20.098+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:25:20.100+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:20.099+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:20.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:20.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:20.150+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:25:20.180+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:20.180+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:25:20.209+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T05:25:50.406+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:50.408+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:25:50.409+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:50.409+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:50.431+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:25:50.474+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:50.474+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:25:50.514+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:25:50.514+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:25:50.557+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T05:26:20.846+0000] {processor.py:157} INFO - Started process (PID=143) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:20.848+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:26:20.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:20.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:20.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:20.935+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:20.935+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:26:20.965+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:20.965+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:26:20.988+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T05:26:51.160+0000] {processor.py:157} INFO - Started process (PID=151) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:51.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:26:51.162+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:51.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:51.180+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:26:51.213+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:51.213+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:26:51.248+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:26:51.248+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:26:51.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T05:27:21.537+0000] {processor.py:157} INFO - Started process (PID=159) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:21.547+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:27:21.550+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:21.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:21.586+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:21.629+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:21.629+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:27:21.668+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:21.668+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:27:21.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.173 seconds
[2023-10-09T05:27:51.950+0000] {processor.py:157} INFO - Started process (PID=167) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:51.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:27:51.954+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:51.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:51.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:27:52.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:52.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:27:52.051+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:27:52.050+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:27:52.074+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T05:28:22.332+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:22.333+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:28:22.334+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:22.334+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:22.355+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:22.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:22.389+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:28:22.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:22.421+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:28:22.463+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T05:28:52.648+0000] {processor.py:157} INFO - Started process (PID=185) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:52.649+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:28:52.652+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:52.651+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:52.685+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:28:52.723+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:52.722+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:28:52.762+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:28:52.762+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:28:52.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T05:29:23.079+0000] {processor.py:157} INFO - Started process (PID=193) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:23.080+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:29:23.081+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:23.081+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:23.101+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:23.133+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:23.133+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:29:23.164+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:23.164+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:29:23.200+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T05:29:53.401+0000] {processor.py:157} INFO - Started process (PID=201) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:53.402+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:29:53.404+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:53.403+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:53.425+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:29:53.458+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:53.458+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:29:53.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:29:53.492+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:29:53.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T05:30:23.804+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:23.805+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:30:23.806+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:23.806+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:23.825+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:23.859+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:23.859+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:30:23.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:23.891+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:30:23.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T05:30:54.134+0000] {processor.py:157} INFO - Started process (PID=217) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:54.136+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:30:54.137+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:54.137+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:54.162+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:30:54.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:54.204+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:30:54.238+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:30:54.237+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:30:54.262+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T05:31:24.481+0000] {processor.py:157} INFO - Started process (PID=225) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:24.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:31:24.484+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:24.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:24.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:24.538+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:24.538+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:31:24.572+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:24.571+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:31:24.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T05:31:54.848+0000] {processor.py:157} INFO - Started process (PID=233) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:54.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:31:54.851+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:54.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:54.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:31:54.904+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:54.904+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:31:54.938+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:31:54.938+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:31:54.965+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T05:32:25.208+0000] {processor.py:157} INFO - Started process (PID=241) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:25.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:32:25.210+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:25.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:25.229+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:25.265+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:25.265+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:32:25.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:25.297+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:32:25.321+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T05:32:55.565+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:55.566+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:32:55.568+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:55.567+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:55.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:32:55.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:55.620+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:32:55.651+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:32:55.651+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:32:55.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T05:33:25.937+0000] {processor.py:157} INFO - Started process (PID=258) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:25.939+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:33:25.941+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:25.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:25.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:26.030+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:26.030+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:33:26.062+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:26.061+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:33:26.091+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-10-09T05:33:56.284+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:56.286+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:33:56.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:56.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:56.313+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:33:56.349+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:56.349+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:33:56.384+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:33:56.384+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:33:56.410+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T05:34:26.662+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:26.664+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:34:26.669+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:26.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:26.695+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:26.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:26.726+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:34:26.758+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:26.758+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:34:26.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T05:34:56.970+0000] {processor.py:157} INFO - Started process (PID=283) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:56.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:34:56.972+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:56.972+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:56.992+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:34:57.026+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:57.026+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:34:57.064+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:34:57.064+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:34:57.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T05:35:27.435+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:27.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:35:27.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:27.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:27.456+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:27.487+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:27.487+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:35:27.519+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:27.519+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:35:27.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-09T05:35:57.791+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:57.792+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:35:57.794+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:57.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:57.820+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:35:57.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:57.858+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:35:57.888+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:35:57.888+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:35:57.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T05:36:28.194+0000] {processor.py:157} INFO - Started process (PID=307) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:28.196+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:36:28.199+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:28.198+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:28.225+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:28.260+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:28.260+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:36:28.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:28.290+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:36:28.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T05:36:58.495+0000] {processor.py:157} INFO - Started process (PID=315) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:58.496+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:36:58.497+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:58.497+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:58.520+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:36:58.558+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:58.558+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:36:58.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:36:58.592+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:36:58.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T05:37:28.931+0000] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:28.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:37:28.934+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:28.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:28.955+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:28.988+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:28.987+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:37:29.017+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:29.017+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:37:29.039+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T05:37:59.244+0000] {processor.py:157} INFO - Started process (PID=331) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:59.245+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:37:59.248+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:59.247+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:59.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:37:59.315+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:59.315+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:37:59.366+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:37:59.366+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:37:59.402+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-10-09T05:38:29.629+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:38:29.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:38:29.634+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:38:29.633+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:38:29.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:38:29.692+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:38:29.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:38:29.723+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:38:29.723+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:38:29.750+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T05:39:00.025+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:00.026+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:39:00.029+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:00.028+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:00.056+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:00.087+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:00.087+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:39:00.118+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:00.117+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:39:00.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.173 seconds
[2023-10-09T05:39:30.305+0000] {processor.py:157} INFO - Started process (PID=355) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:30.306+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:39:30.308+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:30.307+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:30.332+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:39:30.367+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:30.367+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:39:30.398+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:39:30.398+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:39:30.428+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T05:40:00.757+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:00.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:40:00.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:00.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:00.784+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:00.821+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:00.820+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:40:00.853+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:00.852+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:40:00.880+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T05:40:31.108+0000] {processor.py:157} INFO - Started process (PID=371) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:31.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:40:31.111+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:31.111+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:31.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:40:31.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:31.172+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:40:31.202+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:40:31.202+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:40:31.251+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T05:41:01.486+0000] {processor.py:157} INFO - Started process (PID=380) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:01.487+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:41:01.488+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:01.488+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:01.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:01.542+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:01.542+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:41:01.573+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:01.573+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:41:01.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T05:41:31.879+0000] {processor.py:157} INFO - Started process (PID=388) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:31.880+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:41:31.881+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:31.881+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:31.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:41:31.943+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:31.943+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:41:31.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:41:31.978+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:41:32.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.188 seconds
[2023-10-09T05:42:02.207+0000] {processor.py:157} INFO - Started process (PID=396) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:02.209+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:42:02.210+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:02.210+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:02.231+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:02.265+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:02.265+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:42:02.295+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:02.295+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:42:02.320+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T05:42:32.569+0000] {processor.py:157} INFO - Started process (PID=404) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:32.573+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:42:32.577+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:32.576+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:32.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:42:32.648+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:32.648+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:42:32.678+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:42:32.678+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:42:32.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-10-09T05:43:02.989+0000] {processor.py:157} INFO - Started process (PID=412) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:02.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:43:02.991+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:02.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:03.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:03.047+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:03.047+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:43:03.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:03.089+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:43:03.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T05:43:33.386+0000] {processor.py:157} INFO - Started process (PID=420) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:33.387+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:43:33.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:33.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:33.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:43:33.441+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:33.440+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:43:33.471+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:43:33.471+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:43:33.530+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T05:44:03.767+0000] {processor.py:157} INFO - Started process (PID=429) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:03.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:44:03.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:03.770+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:03.800+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:03.834+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:03.834+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:44:03.865+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:03.864+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:44:03.902+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T05:44:34.175+0000] {processor.py:157} INFO - Started process (PID=438) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:34.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:44:34.178+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:34.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:34.200+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:44:34.234+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:34.233+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:44:34.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:44:34.266+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:44:34.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T05:45:04.520+0000] {processor.py:157} INFO - Started process (PID=446) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:04.521+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:45:04.523+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:04.523+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:04.542+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:04.576+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:04.576+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:45:04.606+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:04.606+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:45:04.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T05:45:35.066+0000] {processor.py:157} INFO - Started process (PID=454) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:35.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:45:35.069+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:35.069+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:35.091+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:45:35.123+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:35.123+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:45:35.153+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:45:35.153+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:45:35.206+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T05:46:05.394+0000] {processor.py:157} INFO - Started process (PID=462) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:05.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:46:05.398+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:05.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:05.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:05.463+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:05.463+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:46:05.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:05.493+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:46:05.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T05:46:35.845+0000] {processor.py:157} INFO - Started process (PID=470) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:35.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:46:35.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:35.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:35.869+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:46:35.901+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:35.901+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:46:35.931+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:46:35.931+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:46:35.986+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T05:47:06.194+0000] {processor.py:157} INFO - Started process (PID=478) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:06.195+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:47:06.197+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:06.197+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:06.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:06.258+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:06.258+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:47:06.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:06.289+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:47:06.330+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T05:47:36.725+0000] {processor.py:157} INFO - Started process (PID=486) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:36.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:47:36.729+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:36.728+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:36.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:47:36.783+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:36.783+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:47:36.813+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:47:36.813+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:47:36.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T05:48:07.083+0000] {processor.py:157} INFO - Started process (PID=495) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:07.084+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:48:07.085+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:07.085+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:07.105+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:07.139+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:07.139+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:48:07.169+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:07.169+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:48:07.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T05:48:37.459+0000] {processor.py:157} INFO - Started process (PID=503) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:37.461+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:48:37.462+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:37.462+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:37.482+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:48:37.515+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:37.515+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:48:37.545+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:48:37.545+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:48:37.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T05:49:07.834+0000] {processor.py:157} INFO - Started process (PID=512) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:07.836+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:49:07.838+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:07.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:07.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:07.895+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:07.894+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:49:07.925+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:07.925+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:49:07.949+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T05:49:38.219+0000] {processor.py:157} INFO - Started process (PID=520) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:38.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T05:49:38.222+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:38.222+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:38.250+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T05:49:38.282+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:38.282+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T05:49:38.317+0000] {logging_mixin.py:150} INFO - [2023-10-09T05:49:38.317+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T05:49:38.354+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T17:00:45.675+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:00:45.683+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:00:45.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:00:45.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:00:45.756+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:00:46.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:00:46.242+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:00:46.305+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:00:46.305+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:00:46.446+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.778 seconds
[2023-10-09T17:01:16.612+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:16.614+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:01:16.615+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:16.615+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:16.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:16.676+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:16.676+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:01:16.712+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:16.712+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:01:16.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T17:01:46.950+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:46.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:01:46.961+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:46.961+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:47.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:01:47.385+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:47.384+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:01:47.534+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:01:47.533+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:01:47.614+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.676 seconds
[2023-10-09T17:02:18.064+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:18.066+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:02:18.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:18.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:18.103+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:18.166+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:18.165+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:02:18.233+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:18.233+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:02:18.285+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.227 seconds
[2023-10-09T17:02:48.727+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:48.730+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:02:48.736+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:48.735+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:48.948+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:02:49.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:49.114+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:02:49.256+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:02:49.256+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:02:49.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.732 seconds
[2023-10-09T17:03:20.205+0000] {processor.py:157} INFO - Started process (PID=74) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:20.220+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:03:20.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:20.237+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:20.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:20.604+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:20.603+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:03:20.683+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:20.683+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:03:20.760+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.597 seconds
[2023-10-09T17:03:50.974+0000] {processor.py:157} INFO - Started process (PID=81) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:50.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:03:50.978+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:50.977+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:50.997+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:03:51.030+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:51.030+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:03:51.061+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:03:51.061+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:03:51.086+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T17:04:21.199+0000] {processor.py:157} INFO - Started process (PID=89) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:21.202+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:04:21.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:21.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:21.230+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:21.265+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:21.264+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:04:21.294+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:21.294+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:04:21.318+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T17:04:51.556+0000] {processor.py:157} INFO - Started process (PID=97) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:51.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:04:51.559+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:51.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:51.578+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:04:51.611+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:51.610+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:04:51.646+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:04:51.646+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:04:51.673+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T17:08:54.034+0000] {processor.py:157} INFO - Started process (PID=53) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:08:54.036+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:08:54.039+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:08:54.038+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:08:54.120+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:08:54.486+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:08:54.486+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:08:54.533+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:08:54.532+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:08:54.577+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.559 seconds
[2023-10-09T17:09:24.967+0000] {processor.py:157} INFO - Started process (PID=61) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:09:24.971+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T17:09:24.978+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:09:24.975+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:09:25.144+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T17:09:25.334+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:09:25.334+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T17:09:25.525+0000] {logging_mixin.py:150} INFO - [2023-10-09T17:09:25.524+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T17:09:25.606+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.662 seconds
[2023-10-09T20:59:40.894+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T20:59:40.897+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T20:59:40.902+0000] {logging_mixin.py:150} INFO - [2023-10-09T20:59:40.900+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T20:59:40.981+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T20:59:41.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T20:59:41.110+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T20:59:41.171+0000] {logging_mixin.py:150} INFO - [2023-10-09T20:59:41.171+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T20:59:41.219+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.334 seconds
[2023-10-09T21:00:11.373+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:11.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:00:11.375+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:11.375+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:11.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:11.436+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:11.436+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:00:11.470+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:11.470+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:00:11.496+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T21:00:41.837+0000] {processor.py:157} INFO - Started process (PID=51) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:41.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:00:41.840+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:41.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:41.867+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:00:41.903+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:41.902+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:00:41.949+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:00:41.949+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:00:41.980+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T21:01:12.980+0000] {processor.py:157} INFO - Started process (PID=59) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:12.981+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:01:12.982+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:12.982+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:13.003+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:13.036+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:13.036+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:01:13.070+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:13.070+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:01:13.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T21:01:43.391+0000] {processor.py:157} INFO - Started process (PID=67) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:43.392+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:01:43.394+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:43.393+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:43.411+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:01:43.443+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:43.443+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:01:43.474+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:01:43.473+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:01:43.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-10-09T21:02:13.718+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:13.719+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:02:13.720+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:13.720+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:13.740+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:13.775+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:13.775+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:02:13.808+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:13.808+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:02:13.831+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T21:02:33.945+0000] {processor.py:157} INFO - Started process (PID=83) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:33.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:02:33.949+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:33.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:33.987+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:02:34.028+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:34.028+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:02:34.061+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:02:34.060+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:02:34.092+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T21:03:04.276+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:04.278+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:03:04.280+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:04.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:04.301+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:04.335+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:04.335+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:03:04.373+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:04.373+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:03:04.401+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T21:03:34.675+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:34.676+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:03:34.678+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:34.678+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:34.698+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:34.739+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:34.739+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:03:34.769+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:34.768+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:03:34.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:03:59.979+0000] {processor.py:157} INFO - Started process (PID=107) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:03:59.983+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:03:59.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:03:59.985+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:04:00.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:04:00.020+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:04:00.091+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:04:00.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.201 seconds
[2023-10-09T21:04:30.216+0000] {processor.py:157} INFO - Started process (PID=115) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:04:30.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:04:30.219+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:04:30.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:04:30.235+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:04:30.230+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:04:30.236+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:04:30.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.415 seconds
[2023-10-09T21:05:01.005+0000] {processor.py:157} INFO - Started process (PID=123) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:01.010+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:05:01.028+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:05:01.027+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:01.091+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:05:01.081+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:05:01.093+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:01.263+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.291 seconds
[2023-10-09T21:05:31.319+0000] {processor.py:157} INFO - Started process (PID=131) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:31.321+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:05:31.322+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:05:31.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:31.331+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:05:31.329+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:05:31.332+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:05:31.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.041 seconds
[2023-10-09T21:06:01.543+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:01.545+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:06:01.547+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:01.546+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:01.558+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:01.555+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:06:01.559+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:01.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.052 seconds
[2023-10-09T21:06:31.875+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:31.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:06:31.883+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:31.882+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:31.901+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:31.896+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 36, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key '' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-09T21:06:31.902+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:31.932+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.064 seconds
[2023-10-09T21:06:44.040+0000] {processor.py:157} INFO - Started process (PID=148) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:44.042+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:06:44.044+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:44.044+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:44.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:06:44.655+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:44.655+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:06:44.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:06:44.719+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:06:44.774+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.741 seconds
[2023-10-09T21:07:15.011+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:15.013+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:07:15.015+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:15.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:15.037+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:15.071+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:15.071+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:07:15.101+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:15.101+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:07:15.124+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T21:07:45.261+0000] {processor.py:157} INFO - Started process (PID=168) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:45.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:07:45.265+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:45.264+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:45.293+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:07:45.331+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:45.331+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:07:45.365+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:07:45.364+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:07:45.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T21:08:15.652+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:08:15.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:08:15.656+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:08:15.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:08:15.677+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:08:15.710+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:08:15.709+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:08:15.750+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:08:15.750+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:08:15.787+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T21:09:49.876+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:09:49.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:09:49.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:09:49.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:09:50.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:09:50.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:09:50.725+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:09:50.804+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:09:50.804+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:09:50.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.015 seconds
[2023-10-09T21:10:21.089+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:21.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:10:21.114+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:21.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:21.189+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:21.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:21.313+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:10:21.404+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:21.404+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:10:21.455+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.394 seconds
[2023-10-09T21:10:51.914+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:51.924+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:10:51.970+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:51.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:52.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:10:52.406+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:52.406+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:10:52.593+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:10:52.592+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:10:52.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.768 seconds
[2023-10-09T21:11:22.872+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:22.881+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:11:22.885+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:22.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:22.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:23.052+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:23.051+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:11:23.116+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:23.116+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:11:23.150+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.294 seconds
[2023-10-09T21:11:53.249+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:53.259+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:11:53.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:53.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:53.319+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:11:53.411+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:53.411+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:11:53.485+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:11:53.484+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:11:53.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.327 seconds
[2023-10-09T21:12:23.797+0000] {processor.py:157} INFO - Started process (PID=91) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:23.799+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:12:23.802+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:23.801+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:23.827+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:23.869+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:23.869+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:12:23.914+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:23.914+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:12:23.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T21:12:53.980+0000] {processor.py:157} INFO - Started process (PID=99) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:53.982+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:12:53.984+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:53.983+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:54.004+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:12:54.037+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:54.037+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:12:54.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:12:54.068+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:12:54.090+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-09T21:13:24.386+0000] {processor.py:157} INFO - Started process (PID=108) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:24.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:13:24.392+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:24.391+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:24.414+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:24.448+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:24.447+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:13:24.479+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:24.479+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:13:24.503+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T21:13:54.645+0000] {processor.py:157} INFO - Started process (PID=116) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:54.646+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:13:54.648+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:54.648+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:54.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:13:54.727+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:54.727+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:13:54.787+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:13:54.787+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:13:54.827+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.188 seconds
[2023-10-09T21:14:24.958+0000] {processor.py:157} INFO - Started process (PID=124) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:24.966+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:14:24.970+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:24.969+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:25.002+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:25.037+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:25.037+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:14:25.069+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:25.069+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:14:25.093+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T21:14:55.368+0000] {processor.py:157} INFO - Started process (PID=132) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:55.370+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:14:55.372+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:55.371+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:55.405+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:14:55.439+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:55.439+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:14:55.469+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:14:55.469+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:14:55.500+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T21:15:25.723+0000] {processor.py:157} INFO - Started process (PID=139) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:25.726+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:15:25.728+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:25.727+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:25.757+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:25.793+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:25.793+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:15:25.825+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:25.825+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:15:25.849+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:15:56.100+0000] {processor.py:157} INFO - Started process (PID=147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:56.102+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:15:56.103+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:56.103+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:56.122+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:15:56.160+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:56.160+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:15:56.192+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:15:56.192+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:15:56.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T21:16:26.488+0000] {processor.py:157} INFO - Started process (PID=155) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:26.490+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:16:26.492+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:26.492+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:26.516+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:26.552+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:26.552+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:16:26.582+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:26.582+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:16:26.615+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T21:16:56.850+0000] {processor.py:157} INFO - Started process (PID=163) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:56.852+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:16:56.855+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:56.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:56.875+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:16:56.907+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:56.907+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:16:56.937+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:16:56.937+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:16:56.960+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T21:17:27.104+0000] {processor.py:157} INFO - Started process (PID=171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:27.105+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:17:27.107+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:27.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:27.132+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:27.168+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:27.168+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:17:27.202+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:27.202+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:17:27.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T21:17:57.446+0000] {processor.py:157} INFO - Started process (PID=179) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:57.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:17:57.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:57.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:57.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:17:57.510+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:57.510+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:17:57.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:17:57.541+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:17:57.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:18:27.770+0000] {processor.py:157} INFO - Started process (PID=188) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:27.772+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:18:27.774+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:27.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:27.798+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:27.835+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:27.835+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:18:27.866+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:27.866+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:18:27.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T21:18:58.088+0000] {processor.py:157} INFO - Started process (PID=195) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:58.090+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:18:58.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:58.093+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:58.115+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:18:58.148+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:58.147+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:18:58.182+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:18:58.182+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:18:58.205+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:19:28.445+0000] {processor.py:157} INFO - Started process (PID=202) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:28.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:19:28.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:28.450+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:28.475+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:28.506+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:28.505+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:19:28.535+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:28.535+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:19:28.588+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T21:19:58.861+0000] {processor.py:157} INFO - Started process (PID=210) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:58.863+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:19:58.864+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:58.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:58.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:19:58.915+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:58.914+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:19:58.944+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:19:58.944+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:19:58.967+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-09T21:20:29.185+0000] {processor.py:157} INFO - Started process (PID=218) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:29.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:20:29.188+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:29.188+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:29.207+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:29.240+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:29.240+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:20:29.271+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:29.270+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:20:29.299+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T21:20:59.514+0000] {processor.py:157} INFO - Started process (PID=226) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:59.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:20:59.517+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:59.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:59.538+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:20:59.572+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:59.572+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:20:59.607+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:20:59.607+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:20:59.630+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T21:21:29.940+0000] {processor.py:157} INFO - Started process (PID=234) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:21:29.942+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:21:29.943+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:21:29.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:21:29.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:21:29.996+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:21:29.996+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:21:30.026+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:21:30.025+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:21:30.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T21:22:00.231+0000] {processor.py:157} INFO - Started process (PID=242) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:00.232+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:22:00.235+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:00.234+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:00.255+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:00.288+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:00.287+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:22:00.318+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:00.317+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:22:00.349+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:22:30.630+0000] {processor.py:157} INFO - Started process (PID=250) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:30.632+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:22:30.635+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:30.634+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:30.659+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:22:30.692+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:30.692+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:22:30.722+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:22:30.722+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:22:30.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:23:00.925+0000] {processor.py:157} INFO - Started process (PID=259) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:00.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:23:00.929+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:00.928+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:00.954+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:00.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:00.987+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:23:01.017+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:01.017+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:23:01.045+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:23:31.263+0000] {processor.py:157} INFO - Started process (PID=267) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:31.265+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:23:31.267+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:31.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:31.288+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:23:31.322+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:31.321+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:23:31.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:23:31.357+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:23:31.392+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:24:01.576+0000] {processor.py:157} INFO - Started process (PID=275) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:01.577+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:24:01.579+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:01.578+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:01.597+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:01.635+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:01.635+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:24:01.669+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:01.669+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:24:01.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T21:24:31.989+0000] {processor.py:157} INFO - Started process (PID=283) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:31.990+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:24:31.992+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:31.991+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:32.014+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:24:32.050+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:32.050+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:24:32.079+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:24:32.079+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:24:32.102+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T21:25:02.395+0000] {processor.py:157} INFO - Started process (PID=291) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:02.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:25:02.399+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:02.398+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:02.422+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:02.462+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:02.462+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:25:02.491+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:02.491+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:25:02.520+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:25:32.754+0000] {processor.py:157} INFO - Started process (PID=299) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:32.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:25:32.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:32.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:32.786+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:25:32.819+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:32.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:25:32.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:25:32.850+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:25:32.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T21:26:03.146+0000] {processor.py:157} INFO - Started process (PID=307) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:03.148+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:26:03.151+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:03.150+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:03.174+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:03.207+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:03.207+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:26:03.238+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:03.237+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:26:03.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:26:33.505+0000] {processor.py:157} INFO - Started process (PID=315) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:33.507+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:26:33.509+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:33.508+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:33.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:26:33.567+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:33.567+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:26:33.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:26:33.598+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:26:33.621+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T21:27:03.830+0000] {processor.py:157} INFO - Started process (PID=323) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:03.832+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:27:03.834+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:03.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:03.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:04.102+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:04.101+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:27:04.132+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:04.132+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:27:04.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.341 seconds
[2023-10-09T21:27:34.462+0000] {processor.py:157} INFO - Started process (PID=331) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:34.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:27:34.467+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:34.466+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:34.491+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:27:34.526+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:34.526+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:27:34.556+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:27:34.556+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:27:34.580+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T21:28:04.758+0000] {processor.py:157} INFO - Started process (PID=339) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:04.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:28:04.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:04.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:04.782+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:04.815+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:04.814+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:28:04.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:04.844+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:28:04.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T21:28:35.246+0000] {processor.py:157} INFO - Started process (PID=347) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:35.248+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:28:35.250+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:35.250+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:35.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:28:35.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:35.306+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:28:35.338+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:28:35.337+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:28:35.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T21:29:05.589+0000] {processor.py:157} INFO - Started process (PID=355) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:05.590+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:29:05.594+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:05.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:05.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:05.648+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:05.648+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:29:05.679+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:05.679+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:29:05.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:29:35.952+0000] {processor.py:157} INFO - Started process (PID=363) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:35.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:29:35.955+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:35.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:35.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:29:36.013+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:36.013+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:29:36.047+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:29:36.047+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:29:36.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T21:30:06.258+0000] {processor.py:157} INFO - Started process (PID=371) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:06.264+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:30:06.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:06.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:06.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:06.324+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:06.324+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:30:06.353+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:06.352+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:30:06.379+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:30:36.537+0000] {processor.py:157} INFO - Started process (PID=379) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:36.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:30:36.540+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:36.539+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:36.559+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:30:36.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:36.591+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:30:36.622+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:30:36.622+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:30:36.668+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:31:06.864+0000] {processor.py:157} INFO - Started process (PID=387) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:06.869+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:31:06.871+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:06.871+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:06.891+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:06.927+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:06.927+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:31:06.967+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:06.967+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:31:06.998+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T21:31:37.189+0000] {processor.py:157} INFO - Started process (PID=395) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:37.191+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:31:37.194+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:37.193+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:37.222+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:31:37.262+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:37.262+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:31:37.294+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:31:37.294+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:31:37.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T21:32:07.589+0000] {processor.py:157} INFO - Started process (PID=403) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:07.591+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:32:07.592+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:07.592+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:07.616+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:07.652+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:07.652+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:32:07.699+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:07.699+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:32:07.725+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T21:32:14.708+0000] {processor.py:157} INFO - Started process (PID=404) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:14.710+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:32:14.712+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:14.711+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:14.735+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:14.872+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:14.872+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:32:14.898+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:14.898+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:32:14.924+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.224 seconds
[2023-10-09T21:32:45.073+0000] {processor.py:157} INFO - Started process (PID=412) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:45.074+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:32:45.076+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:45.075+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:45.099+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:32:45.135+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:45.135+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:32:45.169+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:32:45.168+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:32:45.195+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T21:33:15.456+0000] {processor.py:157} INFO - Started process (PID=420) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:15.457+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:33:15.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:15.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:15.485+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:15.518+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:15.518+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:33:15.547+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:15.547+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:33:15.638+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.191 seconds
[2023-10-09T21:33:45.735+0000] {processor.py:157} INFO - Started process (PID=427) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:45.737+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:33:45.739+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:45.738+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:45.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:33:45.800+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:45.800+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:33:45.832+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:33:45.832+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:33:45.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T21:34:16.094+0000] {processor.py:157} INFO - Started process (PID=435) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:16.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:34:16.098+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:16.097+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:16.123+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:16.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:16.156+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:34:16.189+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:16.188+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:34:16.216+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:34:24.296+0000] {processor.py:157} INFO - Started process (PID=443) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:24.298+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:34:24.300+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:24.299+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:24.324+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:24.475+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:24.475+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:34:24.505+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:24.505+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:34:24.541+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.250 seconds
[2023-10-09T21:34:54.798+0000] {processor.py:157} INFO - Started process (PID=451) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:54.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:34:54.804+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:54.803+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:54.837+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:34:54.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:54.887+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:34:54.933+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:34:54.933+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:34:54.972+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.183 seconds
[2023-10-09T21:35:25.426+0000] {processor.py:157} INFO - Started process (PID=460) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:25.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:35:25.431+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:25.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:26.043+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:26.752+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:26.752+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:35:26.931+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:26.930+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:35:27.080+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.663 seconds
[2023-10-09T21:35:57.442+0000] {processor.py:157} INFO - Started process (PID=468) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:57.444+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:35:57.447+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:57.447+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:57.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:35:57.504+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:57.504+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:35:57.535+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:35:57.534+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:35:57.563+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T21:36:27.881+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:27.882+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:36:27.885+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:27.884+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:27.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:27.937+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:27.937+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:36:27.967+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:27.967+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:36:27.991+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T21:36:58.169+0000] {processor.py:157} INFO - Started process (PID=483) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:58.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:36:58.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:58.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:58.195+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:36:58.236+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:58.236+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:36:58.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:36:58.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:36:58.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T21:37:28.611+0000] {processor.py:157} INFO - Started process (PID=491) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:28.612+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:37:28.614+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:28.614+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:28.636+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:28.668+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:28.668+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:37:28.698+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:28.697+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:37:28.719+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T21:37:58.943+0000] {processor.py:157} INFO - Started process (PID=499) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:58.945+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:37:58.947+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:58.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:58.970+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:37:59.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:59.003+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:37:59.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:37:59.033+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:37:59.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:38:29.334+0000] {processor.py:157} INFO - Started process (PID=507) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:29.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:38:29.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:29.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:29.361+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:29.398+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:29.398+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:38:29.427+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:29.427+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:38:29.451+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T21:38:59.649+0000] {processor.py:157} INFO - Started process (PID=514) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:59.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:38:59.653+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:59.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:59.678+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:38:59.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:59.719+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:38:59.751+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:38:59.751+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:38:59.776+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:39:30.014+0000] {processor.py:157} INFO - Started process (PID=521) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:39:30.016+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:39:30.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:39:30.017+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:39:30.045+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:39:30.094+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:39:30.094+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:39:30.130+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:39:30.130+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:39:30.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T21:40:00.326+0000] {processor.py:157} INFO - Started process (PID=529) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:00.327+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:40:00.329+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:00.329+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:00.350+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:00.415+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:00.415+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:40:00.446+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:00.445+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:40:00.469+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T21:40:30.684+0000] {processor.py:157} INFO - Started process (PID=536) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:30.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:40:30.690+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:30.689+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:30.715+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:40:30.753+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:30.753+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:40:30.785+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:40:30.785+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:40:30.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T21:41:01.074+0000] {processor.py:157} INFO - Started process (PID=544) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:01.076+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:41:01.079+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:01.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:01.104+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:01.137+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:01.137+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:41:01.166+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:01.166+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:41:01.201+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:41:31.425+0000] {processor.py:157} INFO - Started process (PID=552) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:31.428+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:41:31.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:31.430+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:31.454+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:41:31.487+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:31.487+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:41:31.520+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:41:31.520+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:41:31.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T21:42:01.822+0000] {processor.py:157} INFO - Started process (PID=560) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:01.824+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:42:01.827+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:01.826+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:01.848+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:01.883+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:01.883+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:42:01.914+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:01.914+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:42:01.944+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:42:32.146+0000] {processor.py:157} INFO - Started process (PID=568) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:32.147+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:42:32.149+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:32.148+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:32.170+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:42:32.209+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:32.209+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:42:32.242+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:42:32.241+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:42:32.266+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T21:43:02.570+0000] {processor.py:157} INFO - Started process (PID=576) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:02.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:43:02.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:02.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:02.593+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:02.625+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:02.625+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:43:02.655+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:02.655+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:43:02.697+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:43:32.878+0000] {processor.py:157} INFO - Started process (PID=584) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:32.879+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:43:32.881+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:32.880+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:32.901+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:43:32.935+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:32.935+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:43:32.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:43:32.968+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:43:33.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T21:44:03.269+0000] {processor.py:157} INFO - Started process (PID=593) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:03.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:44:03.273+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:03.272+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:03.294+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:03.328+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:03.328+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:44:03.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:03.358+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:44:03.387+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T21:44:33.616+0000] {processor.py:157} INFO - Started process (PID=601) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:33.618+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:44:33.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:33.620+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:33.645+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:44:33.679+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:33.678+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:44:33.708+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:44:33.708+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:44:33.739+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:45:04.052+0000] {processor.py:157} INFO - Started process (PID=609) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:04.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:45:04.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:04.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:04.079+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:04.113+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:04.113+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:45:04.143+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:04.143+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:45:04.180+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:45:34.349+0000] {processor.py:157} INFO - Started process (PID=617) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:34.351+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:45:34.353+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:34.352+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:34.381+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:45:34.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:34.422+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:45:34.455+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:45:34.455+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:45:34.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T21:46:04.764+0000] {processor.py:157} INFO - Started process (PID=625) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:04.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:46:04.768+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:04.767+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:04.793+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:04.826+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:04.826+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:46:04.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:04.857+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:46:04.887+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:46:35.123+0000] {processor.py:157} INFO - Started process (PID=633) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:35.124+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:46:35.126+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:35.125+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:35.147+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:46:35.181+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:35.181+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:46:35.210+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:46:35.210+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:46:35.238+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T21:47:05.548+0000] {processor.py:157} INFO - Started process (PID=641) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:05.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:47:05.552+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:05.551+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:05.575+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:05.609+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:05.609+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:47:05.639+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:05.639+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:47:05.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-09T21:47:35.842+0000] {processor.py:157} INFO - Started process (PID=649) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:35.843+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:47:35.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:35.845+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:35.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:47:35.902+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:35.902+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:47:35.932+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:47:35.932+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:47:35.961+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T21:48:06.271+0000] {processor.py:157} INFO - Started process (PID=656) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:06.272+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:48:06.274+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:06.274+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:06.299+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:06.335+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:06.335+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:48:06.367+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:06.366+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:48:06.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:48:36.566+0000] {processor.py:157} INFO - Started process (PID=664) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:36.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:48:36.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:36.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:36.599+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:48:36.634+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:36.634+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:48:36.666+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:48:36.666+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:48:36.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T21:49:06.959+0000] {processor.py:157} INFO - Started process (PID=673) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:06.960+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:49:06.962+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:06.962+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:06.984+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:07.016+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:07.016+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:49:07.045+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:07.045+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:49:07.072+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T21:49:37.256+0000] {processor.py:157} INFO - Started process (PID=680) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:37.258+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:49:37.261+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:37.260+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:37.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:49:37.331+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:37.331+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:49:37.366+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:49:37.366+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:49:37.403+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-10-09T21:50:07.710+0000] {processor.py:157} INFO - Started process (PID=689) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:07.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:50:07.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:07.724+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:07.807+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:07.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:07.850+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:50:07.881+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:07.881+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:50:07.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.218 seconds
[2023-10-09T21:50:38.008+0000] {processor.py:157} INFO - Started process (PID=697) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:38.009+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:50:38.011+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:38.011+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:38.033+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:50:38.075+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:38.075+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:50:38.107+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:50:38.107+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:50:38.132+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T21:51:08.250+0000] {processor.py:157} INFO - Started process (PID=705) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:08.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:51:08.253+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:08.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:08.279+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:08.332+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:08.332+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:51:08.402+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:08.401+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:51:08.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-10-09T21:51:38.649+0000] {processor.py:157} INFO - Started process (PID=713) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:38.651+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:51:38.654+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:38.653+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:38.680+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:51:38.712+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:38.712+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:51:38.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:51:38.743+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:51:38.766+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T21:52:08.951+0000] {processor.py:157} INFO - Started process (PID=721) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:08.953+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:52:08.955+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:08.954+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:08.980+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:09.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:09.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:52:09.049+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:09.049+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:52:09.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-10-09T21:52:39.297+0000] {processor.py:157} INFO - Started process (PID=729) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:39.299+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:52:39.301+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:39.300+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:39.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:52:39.361+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:39.361+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:52:39.391+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:52:39.391+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:52:39.419+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T21:53:09.731+0000] {processor.py:157} INFO - Started process (PID=737) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:09.735+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:53:09.738+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:09.737+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:09.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:09.819+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:09.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:53:09.855+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:09.854+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:53:09.881+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-10-09T21:53:40.063+0000] {processor.py:157} INFO - Started process (PID=746) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:40.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:53:40.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:40.067+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:40.093+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:53:40.128+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:40.128+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:53:40.161+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:53:40.161+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:53:40.191+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T21:54:10.471+0000] {processor.py:157} INFO - Started process (PID=754) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:10.473+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:54:10.476+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:10.475+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:10.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:10.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:10.541+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:54:10.572+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:10.572+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:54:10.601+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T21:54:40.815+0000] {processor.py:157} INFO - Started process (PID=763) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:40.818+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:54:40.821+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:40.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:40.851+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:54:40.886+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:40.886+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:54:40.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:54:40.917+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:54:40.946+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T21:55:11.215+0000] {processor.py:157} INFO - Started process (PID=772) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:11.217+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:55:11.219+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:11.218+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:11.241+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:11.276+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:11.276+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:55:11.306+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:11.306+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:55:11.329+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T21:55:41.539+0000] {processor.py:157} INFO - Started process (PID=780) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:41.541+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:55:41.542+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:41.542+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:41.563+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:55:41.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:41.598+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:55:41.634+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:55:41.633+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:55:41.661+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T21:56:11.923+0000] {processor.py:157} INFO - Started process (PID=789) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:11.925+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:56:11.927+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:11.926+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:11.949+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:11.982+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:11.982+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:56:12.012+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:12.011+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:56:12.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T21:56:42.249+0000] {processor.py:157} INFO - Started process (PID=797) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:42.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:56:42.255+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:42.254+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:42.281+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:56:42.314+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:42.313+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:56:42.344+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:56:42.344+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:56:42.390+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T21:57:12.580+0000] {processor.py:157} INFO - Started process (PID=805) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:12.581+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:57:12.583+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:12.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:12.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:12.651+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:12.651+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:57:12.683+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:12.683+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:57:12.706+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T21:57:42.845+0000] {processor.py:157} INFO - Started process (PID=812) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:42.850+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:57:42.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:42.856+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:43.019+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:57:43.343+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:43.342+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:57:43.495+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:57:43.494+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:57:43.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.765 seconds
[2023-10-09T21:58:13.865+0000] {processor.py:157} INFO - Started process (PID=820) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:13.870+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:58:13.872+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:13.872+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:13.915+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:13.988+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:13.988+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:58:14.031+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:14.031+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:58:14.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.210 seconds
[2023-10-09T21:58:44.150+0000] {processor.py:157} INFO - Started process (PID=828) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:44.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:58:44.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:44.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:44.182+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:58:44.216+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:44.216+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:58:44.248+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:58:44.248+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:58:44.277+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T21:59:14.482+0000] {processor.py:157} INFO - Started process (PID=836) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:14.485+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:59:14.487+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:14.487+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:14.515+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:14.554+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:14.554+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:59:14.590+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:14.589+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:59:14.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T21:59:44.796+0000] {processor.py:157} INFO - Started process (PID=843) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:44.797+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T21:59:44.800+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:44.799+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:44.843+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T21:59:45.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:45.251+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T21:59:45.274+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:45.273+0000] {dag.py:2763} INFO - Creating ORM DAG for Extract_job_data_in_selenium_container
[2023-10-09T21:59:45.296+0000] {logging_mixin.py:150} INFO - [2023-10-09T21:59:45.296+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T21:59:45.335+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.548 seconds
[2023-10-09T22:00:15.648+0000] {processor.py:157} INFO - Started process (PID=850) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:15.653+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:00:15.657+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:15.656+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:15.724+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:15.776+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:15.776+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:00:15.829+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:15.829+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:00:15.855+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.228 seconds
[2023-10-09T22:00:46.165+0000] {processor.py:157} INFO - Started process (PID=858) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:46.167+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:00:46.169+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:46.169+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:46.197+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:00:46.241+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:46.241+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:00:46.285+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:00:46.284+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:00:46.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-09T22:01:16.441+0000] {processor.py:157} INFO - Started process (PID=866) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:16.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:01:16.444+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:16.444+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:16.465+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:16.502+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:16.501+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:01:16.537+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:16.536+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:01:16.596+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.162 seconds
[2023-10-09T22:01:46.886+0000] {processor.py:157} INFO - Started process (PID=875) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:46.888+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:01:46.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:46.890+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:46.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:01:46.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:46.967+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:01:46.999+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:01:46.999+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:01:47.023+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T22:02:17.196+0000] {processor.py:157} INFO - Started process (PID=883) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:17.198+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:02:17.201+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:17.200+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:17.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:17.267+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:17.266+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:02:17.296+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:17.296+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:02:17.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T22:02:47.588+0000] {processor.py:157} INFO - Started process (PID=891) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:47.589+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:02:47.591+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:47.591+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:47.613+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:02:47.651+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:47.651+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:02:47.686+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:02:47.686+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:02:47.715+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T22:03:17.857+0000] {processor.py:157} INFO - Started process (PID=899) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:17.862+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:03:17.866+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:17.864+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:17.929+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:17.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:17.986+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:03:18.032+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:18.031+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:03:18.059+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.217 seconds
[2023-10-09T22:03:48.184+0000] {processor.py:157} INFO - Started process (PID=907) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:48.186+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:03:48.190+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:48.189+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:48.228+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:03:48.473+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:48.473+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:03:48.492+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:48.491+0000] {dag.py:2763} INFO - Creating ORM DAG for Extract_job_data_in_selenium_container
[2023-10-09T22:03:48.516+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:03:48.515+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:03:48.565+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.389 seconds
[2023-10-09T22:04:18.853+0000] {processor.py:157} INFO - Started process (PID=915) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:18.855+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:04:18.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:18.857+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:18.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:18.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:18.917+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:04:18.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:18.948+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:04:18.992+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-10-09T22:04:49.057+0000] {processor.py:157} INFO - Started process (PID=923) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:49.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:04:49.058+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:49.057+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:49.077+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:04:49.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:49.109+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:04:49.140+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:04:49.140+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:04:49.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T22:05:19.376+0000] {processor.py:157} INFO - Started process (PID=931) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:19.379+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:05:19.382+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:19.381+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:19.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:19.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:19.450+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:05:19.480+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:19.480+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:05:19.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T22:05:49.776+0000] {processor.py:157} INFO - Started process (PID=940) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:49.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:05:49.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:49.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:49.803+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:05:49.837+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:49.836+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:05:49.869+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:05:49.869+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:05:49.894+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T22:06:20.053+0000] {processor.py:157} INFO - Started process (PID=948) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:20.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:06:20.056+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:20.056+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:20.081+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:20.118+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:20.117+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:06:20.153+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:20.153+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:06:20.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T22:06:50.370+0000] {processor.py:157} INFO - Started process (PID=956) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:50.371+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:06:50.373+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:50.372+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:50.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:06:50.434+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:50.434+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:06:50.464+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:06:50.464+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:06:50.487+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T22:07:20.745+0000] {processor.py:157} INFO - Started process (PID=964) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:20.747+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:07:20.750+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:20.749+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:20.778+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:20.812+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:20.812+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:07:20.842+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:20.841+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:07:20.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:07:51.097+0000] {processor.py:157} INFO - Started process (PID=973) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:51.099+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:07:51.101+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:51.100+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:51.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:07:51.153+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:51.153+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:07:51.183+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:07:51.183+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:07:51.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T22:08:21.430+0000] {processor.py:157} INFO - Started process (PID=981) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:21.432+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:08:21.435+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:21.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:21.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:21.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:21.492+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:08:21.525+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:21.525+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:08:21.549+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:08:51.786+0000] {processor.py:157} INFO - Started process (PID=989) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:51.788+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:08:51.790+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:51.789+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:51.815+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:08:51.852+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:51.852+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:08:51.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:08:51.887+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:08:51.915+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T22:09:22.169+0000] {processor.py:157} INFO - Started process (PID=996) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:22.172+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:09:22.178+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:22.177+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:22.213+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:22.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:22.251+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:09:22.285+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:22.285+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:09:22.311+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.166 seconds
[2023-10-09T22:09:52.553+0000] {processor.py:157} INFO - Started process (PID=1004) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:52.555+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:09:52.558+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:52.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:52.588+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:09:52.624+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:52.624+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:09:52.653+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:09:52.653+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:09:52.677+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T22:10:22.950+0000] {processor.py:157} INFO - Started process (PID=1012) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:22.952+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:10:22.954+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:22.953+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:22.975+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:23.009+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:23.009+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:10:23.042+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:23.042+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:10:23.081+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T22:10:53.334+0000] {processor.py:157} INFO - Started process (PID=1020) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:53.336+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:10:53.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:53.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:53.363+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:10:53.397+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:53.397+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:10:53.428+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:10:53.427+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:10:53.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T22:11:23.618+0000] {processor.py:157} INFO - Started process (PID=1028) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:23.619+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:11:23.621+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:23.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:23.652+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:23.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:23.689+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:11:23.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:23.725+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:11:23.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T22:11:54.040+0000] {processor.py:157} INFO - Started process (PID=1037) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:54.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:11:54.051+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:54.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:54.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:11:54.110+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:54.110+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:11:54.142+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:11:54.141+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:11:54.164+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T22:12:24.318+0000] {processor.py:157} INFO - Started process (PID=1045) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:24.320+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:12:24.323+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:24.322+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:24.362+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:24.399+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:24.399+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:12:24.431+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:24.431+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:12:24.457+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T22:12:54.659+0000] {processor.py:157} INFO - Started process (PID=1054) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:54.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:12:54.662+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:54.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:54.696+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:12:54.742+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:54.741+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:12:54.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:12:54.787+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:12:54.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.189 seconds
[2023-10-09T22:13:24.884+0000] {processor.py:157} INFO - Started process (PID=1062) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:24.885+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:13:24.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:24.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:24.909+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:24.941+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:24.941+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:13:24.997+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:24.996+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:13:25.020+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T22:13:55.158+0000] {processor.py:157} INFO - Started process (PID=1069) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:55.160+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:13:55.162+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:55.161+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:55.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:13:55.225+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:55.225+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:13:55.255+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:13:55.255+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:13:55.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:14:25.584+0000] {processor.py:157} INFO - Started process (PID=1077) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:25.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:14:25.588+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:25.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:25.615+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:25.650+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:25.650+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:14:25.683+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:25.683+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:14:25.737+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T22:14:55.952+0000] {processor.py:157} INFO - Started process (PID=1085) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:55.954+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:14:55.956+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:55.955+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:55.982+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:14:56.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:56.018+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:14:56.049+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:14:56.049+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:14:56.112+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.168 seconds
[2023-10-09T22:15:26.352+0000] {processor.py:157} INFO - Started process (PID=1093) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:26.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:15:26.357+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:26.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:26.382+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:26.415+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:26.414+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:15:26.446+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:26.446+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:15:26.473+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T22:15:56.692+0000] {processor.py:157} INFO - Started process (PID=1101) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:56.694+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:15:56.696+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:56.695+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:56.720+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:15:56.754+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:56.754+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:15:56.783+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:15:56.783+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:15:56.805+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T22:16:27.045+0000] {processor.py:157} INFO - Started process (PID=1109) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:27.046+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:16:27.048+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:27.048+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:27.070+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:27.102+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:27.102+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:16:27.132+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:27.132+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:16:27.157+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T22:16:57.382+0000] {processor.py:157} INFO - Started process (PID=1116) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:57.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:16:57.387+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:57.387+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:57.409+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:16:57.443+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:57.442+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:16:57.487+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:16:57.487+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:16:57.529+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-10-09T22:17:27.754+0000] {processor.py:157} INFO - Started process (PID=1124) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:27.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:17:27.760+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:27.759+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:27.788+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:27.820+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:27.819+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:17:27.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:27.850+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:17:27.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T22:17:58.136+0000] {processor.py:157} INFO - Started process (PID=1132) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:58.139+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:17:58.140+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:58.140+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:58.163+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:17:58.200+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:58.200+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:17:58.234+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:17:58.233+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:17:58.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-09T22:18:28.447+0000] {processor.py:157} INFO - Started process (PID=1147) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:28.448+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:18:28.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:28.449+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:28.471+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:28.508+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:28.507+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:18:28.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:28.543+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:18:28.571+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:18:58.757+0000] {processor.py:157} INFO - Started process (PID=1155) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:58.759+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:18:58.762+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:58.761+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:58.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:18:58.823+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:58.823+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:18:58.855+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:18:58.855+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:18:58.878+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T22:19:29.163+0000] {processor.py:157} INFO - Started process (PID=1163) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:29.165+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:19:29.167+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:29.167+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:29.190+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:29.223+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:29.223+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:19:29.252+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:29.252+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:19:29.282+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:19:59.533+0000] {processor.py:157} INFO - Started process (PID=1171) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:59.535+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:19:59.538+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:59.537+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:59.565+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:19:59.604+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:59.604+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:19:59.636+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:19:59.635+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:19:59.669+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T22:20:29.914+0000] {processor.py:157} INFO - Started process (PID=1179) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:20:29.916+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:20:29.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:20:29.917+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:20:29.940+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:20:29.994+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:20:29.994+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:20:30.040+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:20:30.040+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:20:30.084+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.174 seconds
[2023-10-09T22:21:00.323+0000] {processor.py:157} INFO - Started process (PID=1187) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:00.324+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:21:00.326+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:00.325+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:00.352+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:00.388+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:00.388+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:21:00.418+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:00.418+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:21:00.454+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.152 seconds
[2023-10-09T22:21:30.658+0000] {processor.py:157} INFO - Started process (PID=1195) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:30.660+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:21:30.661+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:30.661+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:30.683+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:21:30.717+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:30.717+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:21:30.787+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:21:30.787+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:21:30.812+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-10-09T22:22:01.028+0000] {processor.py:157} INFO - Started process (PID=1203) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:01.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:22:01.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:01.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:01.059+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:01.094+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:01.094+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:22:01.125+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:01.125+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:22:01.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:22:31.407+0000] {processor.py:157} INFO - Started process (PID=1211) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:31.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:22:31.411+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:31.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:31.432+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:22:31.466+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:31.465+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:22:31.498+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:22:31.498+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:22:31.522+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T22:23:01.748+0000] {processor.py:157} INFO - Started process (PID=1219) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:01.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:23:01.753+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:01.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:01.775+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:01.808+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:01.808+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:23:01.840+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:01.839+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:23:01.867+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T22:23:32.201+0000] {processor.py:157} INFO - Started process (PID=1227) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:32.203+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:23:32.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:32.204+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:32.227+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:23:32.259+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:32.259+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:23:32.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:23:32.289+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:23:32.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:24:02.625+0000] {processor.py:157} INFO - Started process (PID=1235) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:02.627+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:24:02.630+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:02.630+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:02.657+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:02.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:02.689+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:24:02.719+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:02.719+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:24:02.753+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T22:24:32.978+0000] {processor.py:157} INFO - Started process (PID=1243) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:32.980+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:24:32.982+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:32.981+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:33.011+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:24:33.045+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:33.044+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:24:33.075+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:24:33.074+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:24:33.103+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T22:25:03.507+0000] {processor.py:157} INFO - Started process (PID=1250) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:03.509+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:25:03.511+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:03.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:03.533+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:03.567+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:03.566+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:25:03.596+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:03.596+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:25:03.625+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T22:25:33.847+0000] {processor.py:157} INFO - Started process (PID=1258) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:33.849+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:25:33.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:33.850+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:33.877+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:25:33.911+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:33.911+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:25:33.942+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:25:33.942+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:25:33.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:26:04.269+0000] {processor.py:157} INFO - Started process (PID=1266) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:04.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:26:04.271+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:04.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:04.290+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:04.322+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:04.322+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:26:04.356+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:04.355+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:26:04.382+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T22:26:34.585+0000] {processor.py:157} INFO - Started process (PID=1275) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:34.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:26:34.588+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:34.587+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:34.607+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:26:34.640+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:34.640+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:26:34.671+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:26:34.670+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:26:34.695+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-09T22:27:04.970+0000] {processor.py:157} INFO - Started process (PID=1283) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:04.972+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:27:04.973+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:04.973+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:05.000+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:05.034+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:05.033+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:27:05.064+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:05.064+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:27:05.087+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T22:27:35.338+0000] {processor.py:157} INFO - Started process (PID=1291) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:35.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:27:35.342+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:35.341+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:35.369+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:27:35.401+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:35.401+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:27:35.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:27:35.431+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:27:35.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T22:28:05.691+0000] {processor.py:157} INFO - Started process (PID=1299) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:05.693+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:28:05.695+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:05.694+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:05.716+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:05.750+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:05.750+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:28:05.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:05.780+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:28:05.803+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T22:28:36.055+0000] {processor.py:157} INFO - Started process (PID=1307) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:36.056+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:28:36.058+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:36.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:36.078+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:28:36.111+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:36.111+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:28:36.142+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:28:36.142+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:28:36.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T22:29:06.382+0000] {processor.py:157} INFO - Started process (PID=1315) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:06.384+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:29:06.385+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:06.385+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:06.404+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:06.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:06.438+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:29:06.469+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:06.469+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:29:06.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T22:29:36.826+0000] {processor.py:157} INFO - Started process (PID=1324) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:36.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:29:36.830+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:36.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:36.852+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:29:36.885+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:36.885+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:29:36.915+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:29:36.915+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:29:36.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T22:30:07.236+0000] {processor.py:157} INFO - Started process (PID=1332) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:07.239+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:30:07.241+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:07.241+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:07.265+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:07.297+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:07.297+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:30:07.327+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:07.327+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:30:07.356+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T22:30:37.556+0000] {processor.py:157} INFO - Started process (PID=1340) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:37.559+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:30:37.561+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:37.560+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:37.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:30:37.623+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:37.623+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:30:37.653+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:30:37.652+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:30:37.678+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T22:31:08.012+0000] {processor.py:157} INFO - Started process (PID=1348) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:08.014+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:31:08.016+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:08.015+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:08.038+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:08.074+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:08.074+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:31:08.105+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:08.104+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:31:08.135+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:31:38.358+0000] {processor.py:157} INFO - Started process (PID=1357) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:38.359+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:31:38.362+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:38.361+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:38.388+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:31:38.422+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:38.422+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:31:38.452+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:31:38.451+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:31:38.480+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:32:08.765+0000] {processor.py:157} INFO - Started process (PID=1365) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:08.767+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:32:08.769+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:08.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:08.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:08.825+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:08.825+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:32:08.855+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:08.854+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:32:08.877+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T22:32:39.113+0000] {processor.py:157} INFO - Started process (PID=1373) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:39.114+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:32:39.116+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:39.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:39.141+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:32:39.175+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:39.175+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:32:39.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:32:39.205+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:32:39.241+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T22:33:09.455+0000] {processor.py:157} INFO - Started process (PID=1381) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:09.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:33:09.458+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:09.458+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:09.480+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:09.515+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:09.514+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:33:09.544+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:09.544+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:33:09.583+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T22:33:39.837+0000] {processor.py:157} INFO - Started process (PID=1390) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:39.838+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:33:39.840+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:39.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:39.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:33:39.892+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:39.892+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:33:39.921+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:33:39.921+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:33:39.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T22:34:10.222+0000] {processor.py:157} INFO - Started process (PID=1398) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:10.225+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:34:10.229+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:10.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:10.275+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:10.310+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:10.309+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:34:10.339+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:10.339+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:34:10.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T22:34:40.601+0000] {processor.py:157} INFO - Started process (PID=1406) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:40.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:34:40.606+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:40.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:40.635+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:34:40.668+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:40.668+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:34:40.699+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:34:40.699+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:34:40.722+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:35:11.058+0000] {processor.py:157} INFO - Started process (PID=1414) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:11.059+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:35:11.061+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:11.061+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:11.082+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:11.114+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:11.113+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:35:11.143+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:11.143+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:35:11.169+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T22:35:41.422+0000] {processor.py:157} INFO - Started process (PID=1422) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:41.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:35:41.426+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:41.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:41.447+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:35:41.481+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:41.481+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:35:41.511+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:35:41.511+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:35:41.538+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T22:36:11.753+0000] {processor.py:157} INFO - Started process (PID=1430) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:11.755+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:36:11.759+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:11.758+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:11.789+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:11.821+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:11.821+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:36:11.850+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:11.850+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:36:11.873+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:36:42.053+0000] {processor.py:157} INFO - Started process (PID=1438) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:42.054+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:36:42.055+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:42.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:42.075+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:36:42.109+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:42.109+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:36:42.139+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:36:42.139+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:36:42.165+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-09T22:37:12.407+0000] {processor.py:157} INFO - Started process (PID=1446) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:12.409+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:37:12.410+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:12.410+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:12.429+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:12.461+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:12.460+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:37:12.491+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:12.490+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:37:12.514+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-09T22:37:42.695+0000] {processor.py:157} INFO - Started process (PID=1454) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:42.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:37:42.698+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:42.698+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:42.718+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:37:42.753+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:42.753+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:37:42.785+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:37:42.785+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:37:42.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T22:38:13.085+0000] {processor.py:157} INFO - Started process (PID=1463) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:13.087+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:38:13.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:13.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:13.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:13.144+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:13.143+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:38:13.173+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:13.173+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:38:13.196+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-09T22:38:43.420+0000] {processor.py:157} INFO - Started process (PID=1471) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:43.424+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:38:43.427+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:43.426+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:43.448+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:38:43.482+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:43.482+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:38:43.511+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:38:43.511+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:38:43.548+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T22:39:13.804+0000] {processor.py:157} INFO - Started process (PID=1479) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:13.806+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:39:13.808+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:13.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:13.832+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:13.864+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:13.864+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:39:13.893+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:13.893+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:39:13.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:39:44.150+0000] {processor.py:157} INFO - Started process (PID=1487) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:44.152+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:39:44.155+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:44.154+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:44.184+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:39:44.221+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:44.221+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:39:44.250+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:39:44.250+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:39:44.279+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T22:40:14.570+0000] {processor.py:157} INFO - Started process (PID=1496) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:14.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:40:14.573+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:14.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:14.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:14.635+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:14.635+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:40:14.665+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:14.665+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:40:14.690+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T22:40:44.919+0000] {processor.py:157} INFO - Started process (PID=1503) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:44.920+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:40:44.922+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:44.921+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:44.945+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:40:44.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:44.979+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:40:45.008+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:40:45.008+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:40:45.035+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T22:41:15.396+0000] {processor.py:157} INFO - Started process (PID=1511) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:15.397+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:41:15.399+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:15.399+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:15.424+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:15.459+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:15.458+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:41:15.493+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:15.493+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:41:15.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:41:45.698+0000] {processor.py:157} INFO - Started process (PID=1519) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:45.699+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:41:45.700+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:45.700+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:45.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:41:45.756+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:45.756+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:41:45.803+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:41:45.803+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:41:45.828+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T22:42:16.094+0000] {processor.py:157} INFO - Started process (PID=1527) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:16.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:42:16.096+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:16.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:16.117+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:16.154+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:16.154+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:42:16.184+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:16.184+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:42:16.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-09T22:42:46.367+0000] {processor.py:157} INFO - Started process (PID=1535) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:46.368+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:42:46.370+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:46.370+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:46.391+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:42:46.429+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:46.429+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:42:46.461+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:42:46.461+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:42:46.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T22:43:16.792+0000] {processor.py:157} INFO - Started process (PID=1543) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:16.793+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:43:16.795+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:16.794+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:16.813+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:16.845+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:16.845+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:43:16.876+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:16.876+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:43:16.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T22:43:47.125+0000] {processor.py:157} INFO - Started process (PID=1551) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:47.128+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:43:47.130+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:47.129+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:47.160+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:43:47.194+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:47.194+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:43:47.224+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:43:47.224+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:43:47.250+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T22:44:17.577+0000] {processor.py:157} INFO - Started process (PID=1560) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:17.578+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:44:17.581+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:17.580+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:17.603+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:17.636+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:17.636+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:44:17.666+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:17.666+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:44:17.691+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T22:44:47.935+0000] {processor.py:157} INFO - Started process (PID=1568) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:47.937+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:44:47.941+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:47.940+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:47.977+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:44:48.014+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:48.013+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:44:48.044+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:44:48.044+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:44:48.067+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-09T22:45:18.408+0000] {processor.py:157} INFO - Started process (PID=1576) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:18.410+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:45:18.412+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:18.411+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:18.437+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:18.469+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:18.469+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:45:18.501+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:18.500+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:45:18.527+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:45:48.704+0000] {processor.py:157} INFO - Started process (PID=1584) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:48.706+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:45:48.708+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:48.708+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:48.729+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:45:48.762+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:48.762+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:45:48.793+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:45:48.793+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:45:48.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T22:46:19.120+0000] {processor.py:157} INFO - Started process (PID=1592) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:19.121+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:46:19.123+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:19.122+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:19.143+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:19.179+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:19.178+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:46:19.210+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:19.210+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:46:19.240+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T22:46:49.474+0000] {processor.py:157} INFO - Started process (PID=1600) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:49.476+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:46:49.479+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:49.478+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:49.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:46:49.540+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:49.540+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:46:49.572+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:46:49.572+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:46:49.595+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T22:47:19.846+0000] {processor.py:157} INFO - Started process (PID=1608) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:19.847+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:47:19.849+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:19.848+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:19.871+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:19.905+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:19.904+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:47:19.934+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:19.934+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:47:19.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T22:47:50.174+0000] {processor.py:157} INFO - Started process (PID=1616) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:50.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:47:50.178+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:50.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:50.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:47:50.232+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:50.232+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:47:50.262+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:47:50.262+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:47:50.290+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T22:48:20.560+0000] {processor.py:157} INFO - Started process (PID=1624) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:20.562+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:48:20.564+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:20.564+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:20.595+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:20.630+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:20.630+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:48:20.660+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:20.660+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:48:20.689+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T22:48:50.941+0000] {processor.py:157} INFO - Started process (PID=1632) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:50.944+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:48:50.947+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:50.946+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:50.971+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:48:51.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:51.003+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:48:51.034+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:48:51.033+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:48:51.076+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T22:49:21.300+0000] {processor.py:157} INFO - Started process (PID=1640) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:21.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:49:21.304+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:21.303+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:21.327+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:21.362+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:21.362+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:49:21.393+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:21.393+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:49:21.420+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T22:49:51.702+0000] {processor.py:157} INFO - Started process (PID=1648) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:51.704+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:49:51.707+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:51.706+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:51.738+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:49:51.775+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:51.775+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:49:51.805+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:49:51.805+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:49:51.829+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T22:50:22.103+0000] {processor.py:157} INFO - Started process (PID=1656) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:22.106+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:50:22.108+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:22.107+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:22.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:22.166+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:22.166+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:50:22.196+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:22.195+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:50:22.254+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-10-09T22:50:52.461+0000] {processor.py:157} INFO - Started process (PID=1664) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:52.465+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:50:52.468+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:52.467+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:52.495+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:50:52.531+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:52.531+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:50:52.562+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:50:52.562+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:50:52.590+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T22:51:22.859+0000] {processor.py:157} INFO - Started process (PID=1672) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:22.861+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:51:22.862+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:22.862+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:22.883+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:22.916+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:22.916+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:51:22.946+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:22.946+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:51:22.973+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T22:51:53.183+0000] {processor.py:157} INFO - Started process (PID=1680) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:53.184+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:51:53.186+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:53.185+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:53.206+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:51:53.239+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:53.239+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:51:53.272+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:51:53.272+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:51:53.343+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-10-09T22:52:23.601+0000] {processor.py:157} INFO - Started process (PID=1689) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:23.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:52:23.606+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:23.605+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:23.631+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:23.663+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:23.663+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:52:23.693+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:23.693+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:52:23.736+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T22:52:53.974+0000] {processor.py:157} INFO - Started process (PID=1697) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:53.976+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:52:53.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:53.978+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:54.005+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:52:54.038+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:54.037+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:52:54.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:52:54.067+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:52:54.096+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T22:53:24.382+0000] {processor.py:157} INFO - Started process (PID=1704) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:24.385+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:53:24.389+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:24.388+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:24.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:24.441+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:24.441+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:53:24.471+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:24.470+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:53:24.499+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:53:54.742+0000] {processor.py:157} INFO - Started process (PID=1712) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:54.744+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:53:54.748+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:54.747+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:54.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:53:54.811+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:54.811+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:53:54.841+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:53:54.841+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:53:54.872+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T22:54:25.151+0000] {processor.py:157} INFO - Started process (PID=1720) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:25.153+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:54:25.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:25.155+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:25.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:25.249+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:25.249+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:54:25.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:25.283+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:54:25.307+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-09T22:54:55.516+0000] {processor.py:157} INFO - Started process (PID=1729) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:55.518+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:54:55.520+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:55.519+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:55.543+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:54:55.580+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:55.580+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:54:55.620+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:54:55.620+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:54:55.644+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T22:55:25.907+0000] {processor.py:157} INFO - Started process (PID=1737) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:25.909+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:55:25.912+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:25.911+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:25.938+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:25.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:25.978+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:55:26.011+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:26.010+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:55:26.034+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T22:55:56.273+0000] {processor.py:157} INFO - Started process (PID=1746) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:56.276+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:55:56.280+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:56.279+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:56.315+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:55:56.349+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:56.349+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:55:56.378+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:55:56.378+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:55:56.407+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.147 seconds
[2023-10-09T22:56:26.721+0000] {processor.py:157} INFO - Started process (PID=1754) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:26.723+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:56:26.726+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:26.725+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:26.754+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:26.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:26.788+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:56:26.818+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:26.818+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:56:26.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:56:57.069+0000] {processor.py:157} INFO - Started process (PID=1762) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:57.070+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:56:57.072+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:57.071+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:57.092+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:56:57.126+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:57.125+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:56:57.156+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:56:57.155+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:56:57.193+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T22:57:27.475+0000] {processor.py:157} INFO - Started process (PID=1769) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:27.478+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:57:27.481+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:27.480+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:27.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:27.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:27.541+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:57:27.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:27.574+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:57:27.599+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T22:57:57.814+0000] {processor.py:157} INFO - Started process (PID=1777) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:57.816+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:57:57.818+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:57.817+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:57.845+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:57:57.882+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:57.882+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:57:57.913+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:57:57.913+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:57:57.937+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T22:58:28.203+0000] {processor.py:157} INFO - Started process (PID=1785) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:28.205+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:58:28.208+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:28.207+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:28.234+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:28.268+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:28.268+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:58:28.298+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:28.298+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:58:28.325+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T22:58:58.508+0000] {processor.py:157} INFO - Started process (PID=1793) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:58.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:58:58.512+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:58.511+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:58.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:58:58.589+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:58.589+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:58:58.639+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:58:58.638+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:58:58.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.181 seconds
[2023-10-09T22:59:28.947+0000] {processor.py:157} INFO - Started process (PID=1800) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:28.948+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:59:28.950+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:28.949+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:28.969+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:29.003+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:29.002+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:59:29.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:29.033+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:59:29.064+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T22:59:59.282+0000] {processor.py:157} INFO - Started process (PID=1808) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:59.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T22:59:59.287+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:59.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:59.311+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T22:59:59.346+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:59.346+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T22:59:59.378+0000] {logging_mixin.py:150} INFO - [2023-10-09T22:59:59.377+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T22:59:59.406+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T23:00:29.684+0000] {processor.py:157} INFO - Started process (PID=1816) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:00:29.685+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:00:29.687+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:00:29.686+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:00:29.708+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:00:29.740+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:00:29.739+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:00:29.771+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:00:29.770+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:00:29.810+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T23:01:00.028+0000] {processor.py:157} INFO - Started process (PID=1824) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:00.030+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:01:00.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:00.033+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:00.058+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:00.093+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:00.092+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:01:00.122+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:00.122+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:01:00.175+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.163 seconds
[2023-10-09T23:01:30.436+0000] {processor.py:157} INFO - Started process (PID=1832) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:30.437+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:01:30.441+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:30.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:30.464+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:01:30.496+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:30.496+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:01:30.526+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:01:30.526+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:01:30.587+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T23:02:00.749+0000] {processor.py:157} INFO - Started process (PID=1839) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:00.751+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:02:00.754+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:00.753+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:00.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:00.810+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:00.810+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:02:00.841+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:00.840+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:02:00.864+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T23:02:31.170+0000] {processor.py:157} INFO - Started process (PID=1847) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:31.171+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:02:31.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:31.172+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:31.192+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:02:31.225+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:31.225+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:02:31.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:02:31.266+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:02:31.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T23:03:01.536+0000] {processor.py:157} INFO - Started process (PID=1855) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:01.538+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:03:01.541+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:01.540+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:01.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:01.613+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:01.613+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:03:01.656+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:01.656+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:03:01.684+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.155 seconds
[2023-10-09T23:03:31.955+0000] {processor.py:157} INFO - Started process (PID=1863) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:31.958+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:03:31.961+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:31.960+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:31.985+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:03:32.018+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:32.017+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:03:32.048+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:03:32.047+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:03:32.099+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T23:04:02.299+0000] {processor.py:157} INFO - Started process (PID=1871) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:02.302+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:04:02.304+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:02.304+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:02.329+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:02.367+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:02.367+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:04:02.396+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:02.396+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:04:02.425+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T23:04:32.764+0000] {processor.py:157} INFO - Started process (PID=1879) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:32.766+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:04:32.769+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:32.768+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:32.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:04:32.831+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:32.831+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:04:32.862+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:04:32.862+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:04:32.900+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T23:05:03.192+0000] {processor.py:157} INFO - Started process (PID=1887) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:03.194+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:05:03.197+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:03.196+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:03.224+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:03.256+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:03.256+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:05:03.287+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:03.286+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:05:03.316+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T23:05:33.541+0000] {processor.py:157} INFO - Started process (PID=1895) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:33.542+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:05:33.545+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:33.544+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:33.570+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:05:33.608+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:33.608+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:05:33.641+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:05:33.641+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:05:33.665+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T23:06:03.975+0000] {processor.py:157} INFO - Started process (PID=1903) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:03.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:06:03.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:03.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:04.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:04.038+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:04.038+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:06:04.069+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:04.069+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:06:04.098+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T23:06:34.372+0000] {processor.py:157} INFO - Started process (PID=1911) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:34.374+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:06:34.377+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:34.376+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:34.401+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:06:34.437+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:34.436+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:06:34.471+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:06:34.471+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:06:34.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.169 seconds
[2023-10-09T23:07:04.776+0000] {processor.py:157} INFO - Started process (PID=1918) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:04.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:07:04.780+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:04.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:04.805+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:04.843+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:04.843+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:07:04.873+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:04.873+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:07:04.897+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T23:07:35.150+0000] {processor.py:157} INFO - Started process (PID=1927) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:35.151+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:07:35.153+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:35.152+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:35.177+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:07:35.212+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:35.212+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:07:35.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:07:35.243+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:07:35.275+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T23:08:05.457+0000] {processor.py:157} INFO - Started process (PID=1935) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:05.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:08:05.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:05.459+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:05.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:05.512+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:05.512+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:08:05.543+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:05.542+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:08:05.611+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.158 seconds
[2023-10-09T23:08:35.851+0000] {processor.py:157} INFO - Started process (PID=1943) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:35.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:08:35.855+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:35.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:35.880+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:08:35.913+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:35.913+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:08:35.944+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:08:35.944+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:08:35.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T23:09:06.281+0000] {processor.py:157} INFO - Started process (PID=1951) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:06.285+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:09:06.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:06.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:06.334+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:06.375+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:06.375+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:09:06.409+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:06.409+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:09:06.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.218 seconds
[2023-10-09T23:09:36.618+0000] {processor.py:157} INFO - Started process (PID=1959) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:36.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:09:36.622+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:36.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:36.642+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:09:36.675+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:36.675+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:09:36.705+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:09:36.705+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:09:36.742+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T23:10:07.018+0000] {processor.py:157} INFO - Started process (PID=1967) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:07.020+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:10:07.022+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:07.022+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:07.044+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:07.086+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:07.086+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:10:07.115+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:07.115+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:10:07.138+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T23:10:37.335+0000] {processor.py:157} INFO - Started process (PID=1976) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:37.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:10:37.338+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:37.338+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:37.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:10:37.400+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:37.400+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:10:37.430+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:10:37.430+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:10:37.464+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-09T23:11:07.778+0000] {processor.py:157} INFO - Started process (PID=1985) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:07.779+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:11:07.781+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:07.780+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:07.808+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:07.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:07.848+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:11:07.882+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:07.882+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:11:07.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-09T23:11:38.113+0000] {processor.py:157} INFO - Started process (PID=1992) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:38.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:11:38.117+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:38.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:38.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:11:38.174+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:38.174+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:11:38.205+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:11:38.204+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:11:38.228+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T23:12:08.461+0000] {processor.py:157} INFO - Started process (PID=1999) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:08.462+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:12:08.464+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:08.463+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:08.484+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:08.517+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:08.516+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:12:08.548+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:08.547+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:12:08.591+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T23:12:38.755+0000] {processor.py:157} INFO - Started process (PID=2007) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:38.757+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:12:38.761+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:38.760+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:38.788+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:12:38.826+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:38.826+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:12:38.860+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:12:38.859+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:12:38.889+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T23:13:09.144+0000] {processor.py:157} INFO - Started process (PID=2015) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:09.146+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:13:09.148+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:09.147+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:09.169+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:09.207+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:09.206+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:13:09.251+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:09.251+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:13:09.278+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-09T23:13:39.420+0000] {processor.py:157} INFO - Started process (PID=2031) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:39.421+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:13:39.423+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:39.422+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:39.442+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:13:39.476+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:39.476+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:13:39.509+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:13:39.509+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:13:39.561+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:14:09.799+0000] {processor.py:157} INFO - Started process (PID=2039) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:09.801+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:14:09.802+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:09.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:09.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:09.858+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:09.857+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:14:09.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:09.891+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:14:09.921+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:14:40.159+0000] {processor.py:157} INFO - Started process (PID=2047) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:40.161+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:14:40.163+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:40.162+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:40.185+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:14:40.227+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:40.227+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:14:40.263+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:14:40.263+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:14:40.300+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.148 seconds
[2023-10-09T23:15:10.591+0000] {processor.py:157} INFO - Started process (PID=2055) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:10.593+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:15:10.595+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:10.594+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:10.618+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:10.654+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:10.654+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:15:10.687+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:10.687+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:15:10.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T23:15:40.931+0000] {processor.py:157} INFO - Started process (PID=2063) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:40.933+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:15:40.936+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:40.936+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:40.966+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:15:41.001+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:41.001+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:15:41.030+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:15:41.030+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:15:41.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T23:16:11.343+0000] {processor.py:157} INFO - Started process (PID=2070) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:11.344+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:16:11.347+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:11.346+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:11.368+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:11.401+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:11.401+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:16:11.433+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:11.433+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:16:11.479+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T23:16:41.694+0000] {processor.py:157} INFO - Started process (PID=2078) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:41.697+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:16:41.700+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:41.699+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:41.723+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:16:41.756+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:41.756+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:16:41.788+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:16:41.788+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:16:41.818+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T23:17:12.085+0000] {processor.py:157} INFO - Started process (PID=2085) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:12.086+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:17:12.089+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:12.088+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:12.111+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:12.144+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:12.143+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:17:12.175+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:12.174+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:17:12.203+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:17:42.440+0000] {processor.py:157} INFO - Started process (PID=2093) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:42.443+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:17:42.445+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:42.445+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:42.481+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:17:42.522+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:42.522+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:17:42.557+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:17:42.557+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:17:42.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T23:18:12.820+0000] {processor.py:157} INFO - Started process (PID=2101) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:12.822+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:18:12.823+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:12.823+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:12.844+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:12.880+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:12.880+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:18:12.910+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:12.910+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:18:12.938+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T23:18:43.191+0000] {processor.py:157} INFO - Started process (PID=2109) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:43.193+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:18:43.195+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:43.194+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:43.219+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:18:43.253+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:43.253+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:18:43.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:18:43.283+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:18:43.306+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:19:13.569+0000] {processor.py:157} INFO - Started process (PID=2117) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:13.571+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:19:13.573+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:13.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:13.600+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:13.636+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:13.636+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:19:13.669+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:13.668+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:19:13.698+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-09T23:19:43.887+0000] {processor.py:157} INFO - Started process (PID=2125) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:43.889+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:19:43.891+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:43.891+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:43.916+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:19:43.951+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:43.950+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:19:43.982+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:19:43.982+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:19:44.021+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T23:20:14.391+0000] {processor.py:157} INFO - Started process (PID=2133) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:14.393+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:20:14.395+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:14.394+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:14.418+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:14.458+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:14.458+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:20:14.494+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:14.494+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:20:14.535+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T23:20:44.738+0000] {processor.py:157} INFO - Started process (PID=2141) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:44.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:20:44.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:44.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:44.776+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:20:44.812+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:44.811+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:20:44.842+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:20:44.842+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:20:44.866+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T23:21:15.108+0000] {processor.py:157} INFO - Started process (PID=2150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:15.109+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:21:15.113+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:15.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:15.133+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:15.165+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:15.165+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:21:15.196+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:15.195+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:21:15.224+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T23:21:45.462+0000] {processor.py:157} INFO - Started process (PID=2158) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:45.464+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:21:45.466+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:45.465+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:45.490+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:21:45.522+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:45.522+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:21:45.552+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:21:45.552+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:21:45.597+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-09T23:22:15.833+0000] {processor.py:157} INFO - Started process (PID=2165) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:15.835+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:22:15.837+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:15.837+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:15.861+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:15.899+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:15.899+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:22:15.934+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:15.933+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:22:15.962+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T23:22:46.280+0000] {processor.py:157} INFO - Started process (PID=2173) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:46.281+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:22:46.283+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:46.282+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:46.304+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:22:46.341+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:46.341+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:22:46.371+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:22:46.371+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:22:46.394+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-09T23:23:16.618+0000] {processor.py:157} INFO - Started process (PID=2181) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:16.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:23:16.622+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:16.622+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:16.643+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:16.677+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:16.676+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:23:16.707+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:16.707+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:23:16.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T23:23:47.063+0000] {processor.py:157} INFO - Started process (PID=2190) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:47.065+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:23:47.067+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:47.066+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:47.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:23:47.120+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:47.120+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:23:47.150+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:23:47.150+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:23:47.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:24:17.420+0000] {processor.py:157} INFO - Started process (PID=2198) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:17.422+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:24:17.424+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:17.423+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:17.445+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:17.479+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:17.479+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:24:17.508+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:17.508+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:24:17.536+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-09T23:24:47.831+0000] {processor.py:157} INFO - Started process (PID=2206) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:47.833+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:24:47.835+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:47.834+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:47.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:24:47.894+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:47.894+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:24:47.924+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:24:47.924+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:24:47.948+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T23:25:18.203+0000] {processor.py:157} INFO - Started process (PID=2214) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:18.206+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:25:18.209+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:18.208+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:18.238+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:18.277+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:18.277+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:25:18.313+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:18.313+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:25:18.344+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T23:25:48.578+0000] {processor.py:157} INFO - Started process (PID=2222) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:48.581+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:25:48.584+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:48.583+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:48.622+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:25:48.684+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:48.684+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:25:48.736+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:25:48.735+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:25:48.765+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.195 seconds
[2023-10-09T23:26:18.897+0000] {processor.py:157} INFO - Started process (PID=2230) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:18.898+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:26:18.900+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:18.899+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:18.919+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:18.956+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:18.955+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:26:18.992+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:18.992+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:26:19.017+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.125 seconds
[2023-10-09T23:26:49.186+0000] {processor.py:157} INFO - Started process (PID=2238) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:49.189+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:26:49.192+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:49.191+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:49.232+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:26:49.268+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:49.268+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:26:49.298+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:26:49.298+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:26:49.322+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:27:19.610+0000] {processor.py:157} INFO - Started process (PID=2245) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:19.611+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:27:19.614+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:19.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:19.647+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:19.685+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:19.685+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:27:19.715+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:19.714+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:27:19.756+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T23:27:49.910+0000] {processor.py:157} INFO - Started process (PID=2253) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:49.913+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:27:49.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:49.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:49.957+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:27:49.991+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:49.991+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:27:50.021+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:27:50.021+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:27:50.070+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.170 seconds
[2023-10-09T23:28:20.213+0000] {processor.py:157} INFO - Started process (PID=2261) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:20.215+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:28:20.218+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:20.217+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:20.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:20.279+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:20.279+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:28:20.308+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:20.308+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:28:20.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-09T23:28:50.481+0000] {processor.py:157} INFO - Started process (PID=2270) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:50.482+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:28:50.483+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:50.483+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:50.504+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:28:50.538+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:50.537+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:28:50.571+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:28:50.570+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:28:50.618+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T23:29:20.936+0000] {processor.py:157} INFO - Started process (PID=2278) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:20.938+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:29:20.940+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:20.939+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:20.965+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:21.000+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:21.000+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:29:21.033+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:21.033+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:29:21.058+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T23:29:51.272+0000] {processor.py:157} INFO - Started process (PID=2286) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:51.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:29:51.276+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:51.275+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:51.300+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:29:51.334+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:51.334+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:29:51.364+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:29:51.364+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:29:51.391+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-09T23:30:21.660+0000] {processor.py:157} INFO - Started process (PID=2294) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:21.662+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:30:21.664+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:21.664+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:21.689+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:21.724+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:21.724+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:30:21.755+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:21.755+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:30:21.777+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T23:30:51.885+0000] {processor.py:157} INFO - Started process (PID=2303) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:51.887+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:30:51.888+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:51.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:51.908+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:30:51.943+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:51.942+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:30:51.974+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:30:51.973+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:30:52.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:31:22.260+0000] {processor.py:157} INFO - Started process (PID=2311) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:22.261+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:31:22.263+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:22.263+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:22.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:22.329+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:22.329+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:31:22.361+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:22.361+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:31:22.413+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T23:31:52.579+0000] {processor.py:157} INFO - Started process (PID=2319) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:52.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:31:52.582+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:52.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:52.609+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:31:52.667+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:52.667+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:31:52.749+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:31:52.749+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:31:52.796+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.223 seconds
[2023-10-09T23:32:22.968+0000] {processor.py:157} INFO - Started process (PID=2327) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:22.970+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:32:22.972+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:22.971+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:22.999+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:23.048+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:23.048+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:32:23.088+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:23.087+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:32:23.123+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-09T23:32:53.352+0000] {processor.py:157} INFO - Started process (PID=2335) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:53.354+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:32:53.357+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:53.356+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:53.380+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:32:53.413+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:53.413+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:32:53.444+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:32:53.444+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:32:53.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T23:33:23.685+0000] {processor.py:157} INFO - Started process (PID=2343) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:23.687+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:33:23.689+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:23.688+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:23.714+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:23.755+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:23.755+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:33:23.790+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:23.790+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:33:23.814+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T23:33:54.140+0000] {processor.py:157} INFO - Started process (PID=2352) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:54.143+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:33:54.146+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:54.145+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:54.175+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:33:54.219+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:54.219+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:33:54.258+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:33:54.258+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:33:54.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-10-09T23:34:24.489+0000] {processor.py:157} INFO - Started process (PID=2359) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:24.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:34:24.495+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:24.494+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:24.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:24.565+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:24.565+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:34:24.598+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:24.597+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:34:24.626+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.149 seconds
[2023-10-09T23:34:54.784+0000] {processor.py:157} INFO - Started process (PID=2366) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:54.785+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:34:54.787+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:54.786+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:54.809+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:34:54.848+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:54.847+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:34:54.887+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:34:54.887+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:34:54.930+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.151 seconds
[2023-10-09T23:35:25.174+0000] {processor.py:157} INFO - Started process (PID=2375) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:25.176+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:35:25.179+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:25.178+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:25.203+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:25.236+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:25.236+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:35:25.266+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:25.265+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:35:25.303+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T23:35:55.506+0000] {processor.py:157} INFO - Started process (PID=2384) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:55.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:35:55.510+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:55.510+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:55.537+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:35:55.574+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:55.574+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:35:55.605+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:35:55.605+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:35:55.633+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.139 seconds
[2023-10-09T23:36:25.840+0000] {processor.py:157} INFO - Started process (PID=2392) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:25.841+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:36:25.844+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:25.843+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:25.866+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:25.899+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:25.899+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:36:25.929+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:25.929+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:36:25.974+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.144 seconds
[2023-10-09T23:36:56.215+0000] {processor.py:157} INFO - Started process (PID=2400) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:56.218+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:36:56.221+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:56.220+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:56.246+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:36:56.279+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:56.278+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:36:56.310+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:36:56.309+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:36:56.333+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T23:37:26.548+0000] {processor.py:157} INFO - Started process (PID=2408) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:26.550+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:37:26.554+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:26.554+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:26.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:26.611+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:26.610+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:37:26.641+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:26.641+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:37:26.664+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.131 seconds
[2023-10-09T23:37:56.910+0000] {processor.py:157} INFO - Started process (PID=2416) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:56.914+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:37:56.917+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:56.916+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:56.943+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:37:56.975+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:56.975+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:37:57.005+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:37:57.005+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:37:57.033+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T23:38:27.273+0000] {processor.py:157} INFO - Started process (PID=2424) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:27.274+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:38:27.276+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:27.276+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:27.296+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:27.333+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:27.332+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:38:27.365+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:27.364+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:38:27.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:38:57.649+0000] {processor.py:157} INFO - Started process (PID=2432) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:57.650+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:38:57.652+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:57.652+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:57.675+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:38:57.709+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:57.709+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:38:57.742+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:38:57.742+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:38:57.781+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T23:39:27.975+0000] {processor.py:157} INFO - Started process (PID=2440) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:27.977+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:39:27.979+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:27.979+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:28.001+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:28.036+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:28.036+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:39:28.068+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:28.068+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:39:28.095+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T23:39:58.321+0000] {processor.py:157} INFO - Started process (PID=2448) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:58.323+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:39:58.324+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:58.324+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:58.346+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:39:58.388+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:58.388+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:39:58.424+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:39:58.424+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:39:58.452+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T23:40:28.676+0000] {processor.py:157} INFO - Started process (PID=2456) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:28.677+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:40:28.679+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:28.679+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:28.709+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:28.764+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:28.763+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:40:28.811+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:28.811+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:40:28.843+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.173 seconds
[2023-10-09T23:40:59.018+0000] {processor.py:157} INFO - Started process (PID=2463) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:59.019+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:40:59.021+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:59.020+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:59.041+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:40:59.075+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:59.075+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:40:59.107+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:40:59.106+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:40:59.139+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T23:41:29.385+0000] {processor.py:157} INFO - Started process (PID=2472) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:29.388+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:41:29.391+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:29.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:29.415+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:29.450+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:29.449+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:41:29.480+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:29.480+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:41:29.516+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T23:41:59.770+0000] {processor.py:157} INFO - Started process (PID=2480) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:59.771+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:41:59.773+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:59.773+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:59.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:41:59.835+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:59.835+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:41:59.868+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:41:59.867+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:41:59.891+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T23:42:30.098+0000] {processor.py:157} INFO - Started process (PID=2488) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:42:30.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:42:30.102+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:42:30.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:42:30.127+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:42:30.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:42:30.172+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:42:30.214+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:42:30.213+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:42:30.242+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-09T23:43:00.435+0000] {processor.py:157} INFO - Started process (PID=2496) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:00.436+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:43:00.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:00.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:00.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:00.501+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:00.500+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:43:00.532+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:00.532+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:43:00.558+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:43:30.906+0000] {processor.py:157} INFO - Started process (PID=2503) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:30.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:43:30.910+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:30.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:30.931+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:43:30.964+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:30.964+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:43:30.995+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:43:30.994+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:43:31.026+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:44:01.233+0000] {processor.py:157} INFO - Started process (PID=2511) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:01.235+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:44:01.238+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:01.238+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:01.261+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:01.296+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:01.296+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:44:01.330+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:01.329+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:44:01.360+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T23:44:31.626+0000] {processor.py:157} INFO - Started process (PID=2520) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:31.629+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:44:31.632+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:31.631+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:31.674+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:44:31.710+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:31.710+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:44:31.740+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:44:31.739+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:44:31.767+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-09T23:45:01.983+0000] {processor.py:157} INFO - Started process (PID=2528) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:01.985+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:45:01.987+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:01.987+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:02.012+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:02.046+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:02.046+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:45:02.076+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:02.076+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:45:02.105+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-09T23:45:32.457+0000] {processor.py:157} INFO - Started process (PID=2536) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:32.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:45:32.460+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:32.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:32.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:45:32.523+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:32.523+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:45:32.556+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:45:32.556+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:45:32.594+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:46:02.804+0000] {processor.py:157} INFO - Started process (PID=2544) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:02.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:46:02.811+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:02.810+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:02.835+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:02.870+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:02.870+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:46:02.901+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:02.900+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:46:02.936+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:46:33.173+0000] {processor.py:157} INFO - Started process (PID=2551) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:33.175+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:46:33.176+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:33.176+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:33.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:46:33.229+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:33.229+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:46:33.261+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:46:33.261+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:46:33.334+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.166 seconds
[2023-10-09T23:47:03.482+0000] {processor.py:157} INFO - Started process (PID=2560) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:03.484+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:47:03.487+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:03.486+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:03.509+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:03.544+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:03.544+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:47:03.576+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:03.575+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:47:03.600+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-09T23:47:33.885+0000] {processor.py:157} INFO - Started process (PID=2569) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:33.886+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:47:33.888+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:33.888+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:33.911+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:47:33.948+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:33.948+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:47:33.978+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:47:33.978+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:47:34.007+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-09T23:48:04.211+0000] {processor.py:157} INFO - Started process (PID=2577) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:04.212+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:48:04.214+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:04.213+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:04.235+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:04.269+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:04.269+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:48:04.300+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:04.300+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:48:04.326+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T23:48:34.624+0000] {processor.py:157} INFO - Started process (PID=2586) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:34.625+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:48:34.627+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:34.626+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:34.653+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:48:34.694+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:34.694+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:48:34.743+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:48:34.743+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:48:34.793+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.174 seconds
[2023-10-09T23:49:05.015+0000] {processor.py:157} INFO - Started process (PID=2594) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:05.017+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:49:05.019+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:05.018+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:05.046+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:05.081+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:05.080+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:49:05.112+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:05.112+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:49:05.137+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:49:35.433+0000] {processor.py:157} INFO - Started process (PID=2603) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:35.435+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:49:35.438+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:35.437+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:35.468+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:49:35.502+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:35.502+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:49:35.534+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:49:35.533+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:49:35.559+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T23:50:05.809+0000] {processor.py:157} INFO - Started process (PID=2611) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:05.812+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:50:05.814+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:05.814+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:05.841+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:05.876+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:05.876+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:50:05.906+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:05.906+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:50:05.934+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-09T23:50:36.227+0000] {processor.py:157} INFO - Started process (PID=2619) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:36.229+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:50:36.232+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:36.231+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:36.259+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:50:36.290+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:36.290+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:50:36.321+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:50:36.321+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:50:36.357+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.140 seconds
[2023-10-09T23:51:06.578+0000] {processor.py:157} INFO - Started process (PID=2627) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:06.580+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:51:06.583+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:06.582+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:06.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:06.644+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:06.644+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:51:06.677+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:06.677+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:51:06.707+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-09T23:51:36.963+0000] {processor.py:157} INFO - Started process (PID=2635) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:36.965+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:51:36.968+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:36.967+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:36.992+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:51:37.027+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:37.027+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:51:37.060+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:51:37.060+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:51:37.097+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-09T23:52:07.341+0000] {processor.py:157} INFO - Started process (PID=2643) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:07.343+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:52:07.345+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:07.344+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:07.366+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:07.400+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:07.400+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:52:07.432+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:07.432+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:52:07.461+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-09T23:52:37.718+0000] {processor.py:157} INFO - Started process (PID=2652) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:37.720+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:52:37.722+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:37.721+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:37.747+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:52:37.782+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:37.782+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:52:37.814+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:52:37.814+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:52:37.868+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.160 seconds
[2023-10-09T23:53:08.080+0000] {processor.py:157} INFO - Started process (PID=2660) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:08.082+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:53:08.084+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:08.084+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:08.114+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:08.152+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:08.152+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:53:08.185+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:08.185+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:53:08.215+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.142 seconds
[2023-10-09T23:53:38.454+0000] {processor.py:157} INFO - Started process (PID=2668) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:38.456+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:53:38.458+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:38.457+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:38.478+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:53:38.510+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:38.510+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:53:38.542+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:53:38.541+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:53:38.570+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-09T23:54:08.827+0000] {processor.py:157} INFO - Started process (PID=2676) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:08.829+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:54:08.834+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:08.833+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:08.868+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:08.911+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:08.910+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:54:08.946+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:08.945+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:54:08.975+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.156 seconds
[2023-10-09T23:54:39.105+0000] {processor.py:157} INFO - Started process (PID=2684) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:39.107+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:54:39.108+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:39.108+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:39.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:54:39.166+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:39.166+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:54:39.198+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:54:39.198+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:54:39.220+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:55:09.471+0000] {processor.py:157} INFO - Started process (PID=2692) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:09.474+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:55:09.477+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:09.476+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:09.508+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:09.542+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:09.542+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:55:09.575+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:09.575+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:55:09.602+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:55:39.825+0000] {processor.py:157} INFO - Started process (PID=2700) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:39.828+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:55:39.830+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:39.830+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:39.859+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:55:39.895+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:39.894+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:55:39.925+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:55:39.925+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:55:39.964+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.154 seconds
[2023-10-09T23:56:10.237+0000] {processor.py:157} INFO - Started process (PID=2707) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:10.240+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:56:10.243+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:10.242+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:10.270+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:10.302+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:10.302+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:56:10.333+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:10.332+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:56:10.389+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-10-09T23:56:40.556+0000] {processor.py:157} INFO - Started process (PID=2715) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:40.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:56:40.559+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:40.558+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:40.579+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:56:40.613+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:40.612+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:56:40.643+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:56:40.643+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:56:40.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-09T23:57:11.047+0000] {processor.py:157} INFO - Started process (PID=2723) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:11.049+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:57:11.051+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:11.050+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:11.073+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:11.106+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:11.105+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:57:11.136+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:11.136+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:57:11.185+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.145 seconds
[2023-10-09T23:57:41.348+0000] {processor.py:157} INFO - Started process (PID=2731) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:41.355+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:57:41.358+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:41.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:41.400+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:57:41.471+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:41.470+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:57:41.520+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:57:41.520+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:57:41.553+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.216 seconds
[2023-10-09T23:58:11.727+0000] {processor.py:157} INFO - Started process (PID=2739) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:11.729+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:58:11.730+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:11.730+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:11.750+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:11.786+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:11.785+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:58:11.818+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:11.818+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:58:11.844+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-09T23:58:42.113+0000] {processor.py:157} INFO - Started process (PID=2747) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:42.115+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:58:42.117+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:42.116+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:42.139+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:58:42.172+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:42.172+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:58:42.202+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:58:42.201+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:58:42.227+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-09T23:59:12.409+0000] {processor.py:157} INFO - Started process (PID=2754) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:12.411+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:59:12.413+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:12.413+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:12.439+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:12.479+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:12.479+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:59:12.513+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:12.512+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:59:12.537+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-09T23:59:42.813+0000] {processor.py:157} INFO - Started process (PID=2762) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:42.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-09T23:59:42.817+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:42.816+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:42.840+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-09T23:59:42.878+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:42.878+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-09T23:59:42.908+0000] {logging_mixin.py:150} INFO - [2023-10-09T23:59:42.908+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-09T23:59:42.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
