[2023-10-02T03:29:13.521+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:13.529+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:29:13.549+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:13.549+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:13.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:14.403+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:14.402+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:29:14.471+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:14.471+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:29:14.603+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.152 seconds
[2023-10-02T03:29:44.841+0000] {processor.py:157} INFO - Started process (PID=50) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:44.853+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:29:44.855+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:44.854+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:44.907+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:29:44.959+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:44.959+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:29:45.062+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:29:45.061+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:29:45.128+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.294 seconds
[2023-10-02T03:30:15.333+0000] {processor.py:157} INFO - Started process (PID=58) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:15.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:30:15.338+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:15.337+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:15.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:15.410+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:15.410+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:30:15.457+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:15.457+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:30:15.495+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.167 seconds
[2023-10-02T03:30:45.679+0000] {processor.py:157} INFO - Started process (PID=66) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:45.681+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:30:45.683+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:45.682+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:45.699+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:30:45.743+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:45.742+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:30:45.792+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:30:45.792+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:30:45.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.153 seconds
[2023-10-02T03:31:15.873+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:15.874+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:31:15.876+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:15.875+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:15.894+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:15.946+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:15.946+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:31:16.003+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:16.002+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:31:16.037+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.171 seconds
[2023-10-02T03:31:46.184+0000] {processor.py:157} INFO - Started process (PID=84) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:46.185+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:31:46.186+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:46.186+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:46.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:31:46.232+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:46.231+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:31:46.269+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:31:46.269+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:31:46.309+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-02T03:32:16.458+0000] {processor.py:157} INFO - Started process (PID=92) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:32:16.459+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:32:16.461+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:32:16.461+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:32:16.479+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:32:16.517+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:32:16.517+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:32:16.547+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:32:16.547+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:32:16.593+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.141 seconds
[2023-10-02T03:50:11.002+0000] {processor.py:157} INFO - Started process (PID=47) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:11.005+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:50:11.010+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:11.010+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:11.047+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:11.387+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:11.387+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:50:11.434+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:11.434+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:50:11.467+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.471 seconds
[2023-10-02T03:50:41.794+0000] {processor.py:157} INFO - Started process (PID=55) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:41.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:50:41.803+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:41.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:41.828+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:50:41.884+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:41.884+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:50:41.921+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:50:41.921+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:50:41.947+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-02T03:51:12.093+0000] {processor.py:157} INFO - Started process (PID=63) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:12.095+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:51:12.097+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:12.096+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:12.113+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:12.165+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:12.165+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:51:12.215+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:12.215+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:51:12.244+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.159 seconds
[2023-10-02T03:51:42.585+0000] {processor.py:157} INFO - Started process (PID=71) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:42.586+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:51:42.588+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:42.588+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:42.605+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:51:42.648+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:42.648+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:51:42.685+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:51:42.685+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:51:42.716+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-02T03:52:12.930+0000] {processor.py:157} INFO - Started process (PID=79) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:12.932+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:52:12.935+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:12.934+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:12.955+0000] {processor.py:836} INFO - DAG(s) dict_keys(['trigger_script_in_docker']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:12.988+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:12.988+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:52:13.018+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:13.018+0000] {dag.py:3508} INFO - Setting next_dagrun for trigger_script_in_docker to None, run_after=None
[2023-10-02T03:52:13.041+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-02T03:52:27.105+0000] {processor.py:157} INFO - Started process (PID=80) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:27.108+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:52:27.110+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:27.109+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:27.132+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:27.129+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract Job Data in Selenium Container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:52:27.132+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:27.161+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.071 seconds
[2023-10-02T03:52:47.394+0000] {processor.py:157} INFO - Started process (PID=88) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:47.396+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:52:47.398+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:47.397+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:47.415+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:52:47.411+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:52:47.416+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:52:47.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.069 seconds
[2023-10-02T03:53:17.709+0000] {processor.py:157} INFO - Started process (PID=96) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:17.711+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:53:17.712+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:53:17.712+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:17.721+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:53:17.719+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:53:17.722+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:17.747+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-10-02T03:53:48.065+0000] {processor.py:157} INFO - Started process (PID=104) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:48.067+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:53:48.073+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:53:48.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:48.082+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:53:48.080+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:53:48.083+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:53:48.106+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.048 seconds
[2023-10-02T03:54:18.401+0000] {processor.py:157} INFO - Started process (PID=112) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:18.403+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:54:18.406+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:54:18.405+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:18.415+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:54:18.413+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:54:18.415+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:18.439+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.045 seconds
[2023-10-02T03:54:48.701+0000] {processor.py:157} INFO - Started process (PID=120) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:48.703+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:54:48.706+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:54:48.705+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:48.714+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:54:48.712+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:54:48.714+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:54:48.735+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.039 seconds
[2023-10-02T03:55:19.161+0000] {processor.py:157} INFO - Started process (PID=128) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:19.162+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:55:19.164+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:55:19.164+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:19.173+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:55:19.171+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:55:19.174+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:19.198+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-10-02T03:55:49.445+0000] {processor.py:157} INFO - Started process (PID=136) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:49.447+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:55:49.448+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:55:49.448+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:49.457+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:55:49.454+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:55:49.457+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:55:49.484+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.044 seconds
[2023-10-02T03:56:19.788+0000] {processor.py:157} INFO - Started process (PID=144) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:19.789+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:56:19.791+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:56:19.790+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:19.799+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:56:19.797+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:56:19.800+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:19.824+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.042 seconds
[2023-10-02T03:56:50.131+0000] {processor.py:157} INFO - Started process (PID=152) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:50.133+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:56:50.135+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:56:50.135+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:50.145+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:56:50.142+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:56:50.146+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:56:50.174+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.048 seconds
[2023-10-02T03:57:20.452+0000] {processor.py:157} INFO - Started process (PID=160) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:20.454+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:57:20.456+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:57:20.456+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:20.466+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:57:20.463+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:57:20.467+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:20.491+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.047 seconds
[2023-10-02T03:57:50.807+0000] {processor.py:157} INFO - Started process (PID=168) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:50.808+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:57:50.810+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:57:50.809+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:50.819+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:57:50.817+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:57:50.820+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:57:50.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.053 seconds
[2023-10-02T03:58:21.141+0000] {processor.py:157} INFO - Started process (PID=176) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:21.142+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:58:21.144+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:21.144+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:21.153+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:21.150+0000] {dagbag.py:350} ERROR - Failed to import: /opt/airflow/dags/extract_job_data_dag.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dagbag.py", line 346, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/extract_job_data_dag.py", line 16, in <module>
    schedule_interval=None,  # Define your schedule interval
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/dag.py", line 452, in __init__
    validate_key(dag_id)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/helpers.py", line 56, in validate_key
    f"The key {k!r} has to be made of alphanumeric characters, dashes, "
airflow.exceptions.AirflowException: The key 'Extract job data in selenium container' has to be made of alphanumeric characters, dashes, dots and underscores exclusively
[2023-10-02T03:58:21.153+0000] {processor.py:838} WARNING - No viable dags retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:21.176+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.041 seconds
[2023-10-02T03:58:50.388+0000] {processor.py:157} INFO - Started process (PID=184) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:50.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:58:50.391+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:50.410+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:58:50.550+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.550+0000] {manager.py:504} INFO - Created Permission View: can edit on DAG:Extract_job_data_in_selenium_container
[2023-10-02T03:58:50.565+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.565+0000] {manager.py:504} INFO - Created Permission View: can read on DAG:Extract_job_data_in_selenium_container
[2023-10-02T03:58:50.576+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.576+0000] {manager.py:504} INFO - Created Permission View: can delete on DAG:Extract_job_data_in_selenium_container
[2023-10-02T03:58:50.595+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.595+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:58:50.613+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.613+0000] {dag.py:2763} INFO - Creating ORM DAG for Extract_job_data_in_selenium_container
[2023-10-02T03:58:50.627+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:58:50.626+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T03:58:50.654+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.271 seconds
[2023-10-02T03:59:20.934+0000] {processor.py:157} INFO - Started process (PID=192) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:20.941+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:59:20.944+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:20.943+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:21.010+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:21.074+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:21.073+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:59:21.160+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:21.159+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T03:59:21.229+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.345 seconds
[2023-10-02T03:59:51.493+0000] {processor.py:157} INFO - Started process (PID=200) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:51.500+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T03:59:51.504+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:51.502+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:51.584+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T03:59:51.888+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:51.888+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T03:59:52.011+0000] {logging_mixin.py:150} INFO - [2023-10-02T03:59:52.010+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T03:59:52.144+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.677 seconds
[2023-10-02T04:00:22.431+0000] {processor.py:157} INFO - Started process (PID=208) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:22.433+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:00:22.435+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:22.434+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:22.452+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:22.485+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:22.484+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:00:22.521+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:22.521+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:00:22.547+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-02T04:00:52.747+0000] {processor.py:157} INFO - Started process (PID=216) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:52.749+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:00:52.751+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:52.751+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:52.769+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:00:52.806+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:52.806+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:00:52.836+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:00:52.836+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:00:52.859+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-02T04:01:23.163+0000] {processor.py:157} INFO - Started process (PID=224) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:23.164+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:01:23.168+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:23.166+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:23.183+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:23.215+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:23.215+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:01:23.246+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:23.245+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:01:23.269+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-02T04:01:53.509+0000] {processor.py:157} INFO - Started process (PID=232) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:53.511+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:01:53.514+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:53.513+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:53.531+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:01:53.562+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:53.562+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:01:53.592+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:01:53.591+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:01:53.628+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-02T04:02:23.882+0000] {processor.py:157} INFO - Started process (PID=240) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:23.884+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:02:23.887+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:23.886+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:23.905+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:23.941+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:23.941+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:02:23.971+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:23.971+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:02:23.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-02T04:02:54.265+0000] {processor.py:157} INFO - Started process (PID=249) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:54.268+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:02:54.271+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:54.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:54.291+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:02:54.333+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:54.333+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:02:54.362+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:02:54.362+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:02:54.386+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-02T04:03:24.652+0000] {processor.py:157} INFO - Started process (PID=257) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:24.654+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:03:24.656+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:24.655+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:24.673+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:24.707+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:24.707+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:03:24.739+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:24.739+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:03:24.786+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-02T04:03:55.029+0000] {processor.py:157} INFO - Started process (PID=265) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:55.031+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:03:55.033+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:55.032+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:55.066+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:03:55.099+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:55.099+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:03:55.132+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:03:55.132+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:03:55.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-02T04:06:54.323+0000] {processor.py:157} INFO - Started process (PID=36) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:06:54.335+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:06:54.346+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:06:54.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:06:54.562+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:06:55.305+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:06:55.305+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:06:55.430+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:06:55.430+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:06:55.513+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 1.298 seconds
[2023-10-02T04:07:25.730+0000] {processor.py:157} INFO - Started process (PID=44) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:25.743+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:07:25.748+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:25.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:25.974+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:26.238+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:26.238+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:07:26.382+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:26.381+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:07:26.437+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.714 seconds
[2023-10-02T04:07:56.606+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:56.611+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:07:56.615+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:56.613+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:56.760+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:07:56.832+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:56.831+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:07:56.937+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:07:56.937+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:07:56.970+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.392 seconds
[2023-10-02T04:08:27.267+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:27.269+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:08:27.271+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:27.270+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:27.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:27.323+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:27.323+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:08:27.355+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:27.354+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:08:27.378+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-02T04:08:57.565+0000] {processor.py:157} INFO - Started process (PID=75) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:57.568+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:08:57.574+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:57.572+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:57.606+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:08:57.669+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:57.669+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:08:57.746+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:08:57.745+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:08:57.771+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.216 seconds
[2023-10-02T04:10:18.330+0000] {processor.py:157} INFO - Started process (PID=35) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:18.337+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:10:18.340+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:18.339+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:18.387+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:18.627+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:18.627+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:10:18.714+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:18.714+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:10:18.762+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.444 seconds
[2023-10-02T04:10:49.036+0000] {processor.py:157} INFO - Started process (PID=43) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:49.039+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:10:49.042+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:49.041+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:49.062+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:10:49.096+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:49.095+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:10:49.131+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:10:49.131+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:10:49.155+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-02T04:11:19.339+0000] {processor.py:157} INFO - Started process (PID=52) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:19.340+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:11:19.342+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:19.342+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:19.358+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:19.392+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:19.391+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:11:19.423+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:19.423+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:11:19.447+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:11:49.777+0000] {processor.py:157} INFO - Started process (PID=60) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:49.778+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:11:49.780+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:49.779+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:49.795+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:11:49.915+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:49.914+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:11:49.945+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:11:49.945+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:11:49.968+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.197 seconds
[2023-10-02T04:12:20.098+0000] {processor.py:157} INFO - Started process (PID=70) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:20.100+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:12:20.102+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:20.101+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:20.119+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:20.160+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:20.160+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:12:20.194+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:20.194+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:12:20.218+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-02T04:12:50.509+0000] {processor.py:157} INFO - Started process (PID=78) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:50.510+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:12:50.512+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:50.512+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:50.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:12:50.557+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:50.557+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:12:50.586+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:12:50.585+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:12:50.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-02T04:13:20.821+0000] {processor.py:157} INFO - Started process (PID=86) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:20.823+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:13:20.825+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:20.824+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:20.846+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:20.881+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:20.881+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:13:20.910+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:20.910+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:13:20.933+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-02T04:13:51.225+0000] {processor.py:157} INFO - Started process (PID=94) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:51.226+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:13:51.228+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:51.228+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:51.254+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:13:51.296+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:51.296+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:13:51.323+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:13:51.323+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:13:51.346+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.128 seconds
[2023-10-02T04:14:21.571+0000] {processor.py:157} INFO - Started process (PID=102) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:21.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:14:21.574+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:21.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:21.591+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:21.630+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:21.629+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:14:21.657+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:21.657+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:14:21.681+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-02T04:14:51.905+0000] {processor.py:157} INFO - Started process (PID=110) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:51.907+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:14:51.910+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:51.909+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:51.930+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:14:51.971+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:51.970+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:14:52.004+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:14:52.003+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:14:52.029+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.133 seconds
[2023-10-02T04:15:22.282+0000] {processor.py:157} INFO - Started process (PID=118) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:22.284+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:15:22.286+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:22.286+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:22.308+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:22.361+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:22.361+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:15:22.420+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:22.420+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:15:22.472+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.199 seconds
[2023-10-02T04:15:52.597+0000] {processor.py:157} INFO - Started process (PID=126) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:52.600+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:15:52.606+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:52.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:52.654+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:15:52.776+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:52.776+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:15:52.860+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:15:52.859+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:15:52.913+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.334 seconds
[2023-10-02T04:16:23.049+0000] {processor.py:157} INFO - Started process (PID=134) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:23.050+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:16:23.051+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:23.051+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:23.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:23.096+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:23.096+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:16:23.125+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:23.125+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:16:23.148+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.103 seconds
[2023-10-02T04:16:53.376+0000] {processor.py:157} INFO - Started process (PID=142) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:53.378+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:16:53.380+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:53.379+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:53.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:16:53.432+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:53.432+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:16:53.470+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:16:53.470+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:16:53.497+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.127 seconds
[2023-10-02T04:17:23.762+0000] {processor.py:157} INFO - Started process (PID=150) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:23.768+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:17:23.778+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:23.774+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:23.818+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:23.860+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:23.860+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:17:23.893+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:23.892+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:17:23.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.180 seconds
[2023-10-02T04:17:54.171+0000] {processor.py:157} INFO - Started process (PID=158) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:54.173+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:17:54.176+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:54.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:54.199+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:17:54.238+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:54.238+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:17:54.276+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:17:54.275+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:17:54.305+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.146 seconds
[2023-10-02T04:18:24.506+0000] {processor.py:157} INFO - Started process (PID=166) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:24.508+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:18:24.510+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:24.509+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:24.526+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:24.565+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:24.564+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:18:24.605+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:24.605+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:18:24.631+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.132 seconds
[2023-10-02T04:18:54.888+0000] {processor.py:157} INFO - Started process (PID=174) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:54.894+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:18:54.895+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:54.895+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:54.910+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:18:54.943+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:54.943+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:18:54.972+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:18:54.972+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:18:54.995+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-10-02T04:19:25.251+0000] {processor.py:157} INFO - Started process (PID=181) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:25.252+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:19:25.254+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:25.253+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:25.271+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:25.303+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:25.302+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:19:25.332+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:25.332+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:19:25.355+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-02T04:19:55.554+0000] {processor.py:157} INFO - Started process (PID=190) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:55.556+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:19:55.558+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:55.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:55.577+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:19:55.663+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:55.662+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:19:55.697+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:19:55.696+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:19:55.723+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.175 seconds
[2023-10-02T04:20:26.040+0000] {processor.py:157} INFO - Started process (PID=198) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:26.047+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:20:26.056+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:26.055+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:26.089+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:26.149+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:26.149+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:20:26.187+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:26.187+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:20:26.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.208 seconds
[2023-10-02T04:20:56.318+0000] {processor.py:157} INFO - Started process (PID=206) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:56.319+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:20:56.321+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:56.321+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:56.336+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:20:56.377+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:56.377+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:20:56.407+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:20:56.407+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:20:56.432+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.120 seconds
[2023-10-02T04:21:26.571+0000] {processor.py:157} INFO - Started process (PID=214) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:26.572+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:21:26.573+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:26.573+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:26.587+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:26.621+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:26.620+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:21:26.651+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:26.651+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:21:26.674+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-10-02T04:21:56.897+0000] {processor.py:157} INFO - Started process (PID=222) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:56.899+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:21:56.901+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:56.901+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:56.921+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:21:56.953+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:56.953+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:21:56.982+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:21:56.982+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:21:57.005+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:22:27.307+0000] {processor.py:157} INFO - Started process (PID=230) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:27.309+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:22:27.311+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:27.310+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:27.325+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:27.357+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:27.357+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:22:27.386+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:27.386+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:22:27.418+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.117 seconds
[2023-10-02T04:22:57.601+0000] {processor.py:157} INFO - Started process (PID=244) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:57.603+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:22:57.605+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:57.604+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:57.623+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:22:57.661+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:57.661+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:22:57.692+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:22:57.691+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:22:57.752+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-02T04:23:28.055+0000] {processor.py:157} INFO - Started process (PID=253) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:28.057+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:23:28.058+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:28.058+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:28.074+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:28.107+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:28.107+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:23:28.137+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:28.137+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:23:28.160+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-02T04:23:58.345+0000] {processor.py:157} INFO - Started process (PID=261) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:58.346+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:23:58.348+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:58.348+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:58.367+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:23:58.402+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:58.402+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:23:58.437+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:23:58.437+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:23:58.460+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.119 seconds
[2023-10-02T04:24:28.780+0000] {processor.py:157} INFO - Started process (PID=269) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:28.781+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:24:28.782+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:28.782+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:28.796+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:28.882+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:28.882+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:24:28.913+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:28.913+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:24:28.940+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-02T04:24:59.109+0000] {processor.py:157} INFO - Started process (PID=277) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:59.111+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:24:59.113+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:59.112+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:59.129+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:24:59.164+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:59.164+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:24:59.195+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:24:59.195+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:24:59.217+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:25:29.439+0000] {processor.py:157} INFO - Started process (PID=285) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:29.440+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:25:29.442+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:29.441+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:29.457+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:29.487+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:29.487+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:25:29.517+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:29.517+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:25:29.540+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-10-02T04:25:59.809+0000] {processor.py:157} INFO - Started process (PID=293) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:59.815+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:25:59.822+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:59.820+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:59.881+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:25:59.940+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:59.940+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:25:59.977+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:25:59.977+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:26:00.002+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.214 seconds
[2023-10-02T04:26:30.161+0000] {processor.py:157} INFO - Started process (PID=302) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:26:30.163+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:26:30.165+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:26:30.165+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:26:30.186+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:26:30.227+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:26:30.227+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:26:30.257+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:26:30.257+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:26:30.304+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-02T04:27:00.603+0000] {processor.py:157} INFO - Started process (PID=310) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:00.604+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:27:00.606+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:00.606+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:00.628+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:00.660+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:00.659+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:27:00.688+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:00.687+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:27:00.711+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-02T04:27:30.987+0000] {processor.py:157} INFO - Started process (PID=318) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:30.993+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:27:30.999+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:30.997+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:31.064+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:27:31.119+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:31.119+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:27:31.158+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:27:31.157+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:27:31.190+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.227 seconds
[2023-10-02T04:28:01.345+0000] {processor.py:157} INFO - Started process (PID=326) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:01.347+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:28:01.351+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:01.350+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:01.385+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:01.421+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:01.421+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:28:01.450+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:01.450+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:28:01.475+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-02T04:28:31.726+0000] {processor.py:157} INFO - Started process (PID=334) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:31.728+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:28:31.730+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:31.729+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:31.752+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:28:31.788+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:31.787+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:28:31.816+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:28:31.816+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:28:31.840+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-02T04:29:02.013+0000] {processor.py:157} INFO - Started process (PID=342) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:02.015+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:29:02.017+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:02.016+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:02.035+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:02.073+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:02.073+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:29:02.105+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:02.104+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:29:02.129+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
[2023-10-02T04:29:32.387+0000] {processor.py:157} INFO - Started process (PID=351) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:32.389+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:29:32.391+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:32.390+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:32.408+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:29:32.442+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:32.442+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:29:32.471+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:29:32.471+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:29:32.494+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.113 seconds
[2023-10-02T04:30:02.714+0000] {processor.py:157} INFO - Started process (PID=359) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:02.715+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:30:02.717+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:02.717+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:02.734+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:02.768+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:02.768+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:30:02.799+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:02.798+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:30:02.823+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:30:33.100+0000] {processor.py:157} INFO - Started process (PID=367) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:33.101+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:30:33.103+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:33.102+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:33.121+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:30:33.153+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:33.152+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:30:33.186+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:30:33.185+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:30:33.207+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.114 seconds
[2023-10-02T04:31:03.415+0000] {processor.py:157} INFO - Started process (PID=375) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:03.417+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:31:03.419+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:03.418+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:03.438+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:03.474+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:03.474+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:31:03.502+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:03.502+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:31:03.526+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-02T04:31:33.753+0000] {processor.py:157} INFO - Started process (PID=384) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:33.754+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:31:33.755+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:33.755+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:33.770+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:31:33.808+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:33.808+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:31:33.842+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:31:33.842+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:31:33.874+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-02T04:32:04.153+0000] {processor.py:157} INFO - Started process (PID=393) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:04.159+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:32:04.160+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:04.160+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:04.179+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:04.216+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:04.216+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:32:04.253+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:04.252+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:32:04.280+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.138 seconds
[2023-10-02T04:32:34.457+0000] {processor.py:157} INFO - Started process (PID=401) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:34.458+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:32:34.461+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:34.460+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:34.487+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:32:34.525+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:34.524+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:32:34.555+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:32:34.555+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:32:34.584+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.135 seconds
[2023-10-02T04:33:04.806+0000] {processor.py:157} INFO - Started process (PID=408) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:04.807+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:33:04.809+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:04.808+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:04.824+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:04.857+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:04.857+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:33:04.886+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:04.886+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:33:04.909+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-10-02T04:33:35.148+0000] {processor.py:157} INFO - Started process (PID=416) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:35.150+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:33:35.151+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:35.151+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:35.166+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:33:35.197+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:35.197+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:33:35.226+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:33:35.226+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:33:35.259+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-02T04:34:05.494+0000] {processor.py:157} INFO - Started process (PID=424) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:05.497+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:34:05.499+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:05.498+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:05.521+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:05.558+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:05.557+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:34:05.591+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:05.591+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:34:05.619+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.136 seconds
[2023-10-02T04:34:35.835+0000] {processor.py:157} INFO - Started process (PID=433) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:35.837+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:34:35.840+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:35.839+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:35.865+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:34:35.898+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:35.898+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:34:35.928+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:34:35.928+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:34:35.951+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-02T04:35:06.179+0000] {processor.py:157} INFO - Started process (PID=441) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:06.180+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:35:06.182+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:06.181+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:06.205+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:06.249+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:06.249+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:35:06.291+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:06.290+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:35:06.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.150 seconds
[2023-10-02T04:35:36.522+0000] {processor.py:157} INFO - Started process (PID=450) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:36.525+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:35:36.528+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:36.527+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:36.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:35:36.601+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:36.600+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:35:36.637+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:35:36.637+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:35:36.672+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.157 seconds
[2023-10-02T04:36:06.894+0000] {processor.py:157} INFO - Started process (PID=458) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:06.896+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:36:06.898+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:06.898+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:06.917+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:06.951+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:06.951+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:36:06.979+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:06.979+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:36:07.009+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-02T04:36:37.268+0000] {processor.py:157} INFO - Started process (PID=466) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:37.270+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:36:37.271+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:37.271+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:37.287+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:36:37.318+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:37.318+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:36:37.347+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:36:37.347+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:36:37.370+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.107 seconds
[2023-10-02T04:37:07.619+0000] {processor.py:157} INFO - Started process (PID=475) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:07.620+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:37:07.622+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:07.621+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:07.640+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:07.677+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:07.676+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:37:07.710+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:07.710+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:37:07.738+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-02T04:37:37.926+0000] {processor.py:157} INFO - Started process (PID=484) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:37.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:37:37.931+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:37.931+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:37.959+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:37:38.001+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:38.000+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:37:38.032+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:37:38.031+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:37:38.054+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.134 seconds
[2023-10-02T04:38:08.286+0000] {processor.py:157} INFO - Started process (PID=493) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:08.287+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:38:08.289+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:08.288+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:08.302+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:08.335+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:08.335+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:38:08.373+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:08.372+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:38:08.397+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:38:38.555+0000] {processor.py:157} INFO - Started process (PID=501) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:38.557+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:38:38.558+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:38.557+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:38.572+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:38:38.611+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:38.610+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:38:38.683+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:38:38.683+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:38:38.712+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.161 seconds
[2023-10-02T04:39:08.945+0000] {processor.py:157} INFO - Started process (PID=509) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:08.947+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:39:08.948+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:08.948+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:08.961+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:08.992+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:08.992+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:39:09.023+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:09.022+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:39:09.061+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-02T04:39:39.305+0000] {processor.py:157} INFO - Started process (PID=517) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:39.310+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:39:39.317+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:39.316+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:39.397+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:39:39.458+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:39.458+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:39:39.514+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:39:39.513+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:39:39.543+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.262 seconds
[2023-10-02T04:40:09.744+0000] {processor.py:157} INFO - Started process (PID=525) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:09.745+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:40:09.747+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:09.746+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:09.763+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:09.800+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:09.799+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:40:09.829+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:09.829+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:40:09.852+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.116 seconds
[2023-10-02T04:40:40.249+0000] {processor.py:157} INFO - Started process (PID=532) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:40.251+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:40:40.253+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:40.252+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:40.272+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:40:40.310+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:40.310+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:40:40.340+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:40:40.339+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:40:40.362+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.121 seconds
[2023-10-02T04:41:10.533+0000] {processor.py:157} INFO - Started process (PID=540) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:10.534+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:41:10.536+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:10.535+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:10.550+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:10.584+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:10.583+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:41:10.614+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:10.614+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:41:10.637+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.109 seconds
[2023-10-02T04:41:40.949+0000] {processor.py:157} INFO - Started process (PID=548) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:40.951+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:41:40.953+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:40.952+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:40.972+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:41:41.006+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:41.006+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:41:41.038+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:41:41.037+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:41:41.060+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.123 seconds
[2023-10-02T04:42:11.261+0000] {processor.py:157} INFO - Started process (PID=556) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:11.263+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:42:11.267+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:11.266+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:11.286+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:11.322+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:11.321+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:42:11.353+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:11.353+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:42:11.376+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-02T04:42:41.737+0000] {processor.py:157} INFO - Started process (PID=565) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:41.740+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:42:41.743+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:41.742+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:41.787+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:42:41.844+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:41.844+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:42:41.890+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:42:41.890+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:42:41.916+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.192 seconds
[2023-10-02T04:43:12.062+0000] {processor.py:157} INFO - Started process (PID=573) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:12.064+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:43:12.065+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:12.065+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:12.087+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:12.133+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:12.133+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:43:12.168+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:12.168+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:43:12.192+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.137 seconds
[2023-10-02T04:43:42.468+0000] {processor.py:157} INFO - Started process (PID=580) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:42.469+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:43:42.471+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:42.470+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:42.486+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:43:42.518+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:42.518+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:43:42.547+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:43:42.547+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:43:42.569+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.108 seconds
[2023-10-02T04:44:12.799+0000] {processor.py:157} INFO - Started process (PID=588) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:12.800+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:44:12.802+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:12.802+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:12.821+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:12.856+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:12.855+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:44:12.886+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:12.886+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:44:12.911+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.118 seconds
[2023-10-02T04:44:43.175+0000] {processor.py:157} INFO - Started process (PID=596) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:43.177+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:44:43.179+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:43.179+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:43.196+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:44:43.232+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:43.231+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:44:43.261+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:44:43.261+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:44:43.296+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.129 seconds
[2023-10-02T04:45:13.515+0000] {processor.py:157} INFO - Started process (PID=604) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:13.516+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:45:13.517+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:13.517+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:13.535+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:13.567+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:13.567+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:45:13.598+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:13.598+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:45:13.620+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.110 seconds
[2023-10-02T04:45:43.988+0000] {processor.py:157} INFO - Started process (PID=612) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:43.991+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:45:43.993+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:43.992+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:44.018+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:45:44.125+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:44.124+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:45:44.167+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:45:44.167+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:45:44.208+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.226 seconds
[2023-10-02T04:46:14.327+0000] {processor.py:157} INFO - Started process (PID=620) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:14.329+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:46:14.331+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:14.330+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:14.347+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:14.380+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:14.380+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:46:14.411+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:14.411+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:46:14.433+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.115 seconds
[2023-10-02T04:46:44.775+0000] {processor.py:157} INFO - Started process (PID=628) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:44.776+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:46:44.778+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:44.777+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:44.792+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:46:44.823+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:44.823+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:46:44.853+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:46:44.852+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:46:44.876+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.105 seconds
[2023-10-02T04:47:15.072+0000] {processor.py:157} INFO - Started process (PID=637) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:15.077+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:47:15.078+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:15.078+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:15.102+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:15.158+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:15.158+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:47:15.216+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:15.216+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:47:15.324+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.257 seconds
[2023-10-02T04:47:45.663+0000] {processor.py:157} INFO - Started process (PID=646) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:45.666+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:47:45.668+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:45.668+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:45.688+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:47:45.726+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:45.726+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:47:45.756+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:47:45.756+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:47:45.780+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.130 seconds
[2023-10-02T04:48:15.926+0000] {processor.py:157} INFO - Started process (PID=654) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:15.927+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:48:15.929+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:15.929+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:15.950+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:15.990+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:15.990+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:48:16.020+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:16.019+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:48:16.044+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.126 seconds
[2023-10-02T04:48:46.355+0000] {processor.py:157} INFO - Started process (PID=662) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:46.356+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:48:46.358+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:46.357+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:46.372+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:48:46.403+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:46.402+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:48:46.432+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:48:46.432+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:48:46.456+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.107 seconds
[2023-10-02T04:49:16.704+0000] {processor.py:157} INFO - Started process (PID=670) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:16.706+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:49:16.707+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:16.707+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:16.728+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:16.788+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:16.788+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:49:16.818+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:16.817+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:49:16.841+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.143 seconds
[2023-10-02T04:49:47.071+0000] {processor.py:157} INFO - Started process (PID=678) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:47.071+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:49:47.073+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:47.073+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:47.086+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:49:47.128+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:47.128+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:49:47.161+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:49:47.160+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:49:47.188+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.122 seconds
[2023-10-02T04:50:17.491+0000] {processor.py:157} INFO - Started process (PID=686) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:17.492+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:50:17.493+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:17.493+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:17.507+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:17.539+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:17.538+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:50:17.572+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:17.572+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:50:17.598+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.111 seconds
[2023-10-02T04:50:47.911+0000] {processor.py:157} INFO - Started process (PID=694) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:47.912+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:50:47.913+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:47.913+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:47.928+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:50:47.960+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:47.960+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:50:47.990+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:50:47.990+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:50:48.016+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.112 seconds
[2023-10-02T04:51:18.172+0000] {processor.py:157} INFO - Started process (PID=701) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:18.174+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:51:18.176+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:18.175+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:18.194+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:18.240+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:18.239+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:51:18.280+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:18.280+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:51:18.332+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.165 seconds
[2023-10-02T04:51:48.492+0000] {processor.py:157} INFO - Started process (PID=709) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:48.495+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:51:48.497+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:48.496+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:48.527+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:51:48.593+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:48.592+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:51:48.654+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:51:48.654+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:51:48.733+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.253 seconds
[2023-10-02T04:52:19.405+0000] {processor.py:157} INFO - Started process (PID=717) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:19.505+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:52:19.743+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:19.743+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:19.906+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:19.987+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:19.987+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:52:20.062+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:20.062+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:52:20.178+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.791 seconds
[2023-10-02T04:52:50.529+0000] {processor.py:157} INFO - Started process (PID=725) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:50.531+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:52:50.532+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:50.532+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:50.554+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:52:50.607+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:50.606+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:52:50.653+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:52:50.653+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:52:50.688+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.164 seconds
[2023-10-02T04:53:20.838+0000] {processor.py:157} INFO - Started process (PID=733) to work on /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:53:20.839+0000] {processor.py:826} INFO - Processing file /opt/airflow/dags/extract_job_data_dag.py for tasks to queue
[2023-10-02T04:53:20.841+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:53:20.840+0000] {dagbag.py:541} INFO - Filling up the DagBag from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:53:20.860+0000] {processor.py:836} INFO - DAG(s) dict_keys(['Extract_job_data_in_selenium_container']) retrieved from /opt/airflow/dags/extract_job_data_dag.py
[2023-10-02T04:53:20.896+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:53:20.896+0000] {dag.py:2742} INFO - Sync 1 DAGs
[2023-10-02T04:53:20.930+0000] {logging_mixin.py:150} INFO - [2023-10-02T04:53:20.930+0000] {dag.py:3508} INFO - Setting next_dagrun for Extract_job_data_in_selenium_container to None, run_after=None
[2023-10-02T04:53:20.956+0000] {processor.py:179} INFO - Processing /opt/airflow/dags/extract_job_data_dag.py took 0.124 seconds
